{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### RNN의 many to many 구조에 대한 간단 예"
      ],
      "metadata": {
        "id": "-An1wGPjZg7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "model = nn.RNN(input_size, hidden_size,num_layers,batch_frist=True)\n",
        "output, h_n = model(input)\n",
        "```\n",
        "\n",
        "- input_size : input의 feature수\n",
        "- hidden_size :  은닉상태의 feature 수\n",
        "- num_layers : 은닉층의 수 / num_layers가 2 이상이면 다층 RNN(Multi-layer RNN)이 됨.\n",
        "- batch_frist : input 텐서와 output 텐서 형태에서 batch_size의 위치에 대한 옵션\n",
        "    - True이면 batch가 맨 앞에 위치함.\n",
        "\n",
        "- input 텐서의 형태는 (batch_size, sequence_length, input_size) 순서\n",
        "\n",
        "- output 텐서의 형태는 (batch_size, sequence_length, num_directions *hidden_size) 순서\n",
        "    - num_directions은 방향의 수를 나타냄. Bidirectional RNN을 제외하고는 1이다.\n",
        "    - batch_first 옵션은 은닉상태의 형태에는 적용되지는 않음.\n",
        "\n"
      ],
      "metadata": {
        "id": "7hgPeM4PcRll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.RNN의 출력에는 output, h_n이 있음.\n",
        "    - output은 모든 타임 스텝에 대한 결과이고, h_n은 t=n인 마지막 타임 스텝에 대한 은닉 상태 값이다.\n",
        "    - h_n 형태는 (num_layers * num_directions, batch_size, hidden_size)이다.\n",
        "    - 이것은 batch_first=True 지정유무와 무관하다."
      ],
      "metadata": {
        "id": "3JgwkXyRddX-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hys6KnUnZTBa",
        "outputId": "8967b277-6dfc-42d3-c417-e39f2a46fce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input :  torch.Size([4, 5, 1]) \n",
            " tensor([[[ 1.],\n",
            "         [ 2.],\n",
            "         [ 3.],\n",
            "         [ 4.],\n",
            "         [ 5.]],\n",
            "\n",
            "        [[ 6.],\n",
            "         [ 7.],\n",
            "         [ 8.],\n",
            "         [ 9.],\n",
            "         [10.]],\n",
            "\n",
            "        [[11.],\n",
            "         [12.],\n",
            "         [13.],\n",
            "         [14.],\n",
            "         [15.]],\n",
            "\n",
            "        [[16.],\n",
            "         [17.],\n",
            "         [18.],\n",
            "         [19.],\n",
            "         [20.]]])\n",
            "\n",
            "output :  torch.Size([4, 5, 2]) \n",
            " tensor([[[-0.0819,  0.8100],\n",
            "         [-0.4311,  0.9332],\n",
            "         [-0.3162,  0.9748],\n",
            "         [-0.3979,  0.9875],\n",
            "         [-0.3675,  0.9944]],\n",
            "\n",
            "        [[-0.1081,  0.9953],\n",
            "         [-0.5145,  0.9986],\n",
            "         [-0.3269,  0.9995],\n",
            "         [-0.4254,  0.9997],\n",
            "         [-0.3820,  0.9999]],\n",
            "\n",
            "        [[-0.1342,  0.9999],\n",
            "         [-0.5245,  1.0000],\n",
            "         [-0.3458,  1.0000],\n",
            "         [-0.4382,  1.0000],\n",
            "         [-0.3982,  1.0000]],\n",
            "\n",
            "        [[-0.1601,  1.0000],\n",
            "         [-0.5328,  1.0000],\n",
            "         [-0.3648,  1.0000],\n",
            "         [-0.4506,  1.0000],\n",
            "         [-0.4143,  1.0000]]], grad_fn=<TransposeBackward1>)\n",
            "\n",
            "hidden :  torch.Size([1, 4, 2]) \n",
            " tensor([[[-0.3675,  0.9944],\n",
            "         [-0.3820,  0.9999],\n",
            "         [-0.3982,  1.0000],\n",
            "         [-0.4143,  1.0000]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "data = [[[1],[2],[3],[4],[5]],\n",
        "        [[6],[7],[8],[9],[10]],\n",
        "        [[11],[12],[13],[14],[15]],\n",
        "        [[16],[17],[18],[19],[20]]]\n",
        "\n",
        "inputs = torch.FloatTensor(np.array(data))\n",
        "\n",
        "INPUT_SIZE=1\n",
        "SEQUENCE_LENGTH=5\n",
        "HIDDEN_SIZE = 2\n",
        "NUM_LAYERS=1\n",
        "BACTH_SIZE=4\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "model = nn.RNN(input_size= INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, batch_first = True)\n",
        "#input_size : (batch, seq_len, input_size)\n",
        "#output size : (batch,seq_len, num_directions*hidden_size)\n",
        "#h_n shape : (num_layers * num_directions, batch, hidden_size)\n",
        "output, h_n = model(inputs)\n",
        "\n",
        "print('Input : ', inputs.shape, '\\n', inputs)\n",
        "print('\\noutput : ', output.shape, '\\n', output)\n",
        "print('\\nhidden : ', h_n.shape, '\\n', h_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.RNN 함수에서 batch_first=True이므로, 형태는 (batch_size, sequence_length, input_size) = (4,5,1)이고, 출력 데이터 형태도 (batch,sequence_length, num_direction *hidden_size) = (4,5,2) / 은닉상태의 형태는 batch_first=True는 지정과 무관하게 (num*layers * num_directions, batch, hidden_size) = (1,4,2)"
      ],
      "metadata": {
        "id": "AirmwtXbfxdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위는 20개의 데이터를 nn.RNN 클래스에서 원하는 형태에 맞추어 미리 변환한 후 모델 구축에 사용함.\n",
        "\n",
        "- 이번에는 20개의 데이터를 view()함수에 의해 원하는 형태로 변환한 후 RNN 모델을 구축해보자."
      ],
      "metadata": {
        "id": "C3VnlG_Kg_NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "data = torch.Tensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "#print('Data : ', data.shape, '\\n', data)\n",
        "\n",
        "INPUT_SIZE=1\n",
        "SEQUENCE_LENGTH=5\n",
        "HIDDEN_SIZE = 2\n",
        "NUM_LAYERS=1\n",
        "BACTH_SIZE=4\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "model = nn.RNN(input_size= INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, batch_first = True)\n",
        "#input_size : (batch, seq_len, input_size)\n",
        "input = data.view(BACTH_SIZE,SEQUENCE_LENGTH,INPUT_SIZE)\n",
        "#output size : (batch,seq_len, num_directions*hidden_size)\n",
        "#h_n shape : (num_layers * num_directions, batch, hidden_size)\n",
        "output, h_n = model(input)\n",
        "\n",
        "print('Input : ', input.shape, '\\n', input)\n",
        "print('\\noutput : ', output.shape, '\\n', output)\n",
        "print('\\nhidden : ', h_n.shape, '\\n', h_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qU_ACiTZ_-O",
        "outputId": "59397a25-ae6b-4201-b011-62860c237ca9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input :  torch.Size([4, 5, 1]) \n",
            " tensor([[[ 1.],\n",
            "         [ 2.],\n",
            "         [ 3.],\n",
            "         [ 4.],\n",
            "         [ 5.]],\n",
            "\n",
            "        [[ 6.],\n",
            "         [ 7.],\n",
            "         [ 8.],\n",
            "         [ 9.],\n",
            "         [10.]],\n",
            "\n",
            "        [[11.],\n",
            "         [12.],\n",
            "         [13.],\n",
            "         [14.],\n",
            "         [15.]],\n",
            "\n",
            "        [[16.],\n",
            "         [17.],\n",
            "         [18.],\n",
            "         [19.],\n",
            "         [20.]]])\n",
            "\n",
            "output :  torch.Size([4, 5, 2]) \n",
            " tensor([[[-0.0819,  0.8100],\n",
            "         [-0.4311,  0.9332],\n",
            "         [-0.3162,  0.9748],\n",
            "         [-0.3979,  0.9875],\n",
            "         [-0.3675,  0.9944]],\n",
            "\n",
            "        [[-0.1081,  0.9953],\n",
            "         [-0.5145,  0.9986],\n",
            "         [-0.3269,  0.9995],\n",
            "         [-0.4254,  0.9997],\n",
            "         [-0.3820,  0.9999]],\n",
            "\n",
            "        [[-0.1342,  0.9999],\n",
            "         [-0.5245,  1.0000],\n",
            "         [-0.3458,  1.0000],\n",
            "         [-0.4382,  1.0000],\n",
            "         [-0.3982,  1.0000]],\n",
            "\n",
            "        [[-0.1601,  1.0000],\n",
            "         [-0.5328,  1.0000],\n",
            "         [-0.3648,  1.0000],\n",
            "         [-0.4506,  1.0000],\n",
            "         [-0.4143,  1.0000]]], grad_fn=<TransposeBackward1>)\n",
            "\n",
            "hidden :  torch.Size([1, 4, 2]) \n",
            " tensor([[[-0.3675,  0.9944],\n",
            "         [-0.3820,  0.9999],\n",
            "         [-0.3982,  1.0000],\n",
            "         [-0.4143,  1.0000]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 언어 모델\n",
        "    - 순차적으로 입력된 자료를 바탕으로 다음에 나올 단어(word)나 문자(character)를 예측하는 모델로 자연어 처리나 음성인식 분야에 활용되고 있다.\n",
        "    - 단어(word)를 기반으로 학습하는 단어-레벨 언어 모델(word-level language model) 과 문자(character)를 기반으로 학습하는 문자-레벨 언어 모델(word-level language model)이 있다."
      ],
      "metadata": {
        "id": "wA3yYyw1hcZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- epoch이 증가할수록 손실함수 값이 작아지면서 RNN 모델은 목표값을 잘 예측함을 알 수 있다."
      ],
      "metadata": {
        "id": "wSmB44czdMA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- hell에 해당되는 숫자 데이터 x_data, 'hell'에 해당되는 원-핫 인코딩 표현 x_one_hot, 그리고 'hell'에 대한 목표값 y_data에 대한 코드"
      ],
      "metadata": {
        "id": "-md3BUfYd3mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data=[[0,1,2,2]] #hell\n",
        "#batch_size=1\n",
        "x_one_hot = [[[1,0,0,0], #h\n",
        "             [0,1,0,0],#e\n",
        "             [0,0,1,0], #l\n",
        "             [0,0,1,0]]] #l\n",
        "y_data = [[1,2,2,3]] #ello"
      ],
      "metadata": {
        "id": "Su6JXN-XePa4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.RNN 함수에서 인자 결정\n",
        "    - input_size를 정한다. 여기서는 input_size=4\n",
        "    - hidden_size를 정하기 위해서는 nn.RNN함수에서 outputs의 형태를 고려해야한다.\n",
        "    - 출력이 하나는 outputs로 하고 다른 하나는 다음 타임 스텝에서 hidden_state로 들어가기 때문이다."
      ],
      "metadata": {
        "id": "QkzLiqLvej_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_set = ['h','e','l','o']\n",
        "input_size = len(char_set) #=4\n",
        "hidden_size = len(char_set) #=4\n",
        "num_layers=1"
      ],
      "metadata": {
        "id": "Q2FzOdS6e6Kq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 배열을 텐서로 변환\n"
      ],
      "metadata": {
        "id": "JIKIRsDce-6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transform as torch tensor\n",
        "inputs = torch.FloatTensor(x_one_hot)\n",
        "labels = torch.LongTensor(y_data)\n",
        "print('입력 데이터의 크기 : {}'.format(inputs.shape))\n",
        "print('레이블의 크기 : {}'.format(labels.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECcSHdOMe9dy",
        "outputId": "91fd2a69-6b84-4872-918c-9e9ecb328a0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 데이터의 크기 : torch.Size([1, 4, 4])\n",
            "레이블의 크기 : torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입력 데이터의 형태는 [1,4,4]는 (batch_size, sequence_length, input_size)이다."
      ],
      "metadata": {
        "id": "NEJWl4R9fULD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RNN 모델 생성\n",
        "    - batch_first이면, 입력 데이터의 크기는 (bacth_size, sequence_length, input_size) 순서가 된다."
      ],
      "metadata": {
        "id": "7OgdCV6BfJU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declare RNN\n",
        "#batch_first gruarantees the order=(batch_size,sequence_length,input_size)\n",
        "rnn = torch.nn.RNN(input_size, hidden_size,num_layers, batch_first=True) #batch_first guarantees the order of ouput = (B, S, F)\n",
        "print(rnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWX5HpC8fIYo",
        "outputId": "18ea7f63-e713-40e4-afee-e87ca9042326"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(4, 4, batch_first=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실함수와 최적화 방법 선택"
      ],
      "metadata": {
        "id": "oLd3X_VOgAkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "#loss & optimizer setting\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "Wlko4pf0fIa6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RNN 모델 학습"
      ],
      "metadata": {
        "id": "asVb7xHPgEGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  outputs, _ = rnn(inputs)\n",
        "  loss = loss_function(outputs.view(-1, input_size), labels.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  #print(outputs)\n",
        "  result = outputs.data.numpy().argmax(axis=2)\n",
        "  #print(result)\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  #print(result_str)\n",
        "  print('epoch=',i+1,',', \"loss: \", round(loss.item(),4),',', \"pred: \", result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX_FJr7qfIdB",
        "outputId": "9fd07218-521f-412f-ca53-b24b0c05c4fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch= 1 , loss:  1.7335 , pred:  hhhh\n",
            "epoch= 2 , loss:  1.3619 , pred:  holl\n",
            "epoch= 3 , loss:  1.1665 , pred:  ooll\n",
            "epoch= 4 , loss:  1.0635 , pred:  olll\n",
            "epoch= 5 , loss:  0.9962 , pred:  olll\n",
            "epoch= 6 , loss:  0.9314 , pred:  ooll\n",
            "epoch= 7 , loss:  0.8608 , pred:  eolo\n",
            "epoch= 8 , loss:  0.7983 , pred:  eolo\n",
            "epoch= 9 , loss:  0.7539 , pred:  eolo\n",
            "epoch= 10 , loss:  0.7072 , pred:  eolo\n",
            "epoch= 11 , loss:  0.6637 , pred:  eolo\n",
            "epoch= 12 , loss:  0.628 , pred:  eolo\n",
            "epoch= 13 , loss:  0.6 , pred:  eolo\n",
            "epoch= 14 , loss:  0.5782 , pred:  eolo\n",
            "epoch= 15 , loss:  0.5607 , pred:  eolo\n",
            "epoch= 16 , loss:  0.5463 , pred:  eolo\n",
            "epoch= 17 , loss:  0.5341 , pred:  eolo\n",
            "epoch= 18 , loss:  0.5238 , pred:  eolo\n",
            "epoch= 19 , loss:  0.5151 , pred:  eolo\n",
            "epoch= 20 , loss:  0.5077 , pred:  eolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "loss = loss_function(outputs.view(-1, input_size).labels.view(-1)\n",
        "```\n",
        "\n",
        "- nn.CrossEntropyLoss()함수를 사용하여 손실함수를 계산하는 경우 nn.CrossEntropyLoss()함수는 2개의 텐서 인자를 받는다.\n",
        "\n",
        "- 하나는 예측된 output값이고 다른 하나는 목표값이다. (인자들의 데이터 형태에 주의해야 한다, 그 이유는 데이터 형태가 서로 맞지 않은 경우 오류가 발생하기 때문이다.)\n",
        "\n",
        "- 현재 outputs.view(-1,input_size)의 형태는 [4,4]이고 y.view(-1)의 형태는 [4]이다. 이처럼 nn.CrossEntropyLoss()함수의 인자로서 outputs.view(-1, input_size)의 형태가 [4,?]인 경우 y.view(-1)의 형태는 [4]가 되어야 한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Upxm4B7hgmks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declare RNN\n",
        "#batch_first gruarantees the order=(batch_size,sequence_length,input_size)\n",
        "rnn = torch.nn.RNN(input_size, hidden_size,num_layers, batch_first=True) #batch_first guarantees the order of ouput = (B, S, F)\n",
        "outputs, _ = rnn(inputs)\n",
        "print(outputs.view(-1, input_size).shape)\n",
        "print(labels.view(-1).shape)\n",
        "\n",
        "#loss = loss_function(outputs.view(-1, input_size),label_view(-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Mu0ucyfIfO",
        "outputId": "c945b6a5-0726-491f-80ba-c2a9082fe805"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "result = outputs.data.numpy().argmax(axis=2)\n",
        "\n",
        "```\n",
        "- 최댓값이 있는 인덱스를 구하는 함수.\n",
        "    - 2차원 배열인 경우 axis=0이면 열, axis=1이면 행을 기준으로 계산.\n",
        "    - 3차원 배열인 경우 axis=1이면 열, axis=2이면 행을 기준으로 계산한다.\n",
        "    \n"
      ],
      "metadata": {
        "id": "JEWLaw81iEk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)\n",
        "result = outputs.data.numpy().argmax(axis=2)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4xhbNwDh8_n",
        "outputId": "daf6b835-ca60-4908-d621-ba7e0eac9033"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.5495, -0.3734, -0.0606, -0.5893],\n",
            "         [ 0.4305, -0.8899,  0.3382, -0.3102],\n",
            "         [ 0.3430, -0.6039,  0.4425, -0.1028],\n",
            "         [ 0.4783, -0.5452,  0.4491, -0.1519]]], grad_fn=<TransposeBackward1>)\n",
            "[[0 0 2 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- numpy.argmax()함수와 유사한 numpy.max()함수가 있다. 사용 예를 한번 봐보자."
      ],
      "metadata": {
        "id": "Vn7l3WYljT4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([[1,2,3,4],[4,5,6,7],[7,8,9,10]])\n",
        "print('array=\\n', arr)\n",
        "print('dimension',arr.ndim)\n",
        "print('argmax:', arr.argmax(axis=1))\n",
        "print('max:',arr.max(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxWL0zWkh9B5",
        "outputId": "5e0192aa-2bc7-4105-8baf-82ff45a59737"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array=\n",
            " [[ 1  2  3  4]\n",
            " [ 4  5  6  7]\n",
            " [ 7  8  9 10]]\n",
            "dimension 2\n",
            "argmax: [3 3 3]\n",
            "max: [ 4  7 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 3차원 배열에서 numpy.argmax()함수와 numpy.max()함수의 사용 예"
      ],
      "metadata": {
        "id": "_L5t74mFj9wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "arr = np.array([[[1,2,3,4],[4,5,6,7],[7,8,9,10]]])\n",
        "print('array=\\n', arr)\n",
        "print('dimension',arr.ndim)\n",
        "print('argmax:', arr.argmax(axis=2))\n",
        "print('max:',arr.max(axis=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4nIE6UJh9F9",
        "outputId": "6679ccb6-9e0b-45f6-e6bf-2833bdb3f7e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array=\n",
            " [[[ 1  2  3  4]\n",
            "  [ 4  5  6  7]\n",
            "  [ 7  8  9 10]]]\n",
            "dimension 3\n",
            "argmax: [[3 3 3]]\n",
            "max: [[ 4  7 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)\n",
        "print(np.squeeze(result))\n",
        "print([char_set[c] for c in np.squeeze(result)])\n",
        "result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "print(result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl-OlWXGh9Ib",
        "outputId": "b40fbd75-2656-49da-cc29-adfbd5addf2e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 2 0]]\n",
            "[0 0 2 0]\n",
            "['h', 'h', 'l', 'h']\n",
            "hhlh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word level language model\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "\n",
        "char_set = ['h','e','l','o']\n",
        "input_size = len(char_set) #=4\n",
        "hidden_size = len(char_set) #=4\n",
        "num_layers=1\n",
        "\n",
        "x_data=[[0,1,2,2]] #hell\n",
        "#batch_size=1\n",
        "x_one_hot = [[[1,0,0,0], #h\n",
        "             [0,1,0,0],#e\n",
        "             [0,0,1,0], #l\n",
        "             [0,0,1,0]]] #l\n",
        "y_data = [[1,2,2,3]] #ello\n",
        "\n",
        "#transform as torch tensor\n",
        "inputs = torch.FloatTensor(x_one_hot)\n",
        "labels = torch.LongTensor(y_data)\n",
        "print('입력 데이터의 크기 : {}'.format(inputs.shape))\n",
        "print('레이블의 크기 : {}'.format(labels.shape))\n",
        "\n",
        "#declare RNN\n",
        "#batch_first gruarantees the order=(batch_size,sequence_length,input_size)\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, batch_first=True) #batch_first guarantees the order of ouput = (B, S, F)\n",
        "\n",
        "#loss & optimizer setting\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=0.1)\n",
        "\n",
        "#start training\n",
        "\n",
        "for i in range(20):\n",
        "  outputs, _ = rnn(inputs)\n",
        "  loss = criterion(outputs.view(-1, input_size), labels.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  #print(outputs)\n",
        "  result = outputs.data.numpy().argmax(axis=2)\n",
        "  #print(result)\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  #print(result_str)\n",
        "  print('epoch=',i+1,',', \"loss: \", round(loss.item(),4),',', \"pred: \", result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NfAjJifhPzH",
        "outputId": "d7d62aba-619c-43c7-bd61-5d6d760ffaf0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 데이터의 크기 : torch.Size([1, 4, 4])\n",
            "레이블의 크기 : torch.Size([1, 4])\n",
            "epoch= 1 , loss:  1.1658 , pred:  elll\n",
            "epoch= 2 , loss:  0.9308 , pred:  llll\n",
            "epoch= 3 , loss:  0.816 , pred:  lllo\n",
            "epoch= 4 , loss:  0.7669 , pred:  lloo\n",
            "epoch= 5 , loss:  0.7018 , pred:  lllo\n",
            "epoch= 6 , loss:  0.6431 , pred:  ello\n",
            "epoch= 7 , loss:  0.5951 , pred:  ello\n",
            "epoch= 8 , loss:  0.5559 , pred:  ello\n",
            "epoch= 9 , loss:  0.5248 , pred:  ello\n",
            "epoch= 10 , loss:  0.5012 , pred:  ello\n",
            "epoch= 11 , loss:  0.4836 , pred:  ello\n",
            "epoch= 12 , loss:  0.469 , pred:  ello\n",
            "epoch= 13 , loss:  0.4572 , pred:  ello\n",
            "epoch= 14 , loss:  0.4503 , pred:  ello\n",
            "epoch= 15 , loss:  0.4463 , pred:  ello\n",
            "epoch= 16 , loss:  0.4414 , pred:  ello\n",
            "epoch= 17 , loss:  0.437 , pred:  ello\n",
            "epoch= 18 , loss:  0.4338 , pred:  ello\n",
            "epoch= 19 , loss:  0.4284 , pred:  ello\n",
            "epoch= 20 , loss:  0.4232 , pred:  ello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word level language model\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "\n",
        "#hyperparameters\n",
        "learning_rate=0.1\n",
        "num_epochs=20\n",
        "\n",
        "char_set = ['h','e','l','o']\n",
        "\n",
        "#Teach hello:hell->ello\n",
        "x_data=[[0,1,2,2]] #hell\n",
        "#batch_size=1\n",
        "x_one_hot = [[[1,0,0,0], #h\n",
        "             [0,1,0,0],#e\n",
        "             [0,0,1,0], #l\n",
        "             [0,0,1,0]]] #l\n",
        "y_data = [[1,2,2,3]] #ello\n",
        "\n",
        "#As we have one batch of samples, we will change them to variabels only once\n",
        "inputs = torch.Tensor(x_one_hot)\n",
        "labels = torch.LongTensor(y_data)\n",
        "num_classes = 4\n",
        "input_size=4 #one-hot size\n",
        "hidden_size=4 #output from the RNN. 4 to directly predict one-hot\n",
        "num_layers = 1\n",
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(RNN,self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size  = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size,num_classes)\n",
        "    def forward(self,x):\n",
        "        out, _ = self.rnn(x)\n",
        "        #Reshape output from (bacth, seq_len, hidden_size) to (batch*seq_len, hidden_size)\n",
        "        out = out.view(-1, self.hidden_size)\n",
        "        #Return outputs applied to fully connected layer\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "#Instantiate RNN Model\n",
        "rnn = RNN(num_classes, input_size, hidden_size, num_layers)\n",
        "#Set loss & optimizer  function\n",
        "loss_function = torch.nn.CrossEntropyLoss() #Softmax is internally computed.\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "\n",
        "#Tran the model\n",
        "for epoch in range(num_epochs):\n",
        "  outputs = rnn(inputs)\n",
        "  loss = loss_function(outputs, labels.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  result = outputs.data.numpy().argmax(axis=1)\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  print('epoch=',epoch+1,',', \"loss: \", round(loss.item(),4),',', \"pred =  \", ''.join(result_str)) #ello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnsO5yN1pmVi",
        "outputId": "34508b4b-eb5e-49ca-cd23-a9a90c3825d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch= 1 , loss:  1.688 , pred =   hhhh\n",
            "epoch= 2 , loss:  1.3476 , pred =   hlll\n",
            "epoch= 3 , loss:  1.1333 , pred =   llll\n",
            "epoch= 4 , loss:  1.0257 , pred =   llll\n",
            "epoch= 5 , loss:  0.9769 , pred =   llll\n",
            "epoch= 6 , loss:  0.931 , pred =   llll\n",
            "epoch= 7 , loss:  0.8573 , pred =   llll\n",
            "epoch= 8 , loss:  0.7595 , pred =   elll\n",
            "epoch= 9 , loss:  0.6604 , pred =   elll\n",
            "epoch= 10 , loss:  0.5792 , pred =   elll\n",
            "epoch= 11 , loss:  0.5104 , pred =   elll\n",
            "epoch= 12 , loss:  0.4391 , pred =   ello\n",
            "epoch= 13 , loss:  0.3983 , pred =   ello\n",
            "epoch= 14 , loss:  0.3603 , pred =   ello\n",
            "epoch= 15 , loss:  0.3088 , pred =   ello\n",
            "epoch= 16 , loss:  0.2781 , pred =   ello\n",
            "epoch= 17 , loss:  0.2522 , pred =   ello\n",
            "epoch= 18 , loss:  0.2101 , pred =   ello\n",
            "epoch= 19 , loss:  0.1761 , pred =   ello\n",
            "epoch= 20 , loss:  0.146 , pred =   ello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word level language model\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device', device)\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "\n",
        "#hyperparameters\n",
        "learning_rate=0.1\n",
        "num_epochs=20\n",
        "\n",
        "input_str = 'hell'\n",
        "label_str = 'ello'\n",
        "\n",
        "char_set = list(set(input_str+label_str))\n",
        "#print(char_set)\n",
        "#char_set = ['h','e','l','o']\n",
        "\n",
        "input_size = len(char_set) # RNN input size(one hot size)\n",
        "hidden_size = len(char_set) # RNN Output size\n",
        "num_classes = len(char_set) # final output size (RNN or softamx, etc.)\n",
        "num_layers = 1\n",
        "#batch_size = 1 #one sentence\n",
        "\n",
        "char_to_index = dict((c,i) for i,c in enumerate(char_set)) #문자에 고유한 정수 인덱스 부여\n",
        "#print(char_to_index)\n",
        "\n",
        "#1차원 리스트\n",
        "\n",
        "x_data = [char_to_index[c] for c in input_str]\n",
        "y_data = [char_to_index[c] for c in label_str]\n",
        "#print(x_data)\n",
        "#print(y_data)\n",
        "\n",
        "#2차원 리스트\n",
        "#텐서 연산인 unsqueeze(0)을 통해 해결할 수도 있었음.\n",
        "x_data = [x_data]\n",
        "y_data = [y_data]\n",
        "#print(x_data)\n",
        "#print(y_data)\n",
        "\n",
        "for x in x_data:\n",
        "    x_one_hot = [np.eye(input_size)[x]]\n",
        "#print(x_one_hot)\n",
        "#As we have one batch of samples, we will change them the variables only once\n",
        "inputs = torch.Tensor(x_one_hot)\n",
        "labels = torch.LongTensor(y_data)\n",
        "inputs = inputs.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(RNN,self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size  = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size,num_classes)\n",
        "    def forward(self,x):\n",
        "        out, _ = self.rnn(x)\n",
        "        #Reshape output from (bacth, seq_len, hidden_size) to (batch*seq_len, hidden_size)\n",
        "        out = out.view(-1, self.hidden_size)\n",
        "        #Return outputs applied to fully connected layer\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "#Instantiate RNN Model\n",
        "rnn = RNN(num_classes, input_size, hidden_size, num_layers).to(device)\n",
        "#Set loss & optimizer  function\n",
        "loss_function = torch.nn.CrossEntropyLoss() #Softmax is internally computed.\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "\n",
        "#Tran the model\n",
        "for epoch in range(num_epochs):\n",
        "  outputs = rnn(inputs)\n",
        "  loss = loss_function(outputs, labels.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  result = outputs.cpu().data.numpy().argmax(axis=1)\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  print('epoch=',epoch+1,',', \"loss: \", round(loss.item(),4),',', \"pred =  \", ''.join(result_str)) #ello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I0dCB8W844F",
        "outputId": "5d993b60-784b-45bd-f941-61c1ab6ed70c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n",
            "epoch= 1 , loss:  1.5918 , pred =   hhhh\n",
            "epoch= 2 , loss:  1.3025 , pred =   lllo\n",
            "epoch= 3 , loss:  1.0968 , pred =   lllo\n",
            "epoch= 4 , loss:  0.9535 , pred =   llll\n",
            "epoch= 5 , loss:  0.8296 , pred =   lllo\n",
            "epoch= 6 , loss:  0.7136 , pred =   lllo\n",
            "epoch= 7 , loss:  0.5841 , pred =   lllo\n",
            "epoch= 8 , loss:  0.4818 , pred =   ello\n",
            "epoch= 9 , loss:  0.379 , pred =   ello\n",
            "epoch= 10 , loss:  0.3062 , pred =   ello\n",
            "epoch= 11 , loss:  0.2396 , pred =   ello\n",
            "epoch= 12 , loss:  0.1799 , pred =   ello\n",
            "epoch= 13 , loss:  0.1348 , pred =   ello\n",
            "epoch= 14 , loss:  0.1039 , pred =   ello\n",
            "epoch= 15 , loss:  0.0822 , pred =   ello\n",
            "epoch= 16 , loss:  0.0657 , pred =   ello\n",
            "epoch= 17 , loss:  0.0524 , pred =   ello\n",
            "epoch= 18 , loss:  0.0421 , pred =   ello\n",
            "epoch= 19 , loss:  0.0341 , pred =   ello\n",
            "epoch= 20 , loss:  0.0281 , pred =   ello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Airline Passengers\n",
        "    - 1949년 1월부터 1960년 1`2월까지 매달 국제선 승객의 수에 대한 데이터."
      ],
      "metadata": {
        "id": "wpHxE9oSAXwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDDFrBWY_EVC",
        "outputId": "9dda1cf8-9959-47a5-ac22-0c2658e8a582"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-28 10:18:08--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2180 (2.1K) [text/plain]\n",
            "Saving to: ‘airline-passengers.csv’\n",
            "\n",
            "\rairline-passengers.   0%[                    ]       0  --.-KB/s               \rairline-passengers. 100%[===================>]   2.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-04-28 10:18:08 (38.2 MB/s) - ‘airline-passengers.csv’ saved [2180/2180]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load package\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "yMKb5VUB_bNK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data"
      ],
      "metadata": {
        "id": "GbnbZKMQAmOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = pd.read_csv('airline-passengers.csv')\n",
        "\n",
        "training_set = training_set.iloc[:,1:2].values\n",
        "\n",
        "plt.xlabel('month')\n",
        "plt.ylabel('number of passengers (1000s)')\n",
        "plt.plot(training_set)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "YndoWZ75_ejE",
        "outputId": "50743059-2085-4de2-a2ba-e774e3d68f9a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시계열 데이터이므로 몇 개의 타임스텝을 현재 시점에 반영할 것 인지 정합니다.\n",
        "\n",
        "- 즉, 현재 시점의 값은 지정한 시퀀스 길이에 맞게 직전 몇 개의 값과 연관되게끔 데이터를 재구성하는 것."
      ],
      "metadata": {
        "id": "VHa8BRzWApIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "training_data = sc.fit_transform(training_set)\n",
        "\n",
        "seq_length = 4\n",
        "x, y = sliding_windows(training_data, seq_length)\n",
        "\n",
        "train_size = int(len(y) * 0.30)\n",
        "test_size = len(y) - train_size\n",
        "\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY = Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))\n",
        "\n",
        "print(training_data.shape)\n",
        "print(dataX.shape)\n",
        "print(dataY.shape)\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxm0UhUW_gpT",
        "outputId": "869e5086-0ac3-4bca-f3c4-510e9e02aaae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144, 1)\n",
            "torch.Size([139, 4, 1])\n",
            "torch.Size([139, 1])\n",
            "torch.Size([41, 4, 1])\n",
            "torch.Size([41, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "이제는 시계열 데이터 모델링을 위한 LSTM 모델을 구현해줄 차례입니다. LSTM (Long Short-Term Memory) 는 입력 시퀀스의 타임 스텝 $t$에 따라 hidden state $h_t$, cell state $c_t$에 따른 출력을 Equation 1과 같이 계산합니다. Equation 1의 $i_t, f_t, g_t, o_t$는 각각 input, forget, cell, output 게이트이며 $\\sigma$는 sigmoid 함수를 말합니다.\n",
        "\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Savvas-Varsamopoulos/publication/329362532/figure/fig5/AS:699592479870977@1543807253596/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell_W640.jpg'>"
      ],
      "metadata": {
        "id": "LF469EGLEluP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch 에서는 torch.nn 모듈에서 LSTM 클래스를 쉽게 호출할 수 있습니다. LSTM 클래스 생성시 필요한 파라미터는 다음과 같습니다. \"num_layer\" 아규먼트를 통해 Multi-layer LSTM을 쉽게 구성할 수 있으며 \"num_layer\"가 2 이상일 경우, 타임스텝 $t$, layer $l$에 대한 입력으로는 ($x_t^l, l \\geq 2$) $h_t^{l-1}$에 dropout이 적용된 텐서가 적용됩니다."
      ],
      "metadata": {
        "id": "NXwe8LfHE7QP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- input_size : 입력 $x$의 feature차원\n",
        "- hidden_size : hidden_feature 차원\n",
        "- num_layers : LSTM 층의 개수로 2개 이상일 경우 bais항을 추가할지 말지를 결정.\n",
        "- bias : default : True / bais 항을 추가할지 말지를 결정.\n",
        "- batch_frist : default : False, True일 경우 입력, 출력 모두 [배치사이즈, 입력 길이, feature 차원] 으로 구성되고 fasle일 경우 입력, 출력 모두 [입력 길이, 배치 사이즈, feature 차원]이 됨. 이러한 텐서 차원 순서는 hidden/cell state에는 적용되지 않습니다.\n",
        "\n",
        "- dropout : 마지막 layer의 출력을 제외하고 dropout을 적용함."
      ],
      "metadata": {
        "id": "WDvsgu-HE9_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델을 사용할 때 주의할 점은 각 타임스텝 별로 hidden / cell state 가 업데이트되는 구조로 동작하기 때문에 초기 $h_0, c_0$를 목적에 맞게 선언해줄 수 있다는 점입니다 각각 [$D$*num_layers, 배치 사이즈, feature 차원] 크기로 되어있고 $D$는 bi-directional 일 경우 2, one-directional 일 경우 1이고 따로 제공되지 않을 경우 디폴트는 0으로 할당됩니다. 또한, 입력, 출력의 텐서 구조는 \"batch_first\" 아규먼트가 True / False 여부에 따라 배치 차원이 어디에 위치할지 결정됩니다. 일반적으로 배치 차원은 맨 앞에 있는 것이 편리하므로 \"batch_first=True\"로 설정하는 것이 낫습니다."
      ],
      "metadata": {
        "id": "w1ak0-VAFify"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델에 대해서 forward 함수를 진행할 경우 출력은 \"output, $(h_n, c_n)$\" 이 됩니다. 출력텐서는 (\"output\") \"batch_first\" 아규먼트에 따라 True일 경우 [배치 사이즈, 입력 길이, $D$*feature 차원] 으로 구성되며 각 타임스텝 $t$에 따른 마지막 LSTM layer의 $h_t$를 담습니다. $h_n, c_n$의 크기는 [$D$*num_layers, 배치 사이즈, feature 차원] 으로 구성되며 마지막 타임스텝의 hidden / cell state가 담깁니다"
      ],
      "metadata": {
        "id": "gQ28VbwNFkVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "\n",
        "        c_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "\n",
        "        # Propagate input through LSTM\n",
        "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "\n",
        "        out = self.fc(h_out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "PAWhp2zS_jGb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- $h_0, c_0$는 hidden / cell state의 초기값이기 때문에 requires_grad=False로 설정된 zero 텐서를 넣어줍니다.\n",
        "- 현재 시퀀스 길이는 4이고 마지막 시퀀스에 대해 fully-connected layer를 달아주고 싶기 때문에 $h_n$에 대하여 fully-connected layer를 진행시킵니다.\n",
        "LSTM 모델의 결과로 나오는 \"output\"의 마지막 타임스텝 값은 $h_n$과 같습니다."
      ],
      "metadata": {
        "id": "UOWzQjtcFrDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "rlucDaDxFt6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
        "\n",
        "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = lstm(trainX)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # obtain the loss function\n",
        "    loss = criterion(outputs, trainY)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_ojB7mZ_k_5",
        "outputId": "7616a95e-193f-4414-f368-453ab9d30368"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.10901\n",
            "Epoch: 100, loss: 0.00304\n",
            "Epoch: 200, loss: 0.00215\n",
            "Epoch: 300, loss: 0.00123\n",
            "Epoch: 400, loss: 0.00105\n",
            "Epoch: 500, loss: 0.00102\n",
            "Epoch: 600, loss: 0.00100\n",
            "Epoch: 700, loss: 0.00097\n",
            "Epoch: 800, loss: 0.00094\n",
            "Epoch: 900, loss: 0.00091\n",
            "Epoch: 1000, loss: 0.00088\n",
            "Epoch: 1100, loss: 0.00086\n",
            "Epoch: 1200, loss: 0.00085\n",
            "Epoch: 1300, loss: 0.00084\n",
            "Epoch: 1400, loss: 0.00084\n",
            "Epoch: 1500, loss: 0.00084\n",
            "Epoch: 1600, loss: 0.00083\n",
            "Epoch: 1700, loss: 0.00083\n",
            "Epoch: 1800, loss: 0.00083\n",
            "Epoch: 1900, loss: 0.00083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test\n",
        "\n",
        "- 테스트 진행 시에는 전에 선언했던 \"MinMaxScaler\" 객체의 \"inverse_transform\" 함수를 이용하여 원래 데이터 값으로 복원시킵니다."
      ],
      "metadata": {
        "id": "AwdXg9AcFwKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm.eval()\n",
        "\n",
        "# predict on training and test data\n",
        "all_predict = lstm(dataX)\n",
        "\n",
        "data_predict = all_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "\n",
        "data_predict = sc.inverse_transform(data_predict)\n",
        "dataY_plot = sc.inverse_transform(dataY_plot)\n",
        "\n",
        "plt.axvline(x=train_size, c='r', linestyle='--', label='right limit of GT used')\n",
        "\n",
        "plt.plot(dataY_plot, label='GT')\n",
        "plt.plot(data_predict, label='predictions')\n",
        "plt.suptitle('Time-Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "rtPLQwLlAIdB",
        "outputId": "7e5ee306-51d1-4e8d-ddfd-8e83a25a60df"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 참고) https://hongl.tistory.com/194\n",
        "\n"
      ],
      "metadata": {
        "id": "mW-0hr_HF5Ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torchtext는 자연어 처리(NLP)분야에서 사용되는 dataloader, torchtext는 파일 가져오기, 토큰화, 단어 집합, 생성, 인코딩, 단어 벡터 생성 등의 작업을 지원하기 때문에 자연어 처리에서 많이 사용되고 있음."
      ],
      "metadata": {
        "id": "sg7Z6ivWOAST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BddcGwARc8Kj",
        "outputId": "15af1b98-09c0-4491-a38f-d20fd83126ba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.4\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (2.32.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.4) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.4) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.4) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchtext==0.4)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchtext==0.4) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchtext==0.4) (3.0.2)\n",
            "Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchtext-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import datasets, data # 자연어 데이터셋을 다루기 위해 토치비전이 아닌 토치 텍스트를 사용합니다.\n",
        "\n",
        "# 하이퍼파라미터 정의\n",
        "BATCH_SIZE = 64\n",
        "lr = 0.001\n",
        "EPOCHS = 10\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfK_vS5COQbH",
        "outputId": "8f78e6ce-7dfe-4fd2-f3af-cafe44d30b4e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로딩하기\n",
        "# 텍스트 형태의 영화 리뷰들과 그에 해당하는 리뷰들을 텐서로 바꿔주기\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "# sequential = True : 데이터셋이 순차적인 데이터셋임을 명시\n",
        "# batch_first = True : 신경망에 입력되는 텐서의 첫 번째 차원값을 batch size로 지정\n",
        "# lower = True : 텍스트 데이터 속 모든 영문 알파벳이 소문자가 되도록 처리\n",
        "LABEL = data.Field(sequential=False, batch_first=True) #Label은 순차적 데이터가 아님\n",
        "trainset, testset = datasets.IMDB.splits(TEXT, LABEL) # train test 분리\n",
        "TEXT.build_vocab(trainset, min_freq=5) # 워드 임베딩에 필요한 단어 사전(word vocabulary) 만들기\n",
        "# min_freq = 5 : 학습 데이터에서 최소 5번 이상 등장한 단어만을 사전에 담음\n",
        "LABEL.build_vocab(trainset)\n",
        "\n",
        "# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n",
        "trainset, valset = trainset.split(split_ratio=0.8)\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
        "        shuffle=True, repeat=False)\n",
        "\n",
        "\n",
        "vocab_size = len(TEXT.vocab) #사전 속 단어들의 개수와 레이블 수 지정\n",
        "n_classes = 2\n",
        "\n",
        "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
        "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHWzoJsmc66j",
        "outputId": "ad944497-e808-4d20-9195-fc6e9122c0ce"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:25<00:00, 3.32MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RNN의 입력이 길어지면 기울기(경사도) 폭발(gradient explosion) 혹은 기울기(경사도) 소실(vanishing gradient)이 발생 가능합니다\n",
        "- 이러한 단점이 보완된 것이 GRU(Gated Recurrent Unit)로, GRU는 시계열 데이터 속 벡터 사이의 정보 전달량을 조절함으로써 기울기를 적정하게 유지하고 문장 앞부분의 정보가 끝까지 도달할 수 있도록 돕습니다.\n",
        "GRU에는 시계열 데이터 내 정보 전달량을 조절하는 업데이트 게이트(update gate)와 리셋 게이트(reset gate)라는 개념이 존재합니다.\n",
        "- 리셋 게이트는 새로운 입력이 이전 은닉 벡터와 어떻게 조합하는지를 결정합니다."
      ],
      "metadata": {
        "id": "mA9St5BKfJlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN 모델 구현\n",
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()\n",
        "        print(\"Building Basic GRU model...\")\n",
        "        self.n_layers = n_layers # 은닉 벡터들의 '층'이라고 할 수 있는 n_layers를 정의합니다.(보통 2이하로 정의)\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        # n_vocab : 전체 데이터셋의 모든 단어를 사전형태로 나타냈을 때 그 사전에 등재된 단어 수\n",
        "        # embed_dim : 임베딩된 단어 텐서가 지니는 차원 값\n",
        "        self.hidden_dim = hidden_dim # 은닉 벡터(hidden vector)의 차원값과 드롭아웃을 정의합니다.\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True) #위의 이유로 GRU를 사용합니다.\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes) # 압축된 텐서를 신경망에 통과시켜 예측을 출력합니다.\n",
        "\n",
        "    def forward(self, x): # 입력되는 x는 한 배치 속에 있는 모든 영화평입니다.\n",
        "        x = self.embed(x) # 워드 임베딩하면 시계열 데이터(벡터의 배열)로 변환됩니다.\n",
        "        h_0 = self._init_state(batch_size=x.size(0)) #첫 번쨰 은닉 벡터 H0를 정의해 x와 함께 입력해줍니다.\n",
        "        x, _ = self.gru(x, h_0)  # [i, b, h]\n",
        "        h_t = x[:,-1,:] # 영호 리뷰 배열들을 압축한 은닉벡터입니다.\n",
        "        self.dropout(h_t)\n",
        "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        # parameters() 함수는 신경망 모듈의 가중치 형태를 반복자(iterator) 형태를 반환합니다.\n",
        "        # 즉 weight는 nn.GRU 모듈의 첫 번째 가중치 텐서를 말합니다.\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "metadata": {
        "id": "4tIizRUrdVEg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습함수와 평가함수 구현\n",
        "\n",
        "#학습함수\n",
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter): # 반복마다 배치 데이터를 반환합니다.\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1)  # 1과 2의 레이블 값을 모든 값에서 1씩 빼서 0과 1로 변환\n",
        "        optimizer.zero_grad() # 매번 기울기를 새로 계산\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step() #오차를 구하고 최적화 반복\n",
        "\n",
        "#평가함수\n",
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum') #오차의 합 구하기\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy #오찻값과 정확도의 평균 반환"
      ],
      "metadata": {
        "id": "uPVzsqVglQZb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 객체 정의\n",
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
        "# 모델 내 은닉벡터의 차원값 = 256, 임베딩된 토큰의 차원값 = 128로 임의 설정\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr) # 최적화 알고리즘으로 Adam 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VroAwrm4lRsv",
        "outputId": "67038631-8065-423c-92b3-72398d25959d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Basic GRU model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#검증오차(val_loss) 최소화된 모델 저장\n",
        "best_val_loss = None\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, train_iter)\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"snapshot\"):\n",
        "            os.makedirs(\"snapshot\")\n",
        "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
        "        best_val_loss = val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ndINDmWlSrz",
        "outputId": "31b6b357-dc3c-4c92-eb16-cfdaf2da381f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[이폭: 1] 검증 오차: 0.69 | 검증 정확도:51.74\n",
            "[이폭: 2] 검증 오차: 0.70 | 검증 정확도:49.06\n",
            "[이폭: 3] 검증 오차: 0.63 | 검증 정확도:65.36\n",
            "[이폭: 4] 검증 오차: 0.34 | 검증 정확도:85.32\n",
            "[이폭: 5] 검증 오차: 0.31 | 검증 정확도:87.66\n",
            "[이폭: 6] 검증 오차: 0.32 | 검증 정확도:87.54\n",
            "[이폭: 7] 검증 오차: 0.36 | 검증 정확도:86.88\n",
            "[이폭: 8] 검증 오차: 0.41 | 검증 정확도:86.66\n",
            "[이폭: 9] 검증 오차: 0.41 | 검증 정확도:87.98\n",
            "[이폭: 10] 검증 오차: 0.42 | 검증 정확도:87.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증셋에서 가장 성능이 좋았던 모델을 불러와 테스트\n",
        "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iter)\n",
        "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwkRKKIjlT6C",
        "outputId": "2ecf5b4a-e164-46ac-a6d5-daa1e423b05a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 오차:  0.31 | 테스트 정확도: 86.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seq2Seq 기계 번역\n",
        "  - 2010년 이후 인공지능에서 가장 큰 관심을 받은 건 알파고지만, 그와 더불어 크게 화제가 된 머신러닝 모델이 언어를 다른 언어로 해석해주는 뉴럴 기계 번역(Neural Machine Translation)모델입니다.\n",
        "  - RNN 기반의 번역 모델인 Sequence to Sequence (줄여서 Seq2Seq) 모델은 기계 번역의 새로운 패러다임을 열었다고 할 정도로 뛰어난 성능을 보여줬습니다.\n",
        "  - Seq2Seq 모델은 시퀀스(Sequence)를 입력받아 또 다른 시퀀스를 출력합니다. 한마디로 문장을 다른 문장으로 번역해주는 모델입니다.\n",
        "  - 일반적으로 Seq2Seq와 같은 기계 번역 모델이 이러한 능력을 학습하려면 흔히 병렬 말뭉치(parallel corpora)라고 하는 원문과 번역문이 쌍을 이루는 형태의 많은 텍스트 데이터가 필요합니다. 따라서 이런 모델을 제대로 학습시키려면 당연히 강력한 GPU, 복잡한 텍스트 전처리 과정, 긴 학습시간 등 많은 리소스가 됩니다.\n",
        "\n",
        "\n",
        "따라서, 이번 예제에서는 Seq2Seq 모델을 아주 간소화하여 한 언어의 문장을 다른 언어의 문장으로 번역하는 덩치 큰 모델이 아닌, 영어 알파벳 문자열 \"hello\"를 스페인어 알파벳 문자열 \"hola\"로 번역하는 미니 Seq2Seq 모델을 구현해보겠습니다.\n",
        "\n",
        "#### 개요\n",
        "- Seq2Seq는 각자 다른 역할을 하는 두 개의 RNN을 이어붙인 모델입니다.\n",
        "- 번역은 1. 원문을 이해하고, 2. 번역문을 작성하는 두 가지 동작으로 구성되는데, Seq2Seq 모델에서 이 두 역할을 각각 - 인코더(encoder)와 디코더(decoder)라는 두 RNN에 부여함으로써 번역합니다.\n",
        "- 인코더는 원문 속의 모든 단어를 입력받아 문장의 뜻을 내포하는 고정 크기의 텐서를 만들어냅니다. 이렇게 압축된 텐서는 원문의 뜻과 내용을 압축하고 있다고 하여 문맥 벡터(context vector)라고 합니다. 인코더 RNN은 원문 속의 토큰을 차례대로 입력받습니다. 원문 마지막 토큰에 해당하는 은닉 벡터는 원문의 뜻을 모두 내포하는 문맥 벡터입니다.\n",
        "- 디코더 또한 RNN 모델로, 인코더에서 원문 문맥 벡터를 이어받아 번역문 속의 토큰을 차례대로 예상합니다. 번역할 때 '원문이 말하는 바가 무엇인가'를 항상 생각하고 있어야 합니다. 이는 디코더가 번역문의 단어나 토큰을 출력할 때 인코더로부터 정보를 전달받아야 한 다는 뜻이기도 합니다."
      ],
      "metadata": {
        "id": "9R_8fHXnli9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델구현하기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "GLjL3l1zlhqd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 한 언어로 된 문장을 다른 언어로 번역하는 작업을 할 때는 보통 단어를 문장의 최소단위로 여겨 단어 단위의 임베딩(word embedding)을 하지만 이번 예제에선 간단한 영단어 \"hello\"를 스페인어 \"hola\"로 번역하는 작업을 할 것이므로 이번 예제에서는 단어 단위의 워드 임베딩이 아닌 글자 단위의 캐릭터 임베딩(Character embedding)을 사용하겠습니다."
      ],
      "metadata": {
        "id": "bC-4uejNp4Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 256  # 총 아스키 코드 개수 (아스키 코드: 영문을 숫자로 변환하는 방식)\n",
        "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
        "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
        "print(\"hello -> \", x_)\n",
        "print(\"hola  -> \", y_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Y-pNaUp29K",
        "outputId": "4838df01-3f0a-4b09-d4fa-4ec597a9111a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello ->  [104, 101, 108, 108, 111]\n",
            "hola  ->  [104, 111, 108, 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아스키 코드 리스트를 파이토치 텐서로 변환\n",
        "x = torch.LongTensor(x_)\n",
        "y = torch.LongTensor(y_)"
      ],
      "metadata": {
        "id": "Sqg9MYxIp6IY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seq2Seq 모델 클래스 정의\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.n_layers = 1\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size) # hidden_size가 임베딩된 토큰의 차원값\n",
        "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
        "        self.decoder = nn.GRU(hidden_size, hidden_size) # encoder와 decoder 객체는 GRU\n",
        "        self.project = nn.Linear(hidden_size, vocab_size) # 번역문의 다음 토큰을 예상해내는 신경망\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # 인코더에 들어갈 입력\n",
        "        initial_state = self._init_state()\n",
        "        embedding = self.embedding(inputs).unsqueeze(1)\n",
        "        # embedding = [seq_len, batch_size, embedding_size]\n",
        "\n",
        "        # 인코더 (Encoder)\n",
        "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
        "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
        "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
        "\n",
        "        # 디코더에 들어갈 입력\n",
        "        decoder_state = encoder_state # 원문을 인코더에 입력시킨 문맥벡터 : encoder_state , 디코더의 첫 번째 은닉벡터 : decoder_state\n",
        "        decoder_input = torch.LongTensor([0]) # 0 : 아스키값의 공백 문자(null)를 뜻함\n",
        "\n",
        "        # 디코더 (Decoder)\n",
        "        outputs = []\n",
        "\n",
        "        for i in range(targets.size()[0]): #\"hola\"의 \"h\" 다음에 올 문자가 \"o\"임을 예측하기 위한 for 반복문\n",
        "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
        "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
        "            projection = self.project(decoder_output)\n",
        "            outputs.append(projection) # 디코더의 출력값으로 다음 글자 예측하기\n",
        "\n",
        "            # 티처 포싱(Teacher Forcing) 사용\n",
        "            # 티처 포싱: 디코더 학습시 실제 번역문의 토큰을 디코더의 전 출력값 대신 입력으로 사용해 학습을 가속하는 방법\n",
        "            decoder_input = torch.LongTensor([targets[i]])\n",
        "\n",
        "        outputs = torch.stack(outputs).squeeze() # 번역문의 모든 토큰에 대한 결괏값들의 배열\n",
        "        return outputs\n",
        "\n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
      ],
      "metadata": {
        "id": "am_yNVBJp7SS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq(vocab_size, 16)\n",
        "criterion = nn.CrossEntropyLoss() # 교차 엔트로피 오차를 구하는 CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3) # 최적화 알고리즘"
      ],
      "metadata": {
        "id": "HkrolagJp8_w"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1000번의 이폭에 걸쳐 모델 학습\n",
        "log = []\n",
        "for i in range(1000):\n",
        "    prediction = seq2seq(x, y)\n",
        "    loss = criterion(prediction, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_val = loss.data\n",
        "    log.append(loss_val)\n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
        "        _, top1 = prediction.data.topk(1, 1)\n",
        "        print([chr(c) for c in top1.squeeze().numpy().tolist()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDlPtSy4p9zo",
        "outputId": "74f303f2-8bba-4cb8-a2f3-175f2510a05f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 반복:0 오차: 5.368366718292236\n",
            "['P', '\\n', 'Ï', '_']\n",
            "\n",
            " 반복:100 오차: 2.0385162830352783\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:200 오차: 0.5287455320358276\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:300 오차: 0.2605275511741638\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:400 오차: 0.16916725039482117\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:500 오차: 0.12286531180143356\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:600 오차: 0.09478230029344559\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:700 오차: 0.07595538347959518\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:800 오차: 0.06248652935028076\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:900 오차: 0.052407462149858475\n",
            "['h', 'o', 'l', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 맷플롯립을 통한 오차가 줄어드는 모습 확인\n",
        "plt.plot(log)\n",
        "plt.ylabel('cross entropy loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vTGf4qq2p-40",
        "outputId": "0940cde5-6d97-41a8-be96-af53548c544a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMDB를 활용한 RNN 구현"
      ],
      "metadata": {
        "id": "4FBroRgvIgoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "wETUPqYhqKxj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Field는 데이터 전처리를 위해 사용되며 여기에서 사용되는 파라미터는 다음과 같습니다.\n",
        "\n",
        "```\n",
        "torchtext.data.Field(lower=True, fix_length=200, batch_first=False)\n",
        "```\n",
        "\n",
        "- lower : 대문자를 모두 소문자로 변경. 기본값은 False\n",
        "- fix_length : 고정된 길이의 데이터를 얻을 수 있음. 여기에서는 데이터의 길이를 200으로 고정했으며, 200보다 짧으면 패딩 작업(padding)을 통해 200으로 맞추어줌.\n",
        "\n",
        "- batch_frist : 신경망에 입력되는 텐서의 첫번째 차원 값이 배치 크기(batch_size)가 되도록 합니다. 기본값은 false.\n",
        "\n",
        "- 모델의 네트워크로 입력되는 데이터는 [시퀀스 길이, 배치 크기, 은닉층의 뉴런 개수]([seq_len, batch_size, hidden_size]) 형태.\n",
        "  - batch_size = True로 설정하면 [배치크기, 시퀀스 길이, 은닉층뉴런 개수] ([batch_size, seq_len, hidden_size]) 형태로 변경.\n",
        "  - batch_size = True와 무관하게, [은닉층 개수, 배치 크기, 은닉층의 뉴런 개수] (num_layers, batch, hidden_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "vw7Rg-SHIjs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "TEXT = torchtext.data.Field(lower=True, fix_length=200, batch_first=False)\n",
        "LABEL =torchtext.data.Field(sequential=False)"
      ],
      "metadata": {
        "id": "98Vw7Th_H9E7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "torchtext.data.Field(sequential=False)\n",
        "```\n",
        "\n",
        "seqential : 데이터에 순서(sequenatial)이 있는지를 나타냄.\n",
        "\n"
      ],
      "metadata": {
        "id": "0FVJ70Z6LyxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "metadata": {
        "id": "weU0PzVKJ2zs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- split : 텍스트(text)와 레이블(label)로 분할."
      ],
      "metadata": {
        "id": "xD_Uk_wjL9Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKA_KB9CJ8cW",
        "outputId": "6dd56ee7-6302-4ae0-db17-87b9cbba780c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['i', 'first', 'saw', 'this', 'movie', 'back', 'in', 'the', 'early', \"'90's\", 'when', 'it', 'was', 'first', 'released.', 'room', 'with', 'a', 'view', 'was', 'also', 'newly', 'out.', 'enchanted', 'april', 'had', 'so', 'much', 'more', 'to', 'offer!', 'i', 'found', 'it', 'much', 'more', 'real', 'and', 'earthy,', 'the', 'characters', 'more', 'believable', 'for', 'being', \"'normal'.\", 'by', 'the', 'end', 'of', 'the', 'film', 'i', 'felt', 'the', 'same', 'as', 'i', 'did', 'when', 'i', 'first', 'saw', 'the', 'bbc', 'production', 'of', 'pride', 'and', 'prejudice,', 'i', 'was', 'yearning', 'for', 'the', 'characters', 'to', 'find', 'what', 'they', 'were', 'looking', 'for', 'whether', 'it', 'was', 'isolation,', 'peace,', 'liberty', 'or', 'love.', 'you', 'get', 'a', 'sense', 'throughout', 'that', 'italy', 'is', 'so', 'far', 'removed', 'from', 'everything', 'they', 'have', 'ever', 'known,', 'that', 'they', 'are', 'so', 'decadent', 'for', 'taking', 'a', 'risk', 'and', 'leaving', 'behind', 'all', 'that', 'is', 'humdrum', 'and', 'constricting.', 'but', 'in', 'the', 'heat', 'of', 'the', 'spring', 'in', 'april,', \"everyone's\", 'lives', 'loosen', 'and', 'unravel', '(in', 'line', 'with', 'the', 'victorian', 'corsets)', 'and', 'are', 'slowly', 'rebuilt', 'to', \"everyone's\", 'satisfaction.', 'what', 'a', 'little', 'gem', 'of', 'a', 'film!', 'how', 'come', 'it', \"isn't\", 'more', 'well', 'known?'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- text와 label을 갖는 사전 형식(dict type)으로 구성되어 있음."
      ],
      "metadata": {
        "id": "0WdHUzgzMH1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "for example in train_data.examples:\n",
        "    text = [x.lower() for x in vars(example)['text']]\n",
        "    text = [x.replace(\"<br\",\"\") for x in text]\n",
        "    text = [''.join(c for c in s if c not in string.punctuation) for s in text]\n",
        "    text = [s for s in text if s]\n",
        "    vars(example)['text'] = text\n",
        "\n",
        "for example in test_data.examples:\n",
        "    text = [x.lower() for x in vars(example)['text']]\n",
        "    text = [x.replace(\"<br\",\"\") for x in text]\n",
        "    text = [''.join(c for c in s if c not in string.punctuation) for s in text]\n",
        "    text = [s for s in text if s]\n",
        "    vars(example)['text'] = text"
      ],
      "metadata": {
        "id": "36k5zfDZH-PK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전처리 코드를 진행. 공백처리, 불필요한 문자 제거 등이 포함됨."
      ],
      "metadata": {
        "id": "wDN9rwH5SZN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(0), split_ratio=0.8)"
      ],
      "metadata": {
        "id": "SvOfXcXlKQwQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh2AMGIiKRmb",
        "outputId": "f31209b1-a5c9-4bdd-c43c-509474e4e4a2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단어 집합을 만들어 보겠습니다.\n",
        "  - IMDB 데이터셋에 포함된 단어들을 이용하여 하나의 딕셔너리와 같은 집합을 만드는 것으로 이해하자.\n",
        "  - 단어 집합을 만들 때, 단어들의 중복은 제거된 상태에서 진행합니다."
      ],
      "metadata": {
        "id": "pEA01fsISlWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doxRmhuBKSnI",
        "outputId": "2f4ec66e-f1d8-4838-91a4-5ce3b65ba6ae"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 10002\n",
            "Unique tokens in LABEL vocabulary: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "```\n",
        "\n",
        "- train_data : 훈련 데이터셋\n",
        "- max_size : 단어 집합의 크기로 단어 집합에 포함되는 어휘 수\n",
        "- min_freq : 훈련 데이터셋에서 특정 단어의 최소 등장 횟수\n",
        "- vectors : 임베딩 벡터를 지정할 수 있음. 임베딩 벡터는 워드 임베딩의 결과로 나온 벡터. / pytorch에서도 nn.embedding()을 통해 단어를 랜덤한 숫자 값으로 변환한 후 가중치를 학습하는 방법을 제공함.\n",
        "\n"
      ],
      "metadata": {
        "id": "lcC8KiXpUx_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MCkkZc0KUI1",
        "outputId": "7aaf4b63-a46e-410b-f864-ff2e9b34b401"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7949c97c4ed0>>, {'<unk>': 0, 'pos': 1, 'neg': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "embeding_dim = 100\n",
        "hidden_size = 300\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "E3-2vXfGKVTe"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BucketIterator : dataloader와 쓰임새가 같습니다.\n",
        "  - 즉, 배치 크기 단위로 값을 차례대로 꺼내어 메모리로 가져오고 싶을 때 사용.\n",
        "  - Field에서 fix_length를 사용하지 않았다면, BuckIterator에서 데이터의 길이를 조정할 수 있음.\n",
        "  - BucketIterator는 비슷한 길이의 데이터를 한 배치에 할당하여 패딩(Padding)을 최소화시켜줌."
      ],
      "metadata": {
        "id": "q7rQZw20SGXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.embedding()을 이용하여 임베딩 처리를 진행해 보자."
      ],
      "metadata": {
        "id": "0-kDxMukXALx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCell_Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_size):\n",
        "        super(RNNCell_Encoder, self).__init__()\n",
        "        self.rnn = nn.RNNCell(input_dim, hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        bz = inputs.shape[1]\n",
        "        ht = torch.zeros((bz, hidden_size)).to(device)\n",
        "\n",
        "        for word in inputs:\n",
        "            ht = self.rnn(word, ht) #재귀적으로 발생하는 상태 값을 처리하기 위한 구문.\n",
        "        return ht\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.em = nn.Embedding(len(TEXT.vocab.stoi), embeding_dim)\n",
        "        self.rnn = RNNCell_Encoder(embeding_dim, hidden_size)\n",
        "        self.fc1 = nn.Linear(hidden_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.em(x)\n",
        "        x = self.rnn(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kYe84moVKWfZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "Z7kPNEUBKZrt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(epoch, model, trainloader, validloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for b in trainloader:\n",
        "        x, y = b.text, b.label\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            correct += (y_pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            running_loss += loss.item()\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    valid_correct = 0\n",
        "    valid_total = 0\n",
        "    valid_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for b in validloader:\n",
        "            x, y = b.text, b.label\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            valid_correct += (y_pred == y).sum().item()\n",
        "            valid_total += y.size(0)\n",
        "            valid_running_loss += loss.item()\n",
        "\n",
        "    epoch_valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    epoch_valid_acc = valid_correct / valid_total\n",
        "\n",
        "    print('epoch: ', epoch,\n",
        "          'loss： ', round(epoch_loss, 3),\n",
        "          'accuracy:', round(epoch_acc, 3),\n",
        "          'valid_loss： ', round(epoch_valid_loss, 3),\n",
        "          'valid_accuracy:', round(epoch_valid_acc, 3)\n",
        "          )\n",
        "    return epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc"
      ],
      "metadata": {
        "id": "uzlJoePbKaxV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc = training(epoch, model,train_iterator,valid_iterator)\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    valid_loss.append(epoch_valid_loss)\n",
        "    valid_acc.append(epoch_valid_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhyqFYhkKcId",
        "outputId": "d16815cb-7b02-44a0-8b4e-7ea799d9147a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss：  0.011 accuracy: 0.495 valid_loss：  0.011 valid_accuracy: 0.507\n",
            "epoch:  1 loss：  0.011 accuracy: 0.505 valid_loss：  0.011 valid_accuracy: 0.491\n",
            "epoch:  2 loss：  0.011 accuracy: 0.511 valid_loss：  0.011 valid_accuracy: 0.493\n",
            "epoch:  3 loss：  0.011 accuracy: 0.517 valid_loss：  0.011 valid_accuracy: 0.492\n",
            "epoch:  4 loss：  0.011 accuracy: 0.526 valid_loss：  0.011 valid_accuracy: 0.513\n",
            "143.09658360481262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(epoch, model, testloader):\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    test_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for b in testloader:\n",
        "            x, y = b.text, b.label\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            test_correct += (y_pred == y).sum().item()\n",
        "            test_total += y.size(0)\n",
        "            test_running_loss += loss.item()\n",
        "\n",
        "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
        "    epoch_test_acc = test_correct / test_total\n",
        "\n",
        "    print('epoch: ', epoch,\n",
        "          'test_loss： ', round(epoch_test_loss, 3),\n",
        "          'test_accuracy:', round(epoch_test_acc, 3)\n",
        "          )\n",
        "    return epoch_test_loss, epoch_test_acc"
      ],
      "metadata": {
        "id": "FUAYoRKpKdO4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_test_loss, epoch_test_acc = evaluate(epoch,\n",
        "                                               model,\n",
        "                                               test_iterator)\n",
        "    test_loss.append(epoch_test_loss)\n",
        "    test_acc.append(epoch_test_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3qz4-NVKhD8",
        "outputId": "2adceb59-4eab-4aad-dcf5-1a715e81f5a7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 test_loss：  0.011 test_accuracy: 0.503\n",
            "epoch:  1 test_loss：  0.011 test_accuracy: 0.503\n",
            "epoch:  2 test_loss：  0.011 test_accuracy: 0.503\n",
            "epoch:  3 test_loss：  0.011 test_accuracy: 0.503\n",
            "epoch:  4 test_loss：  0.011 test_accuracy: 0.503\n",
            "180.21351718902588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN 계층적 구현\n",
        "  - 미세한 차이만 있다."
      ],
      "metadata": {
        "id": "GWXBOYIniGac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOEHPO_qiGIj",
        "outputId": "64f9add5-61e5-4c38-ff1b-2db9e363147f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.4 in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (2.32.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtext==0.4) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.4) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.4) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.4) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.4) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchtext==0.4) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchtext==0.4) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "nga0nPUoh-uq"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "TEXT = torchtext.data.Field(sequential = True, batch_first = True, lower = True)\n",
        "LABEL = torchtext.data.Field(sequential = False, batch_first = True)"
      ],
      "metadata": {
        "id": "WaFIDhSrh-ur"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(split_ratio = 0.8)\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "y5Lc4kR9h-ur"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "zxZkMhByKiN6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  vocab_size : 영화 리뷰에 대한 텍스트 길이,\n",
        "- n_classes : 레이블(긍정,부정)값을 지정.\n"
      ],
      "metadata": {
        "id": "uK2NpFTyFC69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 2"
      ],
      "metadata": {
        "id": "xDguuSMDiXJu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True)\n",
        "```\n",
        "\n",
        "- embed_dim : 훈련 데이터셋의 특성(feature) 개수(칼럼 갯수)\n",
        "- self.hidden_dim : 은닉 계층의 뉴런(유닛) 개수\n",
        "- num_layers : RNN 계층의 갯수\n",
        "- batch_first : 기본값은 Flase, 입력 데이터의 형태는 (시퀀스의 길이, 배치 크기, 특성 개수)입니다. True로 설정하게 되면, 배치 크기가 맨 앞으로 오게 되며, (배치 크기, 시퀀스의 길이, 특성 개수) 형태가 됨.\n",
        "\n"
      ],
      "metadata": {
        "id": "rbmCOnGMFMoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicRNN(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p = 0.2):\n",
        "        super(BasicRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True)\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        h_0 = self._init_state(batch_size = x.size(0))\n",
        "        x, _ = self.rnn(x, h_0)\n",
        "        h_t = x[:, -1, :]\n",
        "        self.dropout(h_t)\n",
        "        logit = torch.sigmoid(self.out(h_t))\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size = 1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "metadata": {
        "id": "sx2L1GKMiYHS"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicRNN(n_layers = 1, hidden_dim = 256, n_vocab = vocab_size, embed_dim = 128, n_classes = n_classes, dropout_p = 0.5)\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "CF2QJzZliZip"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1) #뺄셈에 대한 함수, 함수명에 '_'이 붙은 것은 inplace 연산을 하겠다는 의미.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if b % 50 == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(e,\n",
        "                                                                           b * len(x),\n",
        "                                                                           len(train_iter.dataset),\n",
        "                                                                           100. * b / len(train_iter),\n",
        "                                                                           loss.item()))"
      ],
      "metadata": {
        "id": "PH-xClRjial8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):\n",
        "    model.eval()\n",
        "    corrects, total, total_loss = 0, 0, 0\n",
        "\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1)\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction = \"sum\")\n",
        "        total += y.size(0)\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "\n",
        "    avg_loss = total_loss / len(val_iter.dataset)\n",
        "    avg_accuracy = corrects / total\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "R0DOkS20ib6w"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "```\n",
        "\n",
        "- max(1)[1] : max(dim=0)[0]은 최댓값을 나타내고, max(dim=0)[1] 최댓값을 갖는 데이터의 인덱스를 나타냄.\n",
        "\n",
        "- view(y.size()) : logit.max(1)[1] 결과는 y.size() 크기로 변경.\n",
        "\n",
        "-  data == y.data : 모델의 예측 결과(logit.max(1)[1].view(y.size()).data)가 레이블(실제값, y.data)과 같은지 확인함.\n",
        "\n",
        "- sum() : 모델의 예측 결과와 레이블(실제값)이 같으면 그 합을 corrects 변수에 누적하여 저장.\n",
        "\n"
      ],
      "metadata": {
        "id": "p-czhLgsIAHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "LR = 0.001\n",
        "EPOCHS = 5\n",
        "for e in range(1, EPOCHS + 1):\n",
        "    train(model, optimizer, train_iterator)\n",
        "    val_loss, val_accuracy = evaluate(model, valid_iterator)\n",
        "    print(\"[EPOCH: %d], Validation Loss: %5.2f | Validation Accuracy: %5.2f\" % (e, val_loss, val_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENNLsqNAizp4",
        "outputId": "b29ebd96-b948-4ac6-f742-40537c69d15a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.689679\n",
            "Train Epoch: 1 [5000/20000 (25%)]\tLoss: 0.693213\n",
            "Train Epoch: 1 [10000/20000 (50%)]\tLoss: 0.692673\n",
            "Train Epoch: 1 [15000/20000 (75%)]\tLoss: 0.699511\n",
            "[EPOCH: 1], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 2 [0/20000 (0%)]\tLoss: 0.694023\n",
            "Train Epoch: 2 [5000/20000 (25%)]\tLoss: 0.693710\n",
            "Train Epoch: 2 [10000/20000 (50%)]\tLoss: 0.692330\n",
            "Train Epoch: 2 [15000/20000 (75%)]\tLoss: 0.697187\n",
            "[EPOCH: 2], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 3 [0/20000 (0%)]\tLoss: 0.695271\n",
            "Train Epoch: 3 [5000/20000 (25%)]\tLoss: 0.692572\n",
            "Train Epoch: 3 [10000/20000 (50%)]\tLoss: 0.693820\n",
            "Train Epoch: 3 [15000/20000 (75%)]\tLoss: 0.691675\n",
            "[EPOCH: 3], Validation Loss:  0.69 | Validation Accuracy:  0.50\n",
            "Train Epoch: 4 [0/20000 (0%)]\tLoss: 0.687956\n",
            "Train Epoch: 4 [5000/20000 (25%)]\tLoss: 0.693896\n",
            "Train Epoch: 4 [10000/20000 (50%)]\tLoss: 0.693210\n",
            "Train Epoch: 4 [15000/20000 (75%)]\tLoss: 0.694819\n",
            "[EPOCH: 4], Validation Loss:  0.69 | Validation Accuracy:  0.51\n",
            "Train Epoch: 5 [0/20000 (0%)]\tLoss: 0.694675\n",
            "Train Epoch: 5 [5000/20000 (25%)]\tLoss: 0.694057\n",
            "Train Epoch: 5 [10000/20000 (50%)]\tLoss: 0.691674\n",
            "Train Epoch: 5 [15000/20000 (75%)]\tLoss: 0.687596\n",
            "[EPOCH: 5], Validation Loss:  0.69 | Validation Accuracy:  0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_iterator)\n",
        "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sTC-oPIi09f",
        "outputId": "f91c2f99-7e12-4283-9f8a-ed03545f138f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  0.69 | Test Accuracy:  0.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "S9fE7q6XtBuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "이제는 시계열 데이터 모델링을 위한 LSTM 모델을 구현해줄 차례입니다. LSTM (Long Short-Term Memory) 는 입력 시퀀스의 타임 스텝 $t$에 따라 hidden state $h_t$, cell state $c_t$에 따른 출력을 Equation 1과 같이 계산합니다. Equation 1의 $i_t, f_t, g_t, o_t$는 각각 input, forget, cell, output 게이트이며 $\\sigma$는 sigmoid 함수를 말합니다.\n",
        "\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Savvas-Varsamopoulos/publication/329362532/figure/fig5/AS:699592479870977@1543807253596/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell_W640.jpg'>"
      ],
      "metadata": {
        "id": "OgJkYMA2s_Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch 에서는 torch.nn 모듈에서 LSTM 클래스를 쉽게 호출할 수 있습니다. LSTM 클래스 생성시 필요한 파라미터는 다음과 같습니다. \"num_layer\" 아규먼트를 통해 Multi-layer LSTM을 쉽게 구성할 수 있으며 \"num_layer\"가 2 이상일 경우, 타임스텝 $t$, layer $l$에 대한 입력으로는 ($x_t^l, l \\geq 2$) $h_t^{l-1}$에 dropout이 적용된 텐서가 적용됩니다."
      ],
      "metadata": {
        "id": "af3WBW9ss_Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- input_size : 입력 $x$의 feature차원\n",
        "- hidden_size : hidden_feature 차원\n",
        "- num_layers : LSTM 층의 개수로 2개 이상일 경우 bais항을 추가할지 말지를 결정.\n",
        "- bias : default : True / bais 항을 추가할지 말지를 결정.\n",
        "- batch_frist : default : False, True일 경우 입력, 출력 모두 [배치사이즈, 입력 길이, feature 차원] 으로 구성되고 fasle일 경우 입력, 출력 모두 [입력 길이, 배치 사이즈, feature 차원]이 됨. 이러한 텐서 차원 순서는 hidden/cell state에는 적용되지 않습니다.\n",
        "\n",
        "- dropout : 마지막 layer의 출력을 제외하고 dropout을 적용함."
      ],
      "metadata": {
        "id": "lJPD1XUUs_Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델을 사용할 때 주의할 점은 각 타임스텝 별로 hidden / cell state 가 업데이트되는 구조로 동작하기 때문에 초기 $h_0, c_0$를 목적에 맞게 선언해줄 수 있다는 점입니다 각각 [$D$*num_layers, 배치 사이즈, feature 차원] 크기로 되어있고 $D$는 bi-directional 일 경우 2, one-directional 일 경우 1이고 따로 제공되지 않을 경우 디폴트는 0으로 할당됩니다. 또한, 입력, 출력의 텐서 구조는 \"batch_first\" 아규먼트가 True / False 여부에 따라 배치 차원이 어디에 위치할지 결정됩니다. 일반적으로 배치 차원은 맨 앞에 있는 것이 편리하므로 \"batch_first=True\"로 설정하는 것이 낫습니다."
      ],
      "metadata": {
        "id": "cnJ76ua0s_Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델에 대해서 forward 함수를 진행할 경우 출력은 \"output, $(h_n, c_n)$\" 이 됩니다. 출력텐서는 (\"output\") \"batch_first\" 아규먼트에 따라 True일 경우 [배치 사이즈, 입력 길이, $D$*feature 차원] 으로 구성되며 각 타임스텝 $t$에 따른 마지막 LSTM layer의 $h_t$를 담습니다. $h_n, c_n$의 크기는 [$D$*num_layers, 배치 사이즈, feature 차원] 으로 구성되며 마지막 타임스텝의 hidden / cell state가 담깁니다"
      ],
      "metadata": {
        "id": "oOFXcaz4s_Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "torch.manual_seed(125)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(125)"
      ],
      "metadata": {
        "id": "jdfSgebLi2sX"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (1.0,))\n",
        "])"
      ],
      "metadata": {
        "id": "D_b9HrkVtH7h"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "\n",
        "download_root = 'MNIST_DATASET/'\n",
        "\n",
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
        "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwXDHfmxtJMo",
        "outputId": "5c8da52e-f68d-4802-c393-54ae22640f88"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 339kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.17MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.90MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "valid_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)"
      ],
      "metadata": {
        "id": "O0TcL6idtKwa"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_iters = 6000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)"
      ],
      "metadata": {
        "id": "O9YiAekFtNgy"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
        "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        hx, cx = hidden\n",
        "        x = x.view(-1, x.size(1))\n",
        "\n",
        "        gates = self.x2h(x) + self.h2h(hx)\n",
        "        gates = gates.squeeze()\n",
        "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
        "\n",
        "        ingate = F.sigmoid(ingate)\n",
        "        forgetgate = F.sigmoid(forgetgate)\n",
        "        cellgate = F.tanh(cellgate)\n",
        "        outgate = F.sigmoid(outgate)\n",
        "\n",
        "        cy = torch.mul(cx, forgetgate) +  torch.mul(ingate, cellgate)\n",
        "        hy = torch.mul(outgate, F.tanh(cy))\n",
        "        return (hy, cy)"
      ],
      "metadata": {
        "id": "cxgdq3UutO96"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
        "self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
        "```\n",
        "\n",
        "- 왜 4 *hidden_size가 사용되고 있을까요?\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Savvas-Varsamopoulos/publication/329362532/figure/fig5/AS:699592479870977@1543807253596/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell_W640.jpg'>\n",
        "\n",
        "- 게이트는 망각, 입력, 셀, 출력으로 구성되어 있다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "99u8MltLXM2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh)\n",
        "```\n",
        "\n",
        "앞의 F.linear\n",
        "- input : 입력층으로 입력되는 훈련 데이터셋의 특성(feature) 수(Column 수)\n",
        "- w_ih : 입력층과 은닉층 사이의 가중치\n",
        "- b_ih : 입력층과 은닉층 사이의 바이어스\n",
        "\n",
        "뒤의 F.linear\n",
        "- hx : 은닉층의 뉴런/유닛 개수(은닉층의 특성(feature) 개수)\n",
        "- w_hh : 은닉층과 은닉층 사이의 가중치\n",
        "- b_hh : 은닉층과 은닉층 사이의 바이어스\n",
        "\n"
      ],
      "metadata": {
        "id": "U6Bx0ZP6e_87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.layer_dim = layer_dim\n",
        "        self.lstm = LSTMCell(input_dim, hidden_dim, layer_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if torch.cuda.is_available():\n",
        "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
        "        else:\n",
        "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
        "        else:\n",
        "            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), hidden_dim))\n",
        "\n",
        "        outs = []\n",
        "        cn = c0[0,:,:]\n",
        "        hn = h0[0,:,:]\n",
        "\n",
        "        for seq in range(x.size(1)):\n",
        "            hn, cn = self.lstm(x[:,seq,:], (hn,cn))\n",
        "            outs.append(hn)\n",
        "\n",
        "        out = outs[-1].squeeze()\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "otDX0Sg3tQku"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28\n",
        "hidden_dim = 128\n",
        "layer_dim = 1\n",
        "output_dim = 10\n",
        "\n",
        "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "F3Hm4lUdtSH-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_dim = 28\n",
        "loss_list = []\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
        "            labels = Variable(labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            loss.cuda()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_list.append(loss.item())\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in valid_loader:\n",
        "                if torch.cuda.is_available():\n",
        "                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "                else:\n",
        "                    images = Variable(images.view(-1 , seq_dim, input_dim))\n",
        "\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                total += labels.size(0)\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB7Y0aNgtTxd",
        "outputId": "40975404-69c2-4160-b008-6132322770d2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 2.237457275390625. Accuracy: 21.420000076293945\n",
            "Iteration: 1000. Loss: 0.9968994855880737. Accuracy: 74.94999694824219\n",
            "Iteration: 1500. Loss: 0.42673957347869873. Accuracy: 88.13999938964844\n",
            "Iteration: 2000. Loss: 0.30981600284576416. Accuracy: 93.56999969482422\n",
            "Iteration: 2500. Loss: 0.0558248832821846. Accuracy: 95.69000244140625\n",
            "Iteration: 3000. Loss: 0.09873700886964798. Accuracy: 95.58000183105469\n",
            "Iteration: 3500. Loss: 0.08254366368055344. Accuracy: 96.8499984741211\n",
            "Iteration: 4000. Loss: 0.03308983892202377. Accuracy: 97.08000183105469\n",
            "Iteration: 4500. Loss: 0.049307383596897125. Accuracy: 97.08000183105469\n",
            "Iteration: 5000. Loss: 0.08068697154521942. Accuracy: 96.69999694824219\n",
            "Iteration: 5500. Loss: 0.12790139019489288. Accuracy: 97.30999755859375\n",
            "Iteration: 6000. Loss: 0.007093742024153471. Accuracy: 97.66000366210938\n",
            "Iteration: 6500. Loss: 0.011727366596460342. Accuracy: 97.63999938964844\n",
            "Iteration: 7000. Loss: 0.008610538206994534. Accuracy: 98.06999969482422\n",
            "Iteration: 7500. Loss: 0.027341270819306374. Accuracy: 97.8499984741211\n",
            "Iteration: 8000. Loss: 0.10305538773536682. Accuracy: 97.5199966430664\n",
            "Iteration: 8500. Loss: 0.007204337045550346. Accuracy: 98.13999938964844\n",
            "Iteration: 9000. Loss: 0.012087937444448471. Accuracy: 97.4800033569336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):\n",
        "    corrects, total, total_loss = 0, 0, 0\n",
        "    model.eval()\n",
        "    for images, labels in val_iter:\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "        else:\n",
        "            images = Variable(images.view(-1 , seq_dim, input_dim)).to(device)\n",
        "        labels = labels.cuda()\n",
        "        logit = model(images).cuda()\n",
        "        loss = F.cross_entropy(logit, labels, reduction = \"sum\")\n",
        "        _, predicted = torch.max(logit.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_loss += loss.item()\n",
        "        corrects += (predicted == labels).sum()\n",
        "\n",
        "    avg_loss = total_loss / len(val_iter.dataset)\n",
        "    avg_accuracy = corrects / total\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "9nHnoUXCtVto"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_loader)\n",
        "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mslJge22tXVr",
        "outputId": "3b370bd8-fe50-4f12-fdc7-be559c5a1847"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  0.07 | Test Accuracy:  0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU\n",
        "- GRU는 기존 LSTM의 구조를 조금 더 간단하게 개선한 모델입니다. 그리고 모델의 대략적인 구조와 수식은 아래와 같습니다.\n",
        "\n",
        "-   LSTM의 경우 forget gate, input gate, output gate 3개의 gate가 있었지만, GRU에서는 reset gate, update gate 2개의 gate만을 사용합니다. 또한 cell state, hidden state가 합쳐져 하나의 hidden state로 표현하고 있습니다.\n",
        "  - Reset Gate : 이전 시점의 hidden state와 현 시점의 x를 활성화함수 시그모이드를 적용하여 구하는 방식입니다. 결과값은 0~1 사이의 값을 가질 것이며 이전 hidden state의 값을 얼마나 활용할 것인지에 대한 정보로 해석할 수 있을 것입니다.\n",
        "  \n",
        "  - Update Gate : STM의 input, forget gate와 비슷한 역할을 하며 과거와 현재의 정보를 각각 얼마나 반영할지에 대한 비율을 구하는 것이 핵심\n",
        "\n",
        "-  GRU는 기존 LSTM에 비해 더 간단한 구조를 가지고 있습니다. 그리고 마지막 출력값에 활성화함수를 적용하지 않습니다. 성능 면에서는 LSTM과 비교해서 우월하다고 할 수 없지만 학습할 파라미터가 더 적은 것이 장점이라고 할 수 있습니다.|\n",
        "\n"
      ],
      "metadata": {
        "id": "65tB5Qd4hKtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png'>"
      ],
      "metadata": {
        "id": "j2KXqqrbkviK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "torch.manual_seed(125)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(125)"
      ],
      "metadata": {
        "id": "W_hfO9mmtYg4"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (1.0,))\n",
        "])"
      ],
      "metadata": {
        "id": "arBOcbYihMf8"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "download_root = 'MNIST_DATASET/'\n",
        "\n",
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
        "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
      ],
      "metadata": {
        "id": "h_bY-X-_hN2J"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "valid_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)"
      ],
      "metadata": {
        "id": "4Hs6ERyUhO4z"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_iters = 6000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)"
      ],
      "metadata": {
        "id": "wXfGvneRhP4r"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        self.x2h = nn.Linear(input_size, 3 * hidden_size, bias=bias)\n",
        "        self.h2h = nn.Linear(hidden_size, 3 * hidden_size, bias=bias)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.view(-1, x.size(1))\n",
        "\n",
        "        gate_x = self.x2h(x)\n",
        "        gate_h = self.h2h(hidden)\n",
        "\n",
        "        gate_x = gate_x.squeeze()\n",
        "        gate_h = gate_h.squeeze()\n",
        "\n",
        "        i_r, i_i, i_n = gate_x.chunk(3, 1)\n",
        "        h_r, h_i, h_n = gate_h.chunk(3, 1)\n",
        "\n",
        "        resetgate = F.sigmoid(i_r + h_r)\n",
        "        inputgate = F.sigmoid(i_i + h_i)\n",
        "        newgate = F.tanh(i_n + (resetgate * h_n))\n",
        "\n",
        "        hy = newgate + inputgate * (hidden - newgate)\n",
        "        return hy"
      ],
      "metadata": {
        "id": "_QaO-ZSFhQxw"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "        self.gru_cell = GRUCell(input_dim, hidden_dim, layer_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if torch.cuda.is_available():\n",
        "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
        "        else:\n",
        "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
        "\n",
        "        outs = []\n",
        "        hn = h0[0,:,:]\n",
        "\n",
        "        for seq in range(x.size(1)):\n",
        "            hn = self.gru_cell(x[:,seq,:], hn)\n",
        "            outs.append(hn)\n",
        "\n",
        "        out = outs[-1].squeeze()\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "wwtDLzE-hSlJ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28\n",
        "hidden_dim = 128\n",
        "layer_dim = 1\n",
        "output_dim = 10\n",
        "\n",
        "model = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "EXroob8EhTvV"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_dim = 28\n",
        "loss_list = []\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
        "            labels = Variable(labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            loss.cuda()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in valid_loader:\n",
        "                if torch.cuda.is_available():\n",
        "                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "                else:\n",
        "                    images = Variable(images.view(-1 , seq_dim, input_dim))\n",
        "\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_HqceMahU_6",
        "outputId": "a09e50c7-ee78-49d9-9650-194ffa245559"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 1.6616928577423096. Accuracy: 43.59000015258789\n",
            "Iteration: 1000. Loss: 0.8945668339729309. Accuracy: 76.19999694824219\n",
            "Iteration: 1500. Loss: 0.29147759079933167. Accuracy: 89.7300033569336\n",
            "Iteration: 2000. Loss: 0.23627927899360657. Accuracy: 93.51000213623047\n",
            "Iteration: 2500. Loss: 0.03288726136088371. Accuracy: 95.05000305175781\n",
            "Iteration: 3000. Loss: 0.030374974012374878. Accuracy: 95.81999969482422\n",
            "Iteration: 3500. Loss: 0.16210567951202393. Accuracy: 96.33999633789062\n",
            "Iteration: 4000. Loss: 0.19308766722679138. Accuracy: 96.19000244140625\n",
            "Iteration: 4500. Loss: 0.051720067858695984. Accuracy: 97.0\n",
            "Iteration: 5000. Loss: 0.13900163769721985. Accuracy: 97.26000213623047\n",
            "Iteration: 5500. Loss: 0.08090294152498245. Accuracy: 97.62000274658203\n",
            "Iteration: 6000. Loss: 0.10488356649875641. Accuracy: 97.69000244140625\n",
            "Iteration: 6500. Loss: 0.07984025031328201. Accuracy: 97.80000305175781\n",
            "Iteration: 7000. Loss: 0.10250380635261536. Accuracy: 97.55999755859375\n",
            "Iteration: 7500. Loss: 0.0647798627614975. Accuracy: 97.86000061035156\n",
            "Iteration: 8000. Loss: 0.10547610372304916. Accuracy: 97.80000305175781\n",
            "Iteration: 8500. Loss: 0.04281146451830864. Accuracy: 98.0199966430664\n",
            "Iteration: 9000. Loss: 0.041988763958215714. Accuracy: 98.22000122070312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):\n",
        "    corrects, total, total_loss = 0, 0, 0\n",
        "    model.eval()\n",
        "    for images, labels in val_iter:\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "        else:\n",
        "            images = Variable(images.view(-1 , seq_dim, input_dim)).to(device)\n",
        "        labels = labels.cuda()\n",
        "        logit = model(images).cuda()\n",
        "        loss = F.cross_entropy(logit, labels, reduction = \"sum\")\n",
        "        _, predicted = torch.max(logit.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_loss += loss.item()\n",
        "        corrects += (predicted == labels).sum()\n",
        "\n",
        "    avg_loss = total_loss / len(val_iter.dataset)\n",
        "    avg_accuracy = corrects / total\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "S22NKeLEhWgA"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_loader)\n",
        "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js2_cE7ThYBD",
        "outputId": "f75b5123-5d73-4db5-8119-06682385e77b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  0.07 | Test Accuracy:  0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer\n"
      ],
      "metadata": {
        "id": "1oOiIPki8O6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer 참고 : https://cpm0722.github.io/pytorch-implementation/transformer"
      ],
      "metadata": {
        "id": "hfN-Q9iekHGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "# Positional Encoding: 위치 정보를 추가해줌\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
        "        self.register_buffer('pe', pe)  # 학습하지 않는 매개변수로 등록\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "\n",
        "#  Scaled Dot-Product Attention: 핵심 attention 계산\n",
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "    d_k = q.size(-1)\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "    attn = torch.softmax(scores, dim=-1)\n",
        "    output = torch.matmul(attn, v)\n",
        "    return output, attn\n",
        "\n",
        "#  Multi-Head Attention: 여러 개의 attention head\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        batch_size = q.size(0)\n",
        "\n",
        "        # Linear projection + reshape\n",
        "        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1,2)\n",
        "\n",
        "        # Apply scaled dot-product attention\n",
        "        output, attn = scaled_dot_product_attention(q, k, v, mask)\n",
        "\n",
        "        # Concatenate heads\n",
        "        output = output.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
        "\n",
        "        # Final linear layer\n",
        "        output = self.out(output)\n",
        "        return output\n",
        "\n",
        "#  Position-wise Feed Forward\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(torch.relu(self.fc1(x)))\n",
        "\n",
        "#  Encoder Layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask=None):\n",
        "        # Self Attention + Add & Norm\n",
        "        src2 = self.self_attn(src, src, src, src_mask)\n",
        "        src = self.norm1(src + self.dropout1(src2))\n",
        "        # Feed Forward + Add & Norm\n",
        "        src2 = self.feed_forward(src)\n",
        "        src = self.norm2(src + self.dropout2(src2))\n",
        "        return src\n",
        "\n",
        "#  Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
        "        # Masked Self Attention\n",
        "        tgt2 = self.self_attn(tgt, tgt, tgt, tgt_mask)\n",
        "        tgt = self.norm1(tgt + self.dropout1(tgt2))\n",
        "        # Cross Attention (Decoder attends to Encoder output)\n",
        "        tgt2 = self.cross_attn(tgt, memory, memory, memory_mask)\n",
        "        tgt = self.norm2(tgt + self.dropout2(tgt2))\n",
        "        # Feed Forward\n",
        "        tgt2 = self.feed_forward(tgt)\n",
        "        tgt = self.norm3(tgt + self.dropout3(tgt2))\n",
        "        return tgt\n",
        "\n",
        "#  Full Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask=None):\n",
        "        src = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)\n",
        "        src = self.pos_encoder(src)\n",
        "        src = self.dropout(src)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        return src\n",
        "\n",
        "#  Full Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.embedding.embedding_dim)\n",
        "        tgt = self.pos_encoder(tgt)\n",
        "        tgt = self.dropout(tgt)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            tgt = layer(tgt, memory, tgt_mask, memory_mask)\n",
        "\n",
        "        return tgt\n",
        "\n",
        "#  Transformer (Encoder + Decoder)\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_layers=6, num_heads=8, d_ff=2048, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, num_layers, num_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(tgt_vocab_size, d_model, num_layers, num_heads, d_ff, dropout)\n",
        "        self.out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, memory_mask=None):\n",
        "        memory = self.encoder(src, src_mask)\n",
        "        output = self.decoder(tgt, memory, tgt_mask, memory_mask)\n",
        "        output = self.out(output)\n",
        "        return output\n",
        "\n",
        "# Mask 생성 함수 (디코더용)\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
        "    return mask == 0\n"
      ],
      "metadata": {
        "id": "dUNOUme3kJH9"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tiny 번역 시스템"
      ],
      "metadata": {
        "id": "9k3OAB2f90Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단한 source-target 데이터\n",
        "src_sentences = ['hello', 'world', 'hello world']\n",
        "tgt_sentences = ['안녕', '세계', '안녕 세계']"
      ],
      "metadata": {
        "id": "6rbHJCs591Z1"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vocab 만들기"
      ],
      "metadata": {
        "id": "1BW0EDJV9268"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    vocab = {'<pad>': 0, '<sos>':1, '<eos>':2}\n",
        "    idx = 3\n",
        "    for sent in sentences:\n",
        "        for word in sent.split():\n",
        "            if word not in vocab:\n",
        "                vocab[word] = idx\n",
        "                idx += 1\n",
        "    return vocab\n",
        "\n",
        "src_vocab = build_vocab(src_sentences)\n",
        "tgt_vocab = build_vocab(tgt_sentences)\n",
        "\n",
        "print(src_vocab)\n",
        "print(tgt_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvHxWuak92Ym",
        "outputId": "6c3a914b-1a22-499f-f2a8-c3970567d46c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, '<sos>': 1, '<eos>': 2, 'hello': 3, 'world': 4}\n",
            "{'<pad>': 0, '<sos>': 1, '<eos>': 2, '안녕': 3, '세계': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 숫자 인덱스 변환"
      ],
      "metadata": {
        "id": "kCkhZyBi96GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sentence, vocab):\n",
        "    return [vocab['<sos>']] + [vocab[word] for word in sentence.split()] + [vocab['<eos>']]\n",
        "\n",
        "src_data = [encode_sentence(sent, src_vocab) for sent in src_sentences]\n",
        "tgt_data = [encode_sentence(sent, tgt_vocab) for sent in tgt_sentences]\n",
        "\n",
        "print(src_data)\n",
        "print(tgt_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btXb5RF_9454",
        "outputId": "24175d62-8ec6-45e1-ff9f-3e3bbbdeb6ce"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 3, 2], [1, 4, 2], [1, 3, 4, 2]]\n",
            "[[1, 3, 2], [1, 4, 2], [1, 3, 4, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "패딩과 텐서 변환"
      ],
      "metadata": {
        "id": "XxpT_Nrr-A0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sequences, pad_idx):\n",
        "    max_len = max(len(seq) for seq in sequences)\n",
        "    return [seq + [pad_idx]*(max_len - len(seq)) for seq in sequences]\n",
        "\n",
        "src_padded = pad_sequences(src_data, src_vocab['<pad>'])\n",
        "tgt_padded = pad_sequences(tgt_data, tgt_vocab['<pad>'])\n",
        "\n",
        "src_input = torch.LongTensor(src_padded)\n",
        "tgt_input = torch.LongTensor(tgt_padded)\n",
        "\n",
        "print(src_input.shape)\n",
        "print(tgt_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4vPkFYf974W",
        "outputId": "467af00f-7e2f-47d7-80cc-b7e22094d54c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- transformer 모델 생성"
      ],
      "metadata": {
        "id": "AaaaFjZw-FAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_VOCAB_SIZE = len(src_vocab)\n",
        "TGT_VOCAB_SIZE = len(tgt_vocab)\n",
        "D_MODEL = 32\n",
        "N_HEADS = 4\n",
        "N_LAYERS = 2\n",
        "D_FF = 128\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = Transformer(\n",
        "    src_vocab_size=SRC_VOCAB_SIZE,\n",
        "    tgt_vocab_size=TGT_VOCAB_SIZE,\n",
        "    d_model=D_MODEL,\n",
        "    num_layers=N_LAYERS,\n",
        "    num_heads=N_HEADS,\n",
        "    d_ff=D_FF,\n",
        "    dropout=DROPOUT\n",
        ").to('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "j3cAcV_Y-CNX"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Optimzer, Loss 정의"
      ],
      "metadata": {
        "id": "Bj5p355h-Kiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=src_vocab['<pad>'])"
      ],
      "metadata": {
        "id": "oXOM3gb6-G-R"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- training"
      ],
      "metadata": {
        "id": "-DLta6DM-eZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "src_input = src_input.to(device)\n",
        "tgt_input = tgt_input.to(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "\n",
        "    # 타겟은 디코더 입력과 타겟 분리\n",
        "    tgt_input_seq = tgt_input[:, :-1]\n",
        "    tgt_output_seq = tgt_input[:, 1:]\n",
        "\n",
        "    # 마스크 생성\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_input_seq.size(1)).to(device)\n",
        "\n",
        "    output = model(src_input, tgt_input_seq, tgt_mask=tgt_mask)\n",
        "    output = output.view(-1, TGT_VOCAB_SIZE)\n",
        "    tgt_output_seq = tgt_output_seq.contiguous().view(-1)\n",
        "\n",
        "    loss = criterion(output, tgt_output_seq)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print(f'Epoch {epoch+1}, Loss {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck_5KEY_-ctS",
        "outputId": "91016fef-e04e-4f24-ae74-c825ea9db987"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss 1.2287\n",
            "Epoch 10, Loss 0.8478\n",
            "Epoch 15, Loss 0.7316\n",
            "Epoch 20, Loss 0.5541\n",
            "Epoch 25, Loss 0.5207\n",
            "Epoch 30, Loss 0.4034\n",
            "Epoch 35, Loss 0.2546\n",
            "Epoch 40, Loss 0.1678\n",
            "Epoch 45, Loss 0.1583\n",
            "Epoch 50, Loss 0.0988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pkNsac0w__hz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}