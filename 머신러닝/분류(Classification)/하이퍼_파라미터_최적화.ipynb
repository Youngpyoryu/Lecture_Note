{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# iris_data를 xgboost로 적용을 해보자."
      ],
      "metadata": {
        "id": "-XgDYosabhoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#Loading iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "#independent feautres\n",
        "X = iris.data\n",
        "\n",
        "# target features\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "APzk3M3Hbklu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import XGboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#Defining XGB Classification model\n",
        "clf = XGBClassifier()"
      ],
      "metadata": {
        "id": "YH_KPRdnbklw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- xgboost의 단점은 복잡한 하이퍼 파라미터가 있다."
      ],
      "metadata": {
        "id": "v7wfVSY2bro4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Grid SearchCV\n",
        "- 사용자가 하이퍼 파라미터마다 몇가지 값을 가진 리스트를 입력하면, 가능한 하이퍼 파라미터의 경우의 수마다 예측 성능을 측정하여 사용자가 일일이 하이퍼 파라미터를 설정하고, 예측 성능을 비교하여 최적의 파라미터를 찾는 수고를 줄이고 이 과정을 한꺼번에 진행한다."
      ],
      "metadata": {
        "id": "bjRTeDOlburH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing packages from sklearn\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "#defining a set of values as a dictionary for hyperparameters\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\":[100,200,300,400],\n",
        "    \"max_depth\":[1,3,5,7],\n",
        "    \"reg_lambda\":[.01,.1,.5]    \n",
        "}\n",
        "\n",
        "#declaring GridSearchCV model\n",
        "\n",
        "model = model_selection.GridSearchCV(\n",
        "    estimator = clf,\n",
        "    param_grid = param_grid,\n",
        "    scoring = 'accuracy',\n",
        "    verbose = 10,\n",
        "    n_jobs = 1,\n",
        "    cv = 5    \n",
        ")\n",
        "\n",
        "#fitting values to the gridsearchcv model\n",
        "\n",
        "model.fit(X,y)\n",
        "#printing the best possible values to enhance accuracy\n",
        "print(model.best_params_)\n",
        "print(model.best_estimator_)\n",
        "#printing the best score\n",
        "print(model.best_score_)"
      ],
      "metadata": {
        "id": "TsJr9ua1bwty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. RandomizedSearchCV\n",
        "\n",
        "- 그리드 서치에서는 grid_param과 같이 매개변수마다 특정 값을 지정해주었습니다. 만약에 변수 범위가 너무 다양하다면 하나하나 작성해주는게 너무 힘들다.\n",
        "\n",
        "- 하이퍼 파라미터 검색 반영이 너무 클때 사용하는 방식이 Randomized Search입니다.\n"
      ],
      "metadata": {
        "id": "5YOrV2urb0yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining a set of values as a dictionary for hyperparameters\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\":[100,200,300,400],\n",
        "    \"max_depth\":[1,3,5,7],\n",
        "    \"reg_lambda\":[.01,.1,.5]    \n",
        "}\n",
        "\n",
        "#declaring RandomizedSearchCV model\n",
        "\n",
        "model = model_selection.RandomizedSearchCV(\n",
        "    estimator = clf,\n",
        "    param_distributions = param_grid,\n",
        "    scoring = 'accuracy',\n",
        "    verbose = 10,\n",
        "    n_jobs = 1,\n",
        "    cv = 5,\n",
        "    n_iter=10\n",
        ")\n",
        "\n",
        "#fitting values to the RandomizedSearchCV model\n",
        "\n",
        "model.fit(X,y)\n",
        "\n",
        "#printing the best possible values to enhance accuracy\n",
        "\n",
        "print(model.best_params_)\n",
        "print(model.best_estimator_)\n",
        "#printing the best score\n",
        "print(model.best_score_)"
      ],
      "metadata": {
        "id": "xmuYSlArbwv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Bayesian optimization\n",
        "\n",
        "- 참고 : https://wooono.tistory.com/102\n",
        "\n",
        "Bayesian Optimization 은 어느 입력값(x)를 받는 미지의 목적 함수 (f(x))를 판단하고 결정하여, 해당 함숫값 (f(x))을 최대로 만드는 최적해를 찾는 것을 목적으로 합니다.\n",
        "\n",
        "즉, 목적 함수(탐색대상함수)와 하이퍼파라미터 쌍(pair)을 대상으로 Surrogate Model(대체 모델) 을 만들고,\n",
        "순차적으로 하이퍼 파라미터를 업데이트해 가면서 평가를 통해 최적의 하이퍼파라미터 조합을 탐색합니다.\n",
        "이 때의 목적 함수를 black-box function 이라고 합니다.\n",
        "Bayesian Optimization 에는 두 가지 필수 요소가 존재합니다.\n",
        "\n",
        "먼저 Surrogate Model 은, 현재까지 조사된 입력값-함숫결과값 점들 $(x_1, f(x_1)),...,(x_t, f(x_t))$ 을 바탕으로, 미지의 목적 함수의 형태에 대한 확률적인 추정을 수행하는 모델을 지칭합니다. 그리고 Acquisition Function 은, 목적 함수에 대한 현재까지의 확률적 추정 결과를 바탕으로, ‘최적 입력값을 찾는 데 있어 가장 유용할 만한’ 다음 입력값 후보를 추천해 주는 함수를 지칭합니다."
      ],
      "metadata": {
        "id": "RaVcCEqfb3dL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb33tsP%2FbtraMpvxJG0%2FSn7uQK7k910IQ7cP3ZM9vk%2Fimg.png'>"
      ],
      "metadata": {
        "id": "O40L9E6lb5EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 대략적인 수행 과정\n",
        "\n",
        "    - 위의 파란색 선은, 우리가 찾으려고 하는 목적함수 f(x) 를 나타내고,\n",
        "    - 검정색 점선은, 지금까지 관측한 데이터를 바탕으로 우리가 예측한 estimated function 을 의미합니다.\n",
        "    - 검정색 점선 주변에 있는 파란 영역은, 목적함수 f(x) 가 존재할만한 confidence bound(function의 variance) 를 의미합니다.\n",
        "    - 밑에 있는 EI(x) 는, Acquisition function 을 의미하며, 다음 입력값 후보 추천 시 사용됩니다.\n",
        "    - Acquisition function 값이 컸던 지점을 확인하고, 해당 지점의 hyperparameter 를 다음 입력 값으로 사용합니다.\n",
        "    - hyperparamter 에 따라 estimated function 을 계속 update 하면, estimation function 과 목적 함수 f(x) 가 흡사해집니다.\n",
        "    - 관측한 지점 중 best point 을 argmax f(x) 로 선택합니다.\n",
        "- 자세한 수행 과정\n",
        "\n",
        "    - 입력값, 목적 함수 및 그 외 설정값들을 정의합니다.\n",
        "\n",
        "        - 입력값 x : 여러가지 hyperparameter\n",
        "        - 목적 함수 f(x) : 설정한 입력값을 적용해 학습한, 딥러닝 모델의 성능 결과 수치(e.g. 정확도)\n",
        "        - 입력값 x 의 탐색 대상 구간 : (a,b)\n",
        "        - 입력값-함숫결과값 점들의 갯수 : n\n",
        "        - 조사할 입력값-함숫결과값 점들의 갯수 : N\n",
        "    - 설정한 탐색 대상 구간 (a,b) 내에서 처음 n 개의 입력값들을 랜덤하게 샘플링하여 선택합니다.\n",
        "\n",
        "    - 선택한 n 개의 입력값 x1, x2, ..., xn 을 각각 모델의 hyperparameter 로 설정하여 딥러닝 모델을 학습한 뒤, 학습이 완료된 모델의 성능 결과 수치를 계산합니다.\n",
        "\n",
        "        - 이들을 각각 함숫결과값 f(x1), f(x2), ..., f(xn) 으로 간주합니다.\n",
        "입력값-함숫결과값 점들의 모음 (x1, f(x1)), (x2, f(x2)), ..., (xn, f(xn)) 에 대하여 Surrogate Model 로 확률적 추정을 수행합니다.\n",
        "\n",
        "    - 조사된 입력값-함숫결과값 점들이 총 N 개에 도달할 때까지, 아래의 과정을 반복적으로 수행합니다.\n",
        "\n",
        "        - 기존 입력값-함숫결과값 점들의 모음 (x1, f(x1)),(x2, f(x2)), ..., (xt, f(xt)) 에 대한 Surrogate Model 의 확률적 추정 결과를 바탕으로, 입력값 구간 (a,b) 내에서의 EI 의 값을 계산하고, 그 값이 가장 큰 점을 다음 입력값 후보 x1 로 선정합니다.\n",
        "        - 다음 입력값 후보 x1 를 hyperparameter 로 설정하여 딥러닝 모델을 학습한 뒤, 학습이 완료된 모델의 성능 결과 수치를 계산하고, 이를 f(x1) 값으로 간주합니다.\n",
        "        - 새로운 점 (x2, f(x2)) 을 기존 입력값-함숫결과값 점들의 모음에 추가하고, 갱신된 점들의 모음에 대하여 Surrogate Model 로 확률적 추정을 다시 수행합니다.\n",
        "        - 총 N 개의 입력값-함숫결과값 점들에 대하여 확률적으로 추정된 목적 함수 결과물을 바탕으로, 평균 함수 μ(x) 을 최대로 만드는 최적해를 최종 선택합니다. 추후 해당값을 hyperparameter 로 사용하여 딥러닝 모델을 학습하면, 일반화 성능이 극대화된 모델을 얻을 수 있습니다."
      ],
      "metadata": {
        "id": "FZ_RPKfO0Qq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def black_box_function(x, y):\n",
        "    \"\"\"Function with unknown internals we wish to maximize.\n",
        "\n",
        "    This is just serving as an example, for all intents and\n",
        "    purposes think of the internals of this function, i.e.: the process\n",
        "    which generates its output values, as unknown.\n",
        "    \"\"\"\n",
        "    return -x ** 2 - (y - 1) ** 2 + 1"
      ],
      "metadata": {
        "id": "nyr_1tlmbwyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "id": "tjXwJ9Xmb6-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# Bounded region of parameter space\n",
        "pbounds = {'x': (2, 4), 'y': (-3, 3)}\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=black_box_function,\n",
        "    pbounds=pbounds,\n",
        "    random_state=1,\n",
        ")"
      ],
      "metadata": {
        "id": "WDguW3mcb7Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
        "\n",
        "- init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space."
      ],
      "metadata": {
        "id": "T5TAgbkzb9iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.maximize(\n",
        "    init_points=2,\n",
        "    n_iter=3,\n",
        ")"
      ],
      "metadata": {
        "id": "hUs3G-ccb7Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(optimizer.max)"
      ],
      "metadata": {
        "id": "jOnAhNQVb_aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, res in enumerate(optimizer.res):\n",
        "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
      ],
      "metadata": {
        "id": "Th9v5FM1cAOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.set_bounds(new_bounds={\"x\": (-2, 3)})\n",
        "\n",
        "optimizer.maximize(\n",
        "    init_points=0,\n",
        "    n_iter=5,\n",
        ")\n"
      ],
      "metadata": {
        "id": "LBZZaoFNcBMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- xgboost 하이퍼 파라미터 최적화"
      ],
      "metadata": {
        "id": "VnAbSHdbze4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#Loading iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "#independent feautres\n",
        "X = iris.data\n",
        "\n",
        "# target features\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "LT41dfDjztml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, stratify=y)"
      ],
      "metadata": {
        "id": "6_2WiA3szymE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# MAPE Metric\n",
        "def mean_absolute_percentage_error(y_test, y_pred):\n",
        "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "# 탐색 대상 함수 (XGBRegressor)\n",
        "def XGB_cv(max_depth,learning_rate, n_estimators, gamma\n",
        "            ,min_child_weight, subsample\n",
        "            ,colsample_bytree, silent=True, nthread=-1):\n",
        "\n",
        "    # 모델 정의\n",
        "    model = xgb.XGBRegressor(max_depth=int(max_depth),\n",
        "                            learning_rate=learning_rate,\n",
        "                            n_estimators=int(n_estimators),\n",
        "                            gamma=gamma,\n",
        "                            min_child_weight=min_child_weight,\n",
        "                            subsample=subsample,\n",
        "                            colsample_bytree=colsample_bytree, \n",
        "                            nthread=nthread\n",
        "                            )\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 예측값 출력\n",
        "    y_pred= model.predict(X_test)\n",
        "\n",
        "    # 각종 metric 계산\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "    # 오차 최적화로 사용할 metric 반환\n",
        "    return r2"
      ],
      "metadata": {
        "id": "Xn6GBBVVzdRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  bayesian-optimization 라이브러리의 BayesianOptimization 클래스 import\n",
        "from bayes_opt import BayesianOptimization\n",
        "import numpy as np\n",
        "\n",
        "# 실험해보고자하는 hyperparameter 집합\n",
        "pbounds = {'max_depth': (3, 7),\n",
        "            'learning_rate': (0.01, 0.2),\n",
        "            'n_estimators': (5000, 10000),\n",
        "            'gamma': (0, 100),\n",
        "            'min_child_weight': (0, 3),\n",
        "            'subsample': (0.5, 1),\n",
        "            'colsample_bytree' :(0.2, 1)\n",
        "            }\n",
        "\n",
        "# Bayesian optimization 객체 생성\n",
        "# f : 탐색 대상 함수, pbounds : hyperparameter 집합\n",
        "# verbose = 2 항상 출력, verbose = 1 최댓값일 때 출력, verbose = 0 출력 안함\n",
        "# random_state : Bayesian Optimization 상의 랜덤성이 존재하는 부분을 통제 \n",
        "bo=BayesianOptimization(f=XGB_cv, pbounds=pbounds, verbose=2, random_state=1 )    \n",
        "\n",
        "# 메소드를 이용해 최대화 과정 수행\n",
        "# init_points :  초기 Random Search 갯수\n",
        "# n_iter : 반복 횟수 (몇개의 입력값-함숫값 점들을 확인할지! 많을 수록 정확한 값을 얻을 수 있다.)\n",
        "# acq : Acquisition Function들 중 Expected Improvement(EI) 를 사용\n",
        "# xi : exploration 강도 (기본값은 0.0)\n",
        "bo.maximize(init_points=2, n_iter=10, acq='ei', xi=0.01)\n",
        "\n",
        "# ‘iter’는 반복 회차, ‘target’은 목적 함수의 값, 나머지는 입력값을 나타냅니다. \n",
        "# 현재 회차 이전까지 조사된 함숫값들과 비교하여, 현재 회차에 최댓값이 얻어진 경우, \n",
        "# bayesian-optimization 라이브러리는 이를 자동으로 다른 색 글자로 표시하는 것을 확인할 수 있습니다\n",
        "\n",
        "# 찾은 파라미터 값 확인\n",
        "print(bo.max)"
      ],
      "metadata": {
        "id": "qnvOOx3Tzjzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Hyperopt\n",
        "\n",
        "- HyperOpt는 자동화된 하이퍼파라미터 튜닝 프레임워크로서, fmin()이라는 함수 안에는 3가지의 파라미터가 있다:\n",
        "\n",
        "    - Objective Function: 최소화할 손실 함수\n",
        "    - Domain Space: 탐색 범위. 베이지안 최적화에서는 이 범위가 각  하이퍼파라미터에 대해 통계 분포를 만들어낸다.\n",
        "    - Optimization Algorithm : 최적의 조합을 찾기 위한 알고리즘\n",
        "\n",
        "참고 : https://velog.io/@emseoyk/%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D"
      ],
      "metadata": {
        "id": "oNOGx7UrcCXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "K-k_fxgjcDeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages \n",
        "\n",
        "from hyperopt import hp,fmin, tpe, Trials\n",
        "\n",
        "from hyperopt.pyll.base import scope\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "from skopt import space\n",
        "\n",
        "from skopt import gp_minimize\n",
        "\n",
        "#defining a method that will perfrom a 5 split cross validation over\n",
        "\n",
        "#dataset and and will produce the optimum value of the accuracy\n",
        "\n",
        "def optimize(params, x,y):\n",
        "\n",
        "    clf = XGBClassifier(**params)\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for idx in kf.split(X=x,y=y):\n",
        "\n",
        "        train_idx,test_idx = idx[0],idx[1]\n",
        "\n",
        "        xtrain = x[train_idx]\n",
        "\n",
        "        ytrain = y[train_idx]\n",
        "\n",
        "        xtest = x[test_idx]\n",
        "\n",
        "        ytest = y[test_idx]\n",
        "\n",
        "        clf.fit(xtrain,ytrain)\n",
        "\n",
        "        preds =  clf.predict(xtest)\n",
        "\n",
        "        fold_acc = metrics.accuracy_score(ytest,preds)\n",
        "\n",
        "        accuracies.append(fold_acc)\n",
        "\n",
        "    return -1.0 * np.mean(accuracies)\n",
        "\n",
        "#defining a set of values as hp for hyperparameters\n",
        "\n",
        "param_space = {\n",
        "\n",
        "    \"max_depth\" : scope.int(hp.quniform(\"max_depth\",3,20, 1)) ,\n",
        "\n",
        "    \"min_child_weight\" : scope.int(hp.quniform(\"min_child_weight\",1,8, 1)),\n",
        "\n",
        "    \"n_estimators\": scope.int(hp.quniform(\"n_estimators\",100,1500,1)),\n",
        "\n",
        "    'learning_rate': hp.uniform(\"learning_rate\",0.01,1),\n",
        "\n",
        "    'reg_lambda': hp.uniform(\"reg_lambda\",0.01,1),\n",
        "\n",
        "    'gamma': hp.uniform(\"gamma\",0.01,1),\n",
        "\n",
        "    'subsample': hp.uniform(\"subsample\",0.01,1)\n",
        "\n",
        "    }\n",
        "\n",
        "#defiing optimization_fuction as partial and calling optimize within it\n",
        "\n",
        "optimization_fuction = partial(optimize,x = X, y = y) \n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "#Getting the optimum values for hyperparameters\n",
        "\n",
        "result = fmin(\n",
        "\n",
        "    fn = optimization_fuction,\n",
        "\n",
        "    space = param_space,\n",
        "\n",
        "    algo = tpe.suggest,\n",
        "\n",
        "    max_evals = 15,\n",
        "\n",
        "    trials = trials\n",
        "\n",
        ")\n",
        "\n",
        "#Printing the best hyperparemeter set\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "iM-SA_qFcEQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Optuna\n",
        "\n",
        "- Optuna는 ML 알고리즘의 하이퍼파라미터 튜닝을 자동화해주는 오픈소스 툴입니다. 유사한 툴로 Hyperopt가 있지만 사용성과 문서화, 시각화 제공 여부 등에서 Optuna의 손을 들어주는 경우가 많음.\n",
        "\n",
        "- 하이퍼파라미터 튜닝에 쓰고 있는 최신 Automl 기법입니다.\n",
        "- 빠르게 튜닝이 가능하다는 장점이 있음.\n",
        "- 하이퍼파라미터 튜닝 방식을 지정할수 있다. -> 직관적인 api인 튜닝된 lightgbm도 제공해줍니다.\n",
        "\n",
        "- 다른 라이브러리들에 비해 직관적인 장점이 있어 코딩하기 용이합니다.\n"
      ],
      "metadata": {
        "id": "gaNtLF72cFZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 거의 모든 ML/DL 프레임워크에서 사용 가능한 넓은 범용성을 가지고 있다.\n",
        "간단하고 빠르다.\n",
        "- 최신 동향의 다양한 최적화 알고리즘을 갖추고 있다.\n",
        "- 병렬 처리가 가능하다.\n",
        "- 간단한 메소드로 시각화가 가능하다."
      ],
      "metadata": {
        "id": "DgTDs7PVGC37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Optuna를 이해하기 위해서는 다음의 용어에 익숙해져야 한다.\n",
        "\n",
        "    - Study: 목적 함수에 기반한 최적화\n",
        "    - Trial: 목적함수 시행\n",
        "- 쉽게 말해 study는 최적화를 하는 과정이고, trial은 다양한 조합으로 목적함수를 시행하는 횟수를 뜻한다.\n",
        "- Study의 목적은 여러 번의 trial을 거쳐 최적의 하이퍼파라미터 조합을 찾는 것이라고 할 수 있겠다."
      ],
      "metadata": {
        "id": "wO8cko_zGFGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "h3rOl_oqcHAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all the required packages\n",
        "import optuna\n",
        "from sklearn.datasets import load_iris\n",
        "import sklearn.linear_model\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Loading iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "#independent feautres\n",
        "X = iris.data\n",
        "\n",
        "# target features\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "5fGjE4mrcH8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "print(optuna.__version__)"
      ],
      "metadata": {
        "id": "UQYpoUkQcJDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages\n",
        "import optuna\n",
        "from functools import partial\n",
        "\n",
        "#defining a method that will perfrom a 5 split cross validation over\n",
        "#dataset and and will produce the optimum value of the accuracy\n",
        "def optimize(trial, x,y):\n",
        "    #parameter set is declare within function\n",
        "    #suggest_uniform : 범위 내의 균일 분포 값을 선택.\n",
        "    #suggest_discrete_uniform : 이산 균등 분포를 값으로 선택.\n",
        "    #suggest_loguniform : 범위 내의 로그 함수 선상의 값을 선택.\n",
        "    reg_lambda = trial.suggest_uniform('reg_lambda',0.01,1)\n",
        "    \n",
        "    n_estimators = trial.suggest_int('n_estimators',100,1500)\n",
        "    \n",
        "    max_depth = trial.suggest_int('max_depth',3,15)\n",
        "    \n",
        "    max_features = trial.suggest_uniform('max_features',0.01,1)\n",
        "    \n",
        "    clf = XGBClassifier(\n",
        "    \n",
        "    n_estimators= n_estimators,\n",
        "\n",
        "    reg_lambda=reg_lambda,\n",
        "\n",
        "    max_depth=max_depth,\n",
        "\n",
        "    max_features= max_features)\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for idx in kf.split(X=x,y=y):\n",
        "\n",
        "        train_idx,test_idx = idx[0],idx[1]\n",
        "\n",
        "        xtrain = x[train_idx]\n",
        "\n",
        "        ytrain = y[train_idx]\n",
        "\n",
        "        xtest = x[test_idx]\n",
        "\n",
        "        ytest = y[test_idx]\n",
        "\n",
        "        clf.fit(xtrain,ytrain)\n",
        "\n",
        "        preds =  clf.predict(xtest)\n",
        "\n",
        "        fold_acc = metrics.accuracy_score(ytest,preds)\n",
        "\n",
        "        accuracies.append(fold_acc)\n",
        "\n",
        "    return -1.0 * np.mean(accuracies)\n",
        "\n",
        "#defiing optimization_fuction as partial and calling optimize within it\n",
        "\n",
        "optimization_fuction = partial(optimize,x = X, y = y) \n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "\n",
        "#Printing the best hyperparemeter set\n",
        "\n",
        "study.optimize(optimization_fuction, n_trials=15)"
      ],
      "metadata": {
        "id": "1H0r9ygVcKDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- mimimize로 찾은 이유 : https://stackoverflow.com/questions/72193393/find-the-value-of-variables-to-maximize-return-of-function-in-python"
      ],
      "metadata": {
        "id": "WD46e556Omz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages\n",
        "import optuna\n",
        "from functools import partial\n",
        "\n",
        "#defining a method that will perfrom a 5 split cross validation over\n",
        "#dataset and and will produce the optimum value of the accuracy\n",
        "def optimize(trial, x,y):\n",
        "    #parameter set is declare within function\n",
        "    #suggest_uniform : 범위 내의 균일 분포 값을 선택.\n",
        "    #suggest_discrete_uniform : 이산 균등 분포를 값으로 선택.\n",
        "    #suggest_loguniform : 범위 내의 로그 함수 선상의 값을 선택.\n",
        "    reg_lambda = trial.suggest_uniform('reg_lambda',0.01,1)\n",
        "    \n",
        "    n_estimators = trial.suggest_int('n_estimators',100,1500)\n",
        "    \n",
        "    max_depth = trial.suggest_int('max_depth',3,15)\n",
        "    \n",
        "    max_features = trial.suggest_uniform('max_features',0.01,1)\n",
        "    \n",
        "    clf = XGBClassifier(\n",
        "    \n",
        "    n_estimators= n_estimators,\n",
        "\n",
        "    reg_lambda=reg_lambda,\n",
        "\n",
        "    max_depth=max_depth,\n",
        "\n",
        "    max_features= max_features)\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for idx in kf.split(X=x,y=y):\n",
        "\n",
        "        train_idx,test_idx = idx[0],idx[1]\n",
        "\n",
        "        xtrain = x[train_idx]\n",
        "\n",
        "        ytrain = y[train_idx]\n",
        "\n",
        "        xtest = x[test_idx]\n",
        "\n",
        "        ytest = y[test_idx]\n",
        "\n",
        "        clf.fit(xtrain,ytrain)\n",
        "\n",
        "        preds =  clf.predict(xtest)\n",
        "\n",
        "        fold_acc = metrics.accuracy_score(ytest,preds)\n",
        "\n",
        "        accuracies.append(fold_acc)\n",
        "\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "#defiing optimization_fuction as partial and calling optimize within it\n",
        "\n",
        "optimization_fuction = partial(optimize,x = X, y = y) \n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "#Printing the best hyperparemeter set\n",
        "\n",
        "study.optimize(optimization_fuction, n_trials=15)"
      ],
      "metadata": {
        "id": "phw9SbcQJmD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an objective function"
      ],
      "metadata": {
        "id": "9zw7Dt_UcOW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## In optuna, A Trial represents a single call of the objective function\n",
        "## Study shows an optimization session which contains a set of trials\n",
        "## Study: optimization based on an objective function\n",
        "## Trial: a single execution of the objective function\n",
        "\n",
        "## In this demo, \"alpha\" is the hyperparameter which is need to be optimized\n",
        "def objective(trial):\n",
        "   \n",
        "    # hyperparameter setting, trial.suggest_uniform will suggest uniform hyperparameter\n",
        "    #alpha between the range of 0.0 to 2.0, lowest value of interval is closed and \n",
        "    #when low=high, it will return low value\n",
        "    alpha = trial.suggest_uniform('alpha', 0.0, 2.0)\n",
        "    \n",
        "    # data loading and train-test split\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
        "    \n",
        "    # model training and evaluation\n",
        "    model = sklearn.linear_model.Lasso(alpha=alpha)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n",
        "\n",
        "    # output: evaluation score\n",
        "    return error"
      ],
      "metadata": {
        "id": "Pr8FbrtvcPdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an study for that ML model and optimize it"
      ],
      "metadata": {
        "id": "J5_c2l7TcRKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "# In Optuna, we use the study object to manage optimization.\n",
        "# Method :func:`~optuna.create_study` returns a study object.\n",
        "# A study object has useful properties for analyzing the optimization outcome.\n",
        "study = optuna.create_study(direction='minimize') #Set minimize for minimization and maximize for maximization.\n",
        "#To start the optimization, we create a study object and pass the objective function to method\n",
        "study.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "MDjBVqYkcPfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualized the above hyperparameter optimization study"
      ],
      "metadata": {
        "id": "3vQMiNdmcTqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all the plot functions\n",
        "from optuna.visualization import plot_edf\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_slice"
      ],
      "metadata": {
        "id": "CFlHgvK9cPh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the optimization history. See :func:`~optuna.visualization.plot_optimization_history` for the details.\n",
        "plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "E3dHCwofcVE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize high-dimensional parameter relationships. See :func:`~optuna.visualization.plot_parallel_coordinate` for the details.\n",
        "plot_parallel_coordinate(study)"
      ],
      "metadata": {
        "id": "oQ6qT2ZLcVHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize individual hyperparameters as slice plot. See :func:`~optuna.visualization.plot_slice` for the details.\n",
        "plot_slice(study)"
      ],
      "metadata": {
        "id": "HNAk09O6cVJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize parameter importances. See :func:`~optuna.visualization.plot_param_importances` for the details.\n",
        "#In this case, we have only one parameter.\n",
        "plot_param_importances(study)"
      ],
      "metadata": {
        "id": "nNK4p89hcY1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize empirical distribution function. See :func:`~optuna.visualization.plot_edf` for the details.\n",
        "plot_edf(study)"
      ],
      "metadata": {
        "id": "4UnJr023cY3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 1. 최소화/최대화할 목적함수 정의\n",
        "def objective(trial):\n",
        "    iris = sklearn.datasets.load_iris()\n",
        "    x, y = iris.data, iris.target\n",
        "\n",
        "# 2. trial object로 하이퍼파라미터 값 추천\n",
        "# 다양한 분류모델을 설정해서 비교할 수 있다.\n",
        "    classifier_name = trial.suggest_categorical('classifier', ['SVC', 'RandomForest'])\n",
        "    #분류 모델이 SVC일 때\n",
        "    if classifier_name == 'SVC':\n",
        "        svc_c = trial.suggest_loguniform('svc_c', 1e-10, 1e10)\n",
        "        classifier_obj = sklearn.svm.SVC(C=svc_c, gamma='auto')\n",
        "    \n",
        "    #분류모델이 랜덤포레스트일 때\n",
        "    else:\n",
        "        rf_max_depth = int(trial.suggest_loguniform('rf_max_depth', 2, 32))\n",
        "        classifier_obj = sklearn.ensemble.RandomForestClassifier(max_depth=rf_max_depth, n_estimators=10)\n",
        "    \n",
        "    accuracy = cross_val_score(classifier_obj, x, y, cv = 4).mean()\n",
        "    return accuracy\n",
        "\n",
        "# 3. study 오브젝트 생성하고 목적함수 최적화하는 단계\n",
        "# 여기서는 목적함수를 정확도로 설정했기 때문에 최대화를 목표로 하고 있지만, 손실함수의 경우 direction='minimize'로 설정\n",
        "study = optuna.create_study(direction='maximize')\n",
        "# 반복 시행 횟수(trial)는 200번으로\n",
        "study.optimize(objective, n_trials=200)"
      ],
      "metadata": {
        "id": "8PahkZBmcY5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시행된 trial 중 최적의 하이퍼파라미터 반환하는 메소드\n",
        "print(study.best_trial.params)\n",
        "\n",
        "# 시행된 trial 중 가장 높은 값 반환하는 메소드\n",
        "optuna_acc = study.best_trial.value\n",
        "print(optuna_acc)"
      ],
      "metadata": {
        "id": "8ELZ5u6Bcd-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "H2MWEFmgcgfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_param_importances(study)\n",
        "\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "E84NoqGTcd_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcXuNtGJ8XVh"
      },
      "source": [
        "# 6.Pycaret\n",
        "\n",
        "- AutoML을 하게 해주는 파이썬 라이브러리\n",
        "- scikit-learning 패키지를 기반으로 하고 있으며 Classification, Regression, Clustering, Anomaly Detection 등 다양한 모델을 지원함.\n",
        "\n",
        "- 공식문서에 설명이 매우 잘 되어 있고, 몇 줄의 코드로 쉽게 구현이 가능하기 때문에 유용하게 사용할 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#Loading iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "#independent feautres\n",
        "X = iris.data\n",
        "\n",
        "# target features\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "mHkPjpE1acWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "print(optuna.__version__)"
      ],
      "metadata": {
        "id": "qxKNtvxUMLl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages\n",
        "\n",
        "import optuna\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "#defining a method that will perfrom a 5 split cross validation over\n",
        "\n",
        "#dataset and and will produce the optimum value of the accuracy\n",
        "\n",
        "def optimize(trial, x,y):\n",
        "\n",
        "    #parameter set is declare within function\n",
        "\n",
        "    reg_lambda = trial.suggest_uniform('reg_lambda',0.01,1)\n",
        "\n",
        "    n_estimators = trial.suggest_int('n_estimators',100,1500)\n",
        "\n",
        "    max_depth = trial.suggest_int('max_depth',3,15)\n",
        "\n",
        "    max_features = trial.suggest_uniform('max_features',0.01,1)\n",
        "\n",
        "    clf = XGBClassifier(\n",
        "\n",
        "    n_estimators= n_estimators,\n",
        "\n",
        "    reg_lambda=reg_lambda,\n",
        "\n",
        "    max_depth=max_depth,\n",
        "\n",
        "    max_features= max_features)\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for idx in kf.split(X=x,y=y):\n",
        "\n",
        "        train_idx,test_idx = idx[0],idx[1]\n",
        "\n",
        "        xtrain = x[train_idx]\n",
        "\n",
        "        ytrain = y[train_idx]\n",
        "\n",
        "        xtest = x[test_idx]\n",
        "\n",
        "        ytest = y[test_idx]\n",
        "\n",
        "        clf.fit(xtrain,ytrain)\n",
        "\n",
        "        preds =  clf.predict(xtest)\n",
        "\n",
        "        fold_acc = metrics.accuracy_score(ytest,preds)\n",
        "\n",
        "        accuracies.append(fold_acc)\n",
        "\n",
        "    return -1.0 * np.mean(accuracies)\n",
        "\n",
        "#defiing optimization_fuction as partial and calling optimize within it\n",
        "\n",
        "optimization_fuction = partial(optimize,x = X, y = y) \n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "\n",
        "#Printing the best hyperparemeter set\n",
        "\n",
        "study.optimize(optimization_fuction, n_trials=15)"
      ],
      "metadata": {
        "id": "93p39wFfNbh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 설치"
      ],
      "metadata": {
        "id": "JqOxVFkJWQOs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqlGmSqx8aeh"
      },
      "source": [
        "!pip install pycaret\n",
        "!pip install shap #interpret_model 사용할때 필요"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Data load"
      ],
      "metadata": {
        "id": "HPYcpaogWcj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.datasets import get_data\n",
        "diabetes = get_data('diabetes')"
      ],
      "metadata": {
        "id": "sR7dSlwuWW2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Set up\n",
        "- 학습 데이터가 무엇인지, 목표 클래스는 무엇인지 설정\n",
        "\n",
        "- 엔터 한번을 꼭 클릭을 할 것!\n"
      ],
      "metadata": {
        "id": "hZh7GqgpWif2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numba\n",
        " - Python 및 Numpy 코드의 하위 집합을 빠른 기계 코드로 변환하는 오픈소스 Jit 컴파일러.\n",
        "\n",
        " - Just In Time 컴파일러를 사용해 파이썬 코드 내에서 일반 코드 및 Numpy를 아주 빠른 속도로 처리 가능한 기능을 제공."
      ],
      "metadata": {
        "id": "LXMue7hEXHpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba --upgrade"
      ],
      "metadata": {
        "id": "i9e-hfdMW4vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import *\n",
        "data = setup(diabetes, target = 'Class variable')"
      ],
      "metadata": {
        "id": "XrYbAeG3WfEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) 모델 비교"
      ],
      "metadata": {
        "id": "Vbbw1-D_YHdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models()"
      ],
      "metadata": {
        "id": "bMUSFIatWvU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) 모델 생성"
      ],
      "metadata": {
        "id": "Bt1h-dJcYLxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = create_model('lr')"
      ],
      "metadata": {
        "id": "KVA_ln-aYJp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) 모델 튜닝"
      ],
      "metadata": {
        "id": "MOG68YiyYOrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_lr = tune_model(lr)"
      ],
      "metadata": {
        "id": "Yqu7UtmMYNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Bagging"
      ],
      "metadata": {
        "id": "pADYsftgYRUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bagged_lr = ensemble_model(lr, method = 'Bagging')"
      ],
      "metadata": {
        "id": "cxon1iJdYQnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Stacking"
      ],
      "metadata": {
        "id": "Pt9IyAj8YVLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = create_model('lda')\n",
        "rf = create_model('rf')\n",
        "stacker = stack_models(estimator_list = [lda, rf], meta_model = lr)"
      ],
      "metadata": {
        "id": "5Jv2Sl6YYS7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) Plot"
      ],
      "metadata": {
        "id": "CH8XVpoVYX-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lr)"
      ],
      "metadata": {
        "id": "HT4hxnExYXEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) 모델 저장"
      ],
      "metadata": {
        "id": "xYjlaH9SYcMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(lr, 'lr_saved')"
      ],
      "metadata": {
        "id": "CatDYXb7Ybb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11) Model load"
      ],
      "metadata": {
        "id": "wji83abQYfIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_saved = load_model('lr_saved')"
      ],
      "metadata": {
        "id": "sHT3oSo_YeOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}