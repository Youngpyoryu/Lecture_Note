{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# iris_data를 xgboost로 적용을 해보자."
      ],
      "metadata": {
        "id": "-XgDYosabhoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#Loading iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "#independent feautres\n",
        "X = iris.data\n",
        "\n",
        "# target features\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "APzk3M3Hbklu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import XGboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#Defining XGB Classification model\n",
        "clf = XGBClassifier()"
      ],
      "metadata": {
        "id": "YH_KPRdnbklw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- xgboost의 단점은 복잡한 하이퍼 파라미터가 있다."
      ],
      "metadata": {
        "id": "v7wfVSY2bro4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Grid SearchCV\n",
        "- 사용자가 하이퍼 파라미터마다 몇가지 값을 가진 리스트를 입력하면, 가능한 하이퍼 파라미터의 경우의 수마다 예측 성능을 측정하여 사용자가 일일이 하이퍼 파라미터를 설정하고, 예측 성능을 비교하여 최적의 파라미터를 찾는 수고를 줄이고 이 과정을 한꺼번에 진행한다."
      ],
      "metadata": {
        "id": "bjRTeDOlburH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing packages from sklearn\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "#defining a set of values as a dictionary for hyperparameters\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\":[100,200,300,400],\n",
        "    \"max_depth\":[1,3,5,7],\n",
        "    \"reg_lambda\":[.01,.1,.5]    \n",
        "}\n",
        "\n",
        "#declaring GridSearchCV model\n",
        "\n",
        "model = model_selection.GridSearchCV(\n",
        "    estimator = clf,\n",
        "    param_grid = param_grid,\n",
        "    scoring = 'accuracy',\n",
        "    verbose = 10,\n",
        "    n_jobs = 1,\n",
        "    cv = 5    \n",
        ")\n",
        "\n",
        "#fitting values to the gridsearchcv model\n",
        "\n",
        "model.fit(X,y)\n",
        "#printing the best possible values to enhance accuracy\n",
        "print(model.best_params_)\n",
        "print(model.best_estimator_)\n",
        "#printing the best score\n",
        "print(model.best_score_)"
      ],
      "metadata": {
        "id": "TsJr9ua1bwty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. RandomizedSearchCV\n",
        "\n",
        "- 그리드 서치에서는 grid_param과 같이 매개변수마다 특정 값을 지정해주었습니다. 만약에 변수 범위가 너무 다양하다면 하나하나 작성해주는게 너무 힘들다.\n",
        "\n",
        "- 하이퍼 파라미터 검색 반영이 너무 클때 사용하는 방식이 Randomized Search입니다.\n"
      ],
      "metadata": {
        "id": "5YOrV2urb0yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining a set of values as a dictionary for hyperparameters\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\":[100,200,300,400],\n",
        "    \"max_depth\":[1,3,5,7],\n",
        "    \"reg_lambda\":[.01,.1,.5]    \n",
        "}\n",
        "\n",
        "#declaring RandomizedSearchCV model\n",
        "\n",
        "model = model_selection.RandomizedSearchCV(\n",
        "    estimator = clf,\n",
        "    param_distributions = param_grid,\n",
        "    scoring = 'accuracy',\n",
        "    verbose = 10,\n",
        "    n_jobs = 1,\n",
        "    cv = 5,\n",
        "    n_iter=10\n",
        ")\n",
        "\n",
        "#fitting values to the RandomizedSearchCV model\n",
        "\n",
        "model.fit(X,y)\n",
        "\n",
        "#printing the best possible values to enhance accuracy\n",
        "\n",
        "print(model.best_params_)\n",
        "print(model.best_estimator_)\n",
        "#printing the best score\n",
        "print(model.best_score_)"
      ],
      "metadata": {
        "id": "xmuYSlArbwv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Bayesian optimization\n",
        "\n",
        "- 참고 : https://wooono.tistory.com/102\n",
        "\n",
        "Bayesian Optimization 은 어느 입력값(x)를 받는 미지의 목적 함수 (f(x))를 판단하고 결정하여, 해당 함숫값 (f(x))을 최대로 만드는 최적해를 찾는 것을 목적으로 합니다.\n",
        "\n",
        "즉, 목적 함수(탐색대상함수)와 하이퍼파라미터 쌍(pair)을 대상으로 Surrogate Model(대체 모델) 을 만들고,\n",
        "순차적으로 하이퍼 파라미터를 업데이트해 가면서 평가를 통해 최적의 하이퍼파라미터 조합을 탐색합니다.\n",
        "이 때의 목적 함수를 black-box function 이라고 합니다.\n",
        "Bayesian Optimization 에는 두 가지 필수 요소가 존재합니다.\n",
        "\n",
        "먼저 Surrogate Model 은, 현재까지 조사된 입력값-함숫결과값 점들 $(x_1, f(x_1)),...,(x_t, f(x_t))$ 을 바탕으로, 미지의 목적 함수의 형태에 대한 확률적인 추정을 수행하는 모델을 지칭합니다. 그리고 Acquisition Function 은, 목적 함수에 대한 현재까지의 확률적 추정 결과를 바탕으로, ‘최적 입력값을 찾는 데 있어 가장 유용할 만한’ 다음 입력값 후보를 추천해 주는 함수를 지칭합니다."
      ],
      "metadata": {
        "id": "RaVcCEqfb3dL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb33tsP%2FbtraMpvxJG0%2FSn7uQK7k910IQ7cP3ZM9vk%2Fimg.png'>"
      ],
      "metadata": {
        "id": "O40L9E6lb5EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 대략적인 수행 과정\n",
        "\n",
        "    - 위의 파란색 선은, 우리가 찾으려고 하는 목적함수 f(x) 를 나타내고,\n",
        "    - 검정색 점선은, 지금까지 관측한 데이터를 바탕으로 우리가 예측한 estimated function 을 의미합니다.\n",
        "    - 검정색 점선 주변에 있는 파란 영역은, 목적함수 f(x) 가 존재할만한 confidence bound(function의 variance) 를 의미합니다.\n",
        "    - 밑에 있는 EI(x) 는, Acquisition function 을 의미하며, 다음 입력값 후보 추천 시 사용됩니다.\n",
        "    - Acquisition function 값이 컸던 지점을 확인하고, 해당 지점의 hyperparameter 를 다음 입력 값으로 사용합니다.\n",
        "    - hyperparamter 에 따라 estimated function 을 계속 update 하면, estimation function 과 목적 함수 f(x) 가 흡사해집니다.\n",
        "    - 관측한 지점 중 best point 을 argmax f(x) 로 선택합니다.\n",
        "- 자세한 수행 과정\n",
        "\n",
        "    - 입력값, 목적 함수 및 그 외 설정값들을 정의합니다.\n",
        "\n",
        "        - 입력값 x : 여러가지 hyperparameter\n",
        "        - 목적 함수 f(x) : 설정한 입력값을 적용해 학습한, 딥러닝 모델의 성능 결과 수치(e.g. 정확도)\n",
        "        - 입력값 x 의 탐색 대상 구간 : (a,b)\n",
        "        - 입력값-함숫결과값 점들의 갯수 : n\n",
        "        - 조사할 입력값-함숫결과값 점들의 갯수 : N\n",
        "    - 설정한 탐색 대상 구간 (a,b) 내에서 처음 n 개의 입력값들을 랜덤하게 샘플링하여 선택합니다.\n",
        "\n",
        "    - 선택한 n 개의 입력값 x1, x2, ..., xn 을 각각 모델의 hyperparameter 로 설정하여 딥러닝 모델을 학습한 뒤, 학습이 완료된 모델의 성능 결과 수치를 계산합니다.\n",
        "\n",
        "        - 이들을 각각 함숫결과값 f(x1), f(x2), ..., f(xn) 으로 간주합니다.\n",
        "입력값-함숫결과값 점들의 모음 (x1, f(x1)), (x2, f(x2)), ..., (xn, f(xn)) 에 대하여 Surrogate Model 로 확률적 추정을 수행합니다.\n",
        "\n",
        "    - 조사된 입력값-함숫결과값 점들이 총 N 개에 도달할 때까지, 아래의 과정을 반복적으로 수행합니다.\n",
        "\n",
        "        - 기존 입력값-함숫결과값 점들의 모음 (x1, f(x1)),(x2, f(x2)), ..., (xt, f(xt)) 에 대한 Surrogate Model 의 확률적 추정 결과를 바탕으로, 입력값 구간 (a,b) 내에서의 EI 의 값을 계산하고, 그 값이 가장 큰 점을 다음 입력값 후보 x1 로 선정합니다.\n",
        "        - 다음 입력값 후보 x1 를 hyperparameter 로 설정하여 딥러닝 모델을 학습한 뒤, 학습이 완료된 모델의 성능 결과 수치를 계산하고, 이를 f(x1) 값으로 간주합니다.\n",
        "        - 새로운 점 (x2, f(x2)) 을 기존 입력값-함숫결과값 점들의 모음에 추가하고, 갱신된 점들의 모음에 대하여 Surrogate Model 로 확률적 추정을 다시 수행합니다.\n",
        "        - 총 N 개의 입력값-함숫결과값 점들에 대하여 확률적으로 추정된 목적 함수 결과물을 바탕으로, 평균 함수 μ(x) 을 최대로 만드는 최적해를 최종 선택합니다. 추후 해당값을 hyperparameter 로 사용하여 딥러닝 모델을 학습하면, 일반화 성능이 극대화된 모델을 얻을 수 있습니다."
      ],
      "metadata": {
        "id": "FZ_RPKfO0Qq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def black_box_function(x, y):\n",
        "    \"\"\"Function with unknown internals we wish to maximize.\n",
        "\n",
        "    This is just serving as an example, for all intents and\n",
        "    purposes think of the internals of this function, i.e.: the process\n",
        "    which generates its output values, as unknown.\n",
        "    \"\"\"\n",
        "    return -x ** 2 - (y - 1) ** 2 + 1"
      ],
      "metadata": {
        "id": "nyr_1tlmbwyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "id": "tjXwJ9Xmb6-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# Bounded region of parameter space\n",
        "pbounds = {'x': (2, 4), 'y': (-3, 3)}\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=black_box_function,\n",
        "    pbounds=pbounds,\n",
        "    random_state=1,\n",
        ")"
      ],
      "metadata": {
        "id": "WDguW3mcb7Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
        "\n",
        "- init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space."
      ],
      "metadata": {
        "id": "T5TAgbkzb9iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.maximize(\n",
        "    init_points=2,\n",
        "    n_iter=3,\n",
        ")"
      ],
      "metadata": {
        "id": "hUs3G-ccb7Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(optimizer.max)"
      ],
      "metadata": {
        "id": "jOnAhNQVb_aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, res in enumerate(optimizer.res):\n",
        "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
      ],
      "metadata": {
        "id": "Th9v5FM1cAOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.set_bounds(new_bounds={\"x\": (-2, 3)})\n",
        "\n",
        "optimizer.maximize(\n",
        "    init_points=0,\n",
        "    n_iter=5,\n",
        ")\n"
      ],
      "metadata": {
        "id": "LBZZaoFNcBMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- xgboost 하이퍼 파라미터 최적화"
      ],
      "metadata": {
        "id": "VnAbSHdbze4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#Loading iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "#independent feautres\n",
        "X = iris.data\n",
        "\n",
        "# target features\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "LT41dfDjztml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, stratify=y)"
      ],
      "metadata": {
        "id": "6_2WiA3szymE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# MAPE Metric\n",
        "def mean_absolute_percentage_error(y_test, y_pred):\n",
        "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "# 탐색 대상 함수 (XGBRegressor)\n",
        "def XGB_cv(max_depth,learning_rate, n_estimators, gamma\n",
        "            ,min_child_weight, subsample\n",
        "            ,colsample_bytree, silent=True, nthread=-1):\n",
        "\n",
        "    # 모델 정의\n",
        "    model = xgb.XGBRegressor(max_depth=int(max_depth),\n",
        "                            learning_rate=learning_rate,\n",
        "                            n_estimators=int(n_estimators),\n",
        "                            gamma=gamma,\n",
        "                            min_child_weight=min_child_weight,\n",
        "                            subsample=subsample,\n",
        "                            colsample_bytree=colsample_bytree, \n",
        "                            nthread=nthread\n",
        "                            )\n",
        "    # 모델 훈련\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 예측값 출력\n",
        "    y_pred= model.predict(X_test)\n",
        "\n",
        "    # 각종 metric 계산\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "    # 오차 최적화로 사용할 metric 반환\n",
        "    return r2"
      ],
      "metadata": {
        "id": "Xn6GBBVVzdRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  bayesian-optimization 라이브러리의 BayesianOptimization 클래스 import\n",
        "from bayes_opt import BayesianOptimization\n",
        "import numpy as np\n",
        "\n",
        "# 실험해보고자하는 hyperparameter 집합\n",
        "pbounds = {'max_depth': (3, 7),\n",
        "            'learning_rate': (0.01, 0.2),\n",
        "            'n_estimators': (5000, 10000),\n",
        "            'gamma': (0, 100),\n",
        "            'min_child_weight': (0, 3),\n",
        "            'subsample': (0.5, 1),\n",
        "            'colsample_bytree' :(0.2, 1)\n",
        "            }\n",
        "\n",
        "# Bayesian optimization 객체 생성\n",
        "# f : 탐색 대상 함수, pbounds : hyperparameter 집합\n",
        "# verbose = 2 항상 출력, verbose = 1 최댓값일 때 출력, verbose = 0 출력 안함\n",
        "# random_state : Bayesian Optimization 상의 랜덤성이 존재하는 부분을 통제 \n",
        "bo=BayesianOptimization(f=XGB_cv, pbounds=pbounds, verbose=2, random_state=1 )    \n",
        "\n",
        "# 메소드를 이용해 최대화 과정 수행\n",
        "# init_points :  초기 Random Search 갯수\n",
        "# n_iter : 반복 횟수 (몇개의 입력값-함숫값 점들을 확인할지! 많을 수록 정확한 값을 얻을 수 있다.)\n",
        "# acq : Acquisition Function들 중 Expected Improvement(EI) 를 사용\n",
        "# xi : exploration 강도 (기본값은 0.0)\n",
        "bo.maximize(init_points=2, n_iter=10, acq='ei', xi=0.01)\n",
        "\n",
        "# ‘iter’는 반복 회차, ‘target’은 목적 함수의 값, 나머지는 입력값을 나타냅니다. \n",
        "# 현재 회차 이전까지 조사된 함숫값들과 비교하여, 현재 회차에 최댓값이 얻어진 경우, \n",
        "# bayesian-optimization 라이브러리는 이를 자동으로 다른 색 글자로 표시하는 것을 확인할 수 있습니다\n",
        "\n",
        "# 찾은 파라미터 값 확인\n",
        "print(bo.max)"
      ],
      "metadata": {
        "id": "qnvOOx3Tzjzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Hyperopt\n",
        "\n",
        "- HyperOpt는 자동화된 하이퍼파라미터 튜닝 프레임워크로서, fmin()이라는 함수 안에는 3가지의 파라미터가 있다:\n",
        "\n",
        "    - Objective Function: 최소화할 손실 함수\n",
        "    - Domain Space: 탐색 범위. 베이지안 최적화에서는 이 범위가 각  하이퍼파라미터에 대해 통계 분포를 만들어낸다.\n",
        "    - Optimization Algorithm : 최적의 조합을 찾기 위한 알고리즘\n",
        "\n",
        "참고 : https://velog.io/@emseoyk/%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D"
      ],
      "metadata": {
        "id": "oNOGx7UrcCXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "K-k_fxgjcDeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages \n",
        "\n",
        "from hyperopt import hp,fmin, tpe, Trials\n",
        "\n",
        "from hyperopt.pyll.base import scope\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "from skopt import space\n",
        "\n",
        "from skopt import gp_minimize\n",
        "\n",
        "#defining a method that will perfrom a 5 split cross validation over\n",
        "\n",
        "#dataset and and will produce the optimum value of the accuracy\n",
        "\n",
        "def optimize(params, x,y):\n",
        "\n",
        "    clf = XGBClassifier(**params)\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for idx in kf.split(X=x,y=y):\n",
        "\n",
        "        train_idx,test_idx = idx[0],idx[1]\n",
        "\n",
        "        xtrain = x[train_idx]\n",
        "\n",
        "        ytrain = y[train_idx]\n",
        "\n",
        "        xtest = x[test_idx]\n",
        "\n",
        "        ytest = y[test_idx]\n",
        "\n",
        "        clf.fit(xtrain,ytrain)\n",
        "\n",
        "        preds =  clf.predict(xtest)\n",
        "\n",
        "        fold_acc = metrics.accuracy_score(ytest,preds)\n",
        "\n",
        "        accuracies.append(fold_acc)\n",
        "\n",
        "    return -1.0 * np.mean(accuracies)\n",
        "\n",
        "#defining a set of values as hp for hyperparameters\n",
        "\n",
        "param_space = {\n",
        "\n",
        "    \"max_depth\" : scope.int(hp.quniform(\"max_depth\",3,20, 1)) ,\n",
        "\n",
        "    \"min_child_weight\" : scope.int(hp.quniform(\"min_child_weight\",1,8, 1)),\n",
        "\n",
        "    \"n_estimators\": scope.int(hp.quniform(\"n_estimators\",100,1500,1)),\n",
        "\n",
        "    'learning_rate': hp.uniform(\"learning_rate\",0.01,1),\n",
        "\n",
        "    'reg_lambda': hp.uniform(\"reg_lambda\",0.01,1),\n",
        "\n",
        "    'gamma': hp.uniform(\"gamma\",0.01,1),\n",
        "\n",
        "    'subsample': hp.uniform(\"subsample\",0.01,1)\n",
        "\n",
        "    }\n",
        "\n",
        "#defiing optimization_fuction as partial and calling optimize within it\n",
        "\n",
        "optimization_fuction = partial(optimize,x = X, y = y) \n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "#Getting the optimum values for hyperparameters\n",
        "\n",
        "result = fmin(\n",
        "\n",
        "    fn = optimization_fuction,\n",
        "\n",
        "    space = param_space,\n",
        "\n",
        "    algo = tpe.suggest,\n",
        "\n",
        "    max_evals = 15,\n",
        "\n",
        "    trials = trials\n",
        "\n",
        ")\n",
        "\n",
        "#Printing the best hyperparemeter set\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "iM-SA_qFcEQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Optuna\n",
        "\n",
        "- Optuna는 ML 알고리즘의 하이퍼파라미터 튜닝을 자동화해주는 오픈소스 툴입니다. 유사한 툴로 Hyperopt가 있지만 사용성과 문서화, 시각화 제공 여부 등에서 Optuna의 손을 들어주는 경우가 많음.\n",
        "\n",
        "- 하이퍼파라미터 튜닝에 쓰고 있는 최신 Automl 기법입니다.\n",
        "- 빠르게 튜닝이 가능하다는 장점이 있음.\n",
        "- 하이퍼파라미터 튜닝 방식을 지정할수 있다. -> 직관적인 api인 튜닝된 lightgbm도 제공해줍니다.\n",
        "\n",
        "- 다른 라이브러리들에 비해 직관적인 장점이 있어 코딩하기 용이합니다.\n"
      ],
      "metadata": {
        "id": "gaNtLF72cFZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 거의 모든 ML/DL 프레임워크에서 사용 가능한 넓은 범용성을 가지고 있다.\n",
        "간단하고 빠르다.\n",
        "- 최신 동향의 다양한 최적화 알고리즘을 갖추고 있다.\n",
        "- 병렬 처리가 가능하다.\n",
        "- 간단한 메소드로 시각화가 가능하다."
      ],
      "metadata": {
        "id": "DgTDs7PVGC37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Optuna를 이해하기 위해서는 다음의 용어에 익숙해져야 한다.\n",
        "\n",
        "    - Study: 목적 함수에 기반한 최적화\n",
        "    - Trial: 목적함수 시행\n",
        "- 쉽게 말해 study는 최적화를 하는 과정이고, trial은 다양한 조합으로 목적함수를 시행하는 횟수를 뜻한다.\n",
        "- Study의 목적은 여러 번의 trial을 거쳐 최적의 하이퍼파라미터 조합을 찾는 것이라고 할 수 있겠다."
      ],
      "metadata": {
        "id": "wO8cko_zGFGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "h3rOl_oqcHAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all the required packages\n",
        "import optuna\n",
        "from sklearn.datasets import load_iris\n",
        "import sklearn.linear_model\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Loading iris dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "#independent feautres\n",
        "X = iris.data\n",
        "\n",
        "# target features\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "5fGjE4mrcH8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "print(optuna.__version__)"
      ],
      "metadata": {
        "id": "UQYpoUkQcJDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages\n",
        "import optuna\n",
        "from functools import partial\n",
        "\n",
        "#defining a method that will perfrom a 5 split cross validation over\n",
        "#dataset and and will produce the optimum value of the accuracy\n",
        "def optimize(trial, x,y):\n",
        "    #parameter set is declare within function\n",
        "    #suggest_uniform : 범위 내의 균일 분포 값을 선택.\n",
        "    #suggest_discrete_uniform : 이산 균등 분포를 값으로 선택.\n",
        "    #suggest_loguniform : 범위 내의 로그 함수 선상의 값을 선택.\n",
        "    reg_lambda = trial.suggest_uniform('reg_lambda',0.01,1)\n",
        "    \n",
        "    n_estimators = trial.suggest_int('n_estimators',100,1500)\n",
        "    \n",
        "    max_depth = trial.suggest_int('max_depth',3,15)\n",
        "    \n",
        "    max_features = trial.suggest_uniform('max_features',0.01,1)\n",
        "    \n",
        "    clf = XGBClassifier(\n",
        "    \n",
        "    n_estimators= n_estimators,\n",
        "\n",
        "    reg_lambda=reg_lambda,\n",
        "\n",
        "    max_depth=max_depth,\n",
        "\n",
        "    max_features= max_features)\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for idx in kf.split(X=x,y=y):\n",
        "\n",
        "        train_idx,test_idx = idx[0],idx[1]\n",
        "\n",
        "        xtrain = x[train_idx]\n",
        "\n",
        "        ytrain = y[train_idx]\n",
        "\n",
        "        xtest = x[test_idx]\n",
        "\n",
        "        ytest = y[test_idx]\n",
        "\n",
        "        clf.fit(xtrain,ytrain)\n",
        "\n",
        "        preds =  clf.predict(xtest)\n",
        "\n",
        "        fold_acc = metrics.accuracy_score(ytest,preds)\n",
        "\n",
        "        accuracies.append(fold_acc)\n",
        "\n",
        "    return -1.0 * np.mean(accuracies)\n",
        "\n",
        "#defiing optimization_fuction as partial and calling optimize within it\n",
        "\n",
        "optimization_fuction = partial(optimize,x = X, y = y) \n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "\n",
        "#Printing the best hyperparemeter set\n",
        "\n",
        "study.optimize(optimization_fuction, n_trials=15)"
      ],
      "metadata": {
        "id": "1H0r9ygVcKDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- mimimize로 찾은 이유 : https://stackoverflow.com/questions/72193393/find-the-value-of-variables-to-maximize-return-of-function-in-python"
      ],
      "metadata": {
        "id": "WD46e556Omz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing packages\n",
        "import optuna\n",
        "from functools import partial\n",
        "\n",
        "#defining a method that will perfrom a 5 split cross validation over\n",
        "#dataset and and will produce the optimum value of the accuracy\n",
        "def optimize(trial, x,y):\n",
        "    #parameter set is declare within function\n",
        "    #suggest_uniform : 범위 내의 균일 분포 값을 선택.\n",
        "    #suggest_discrete_uniform : 이산 균등 분포를 값으로 선택.\n",
        "    #suggest_loguniform : 범위 내의 로그 함수 선상의 값을 선택.\n",
        "    reg_lambda = trial.suggest_uniform('reg_lambda',0.01,1)\n",
        "    \n",
        "    n_estimators = trial.suggest_int('n_estimators',100,1500)\n",
        "    \n",
        "    max_depth = trial.suggest_int('max_depth',3,15)\n",
        "    \n",
        "    max_features = trial.suggest_uniform('max_features',0.01,1)\n",
        "    \n",
        "    clf = XGBClassifier(\n",
        "    \n",
        "    n_estimators= n_estimators,\n",
        "\n",
        "    reg_lambda=reg_lambda,\n",
        "\n",
        "    max_depth=max_depth,\n",
        "\n",
        "    max_features= max_features)\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    for idx in kf.split(X=x,y=y):\n",
        "\n",
        "        train_idx,test_idx = idx[0],idx[1]\n",
        "\n",
        "        xtrain = x[train_idx]\n",
        "\n",
        "        ytrain = y[train_idx]\n",
        "\n",
        "        xtest = x[test_idx]\n",
        "\n",
        "        ytest = y[test_idx]\n",
        "\n",
        "        clf.fit(xtrain,ytrain)\n",
        "\n",
        "        preds =  clf.predict(xtest)\n",
        "\n",
        "        fold_acc = metrics.accuracy_score(ytest,preds)\n",
        "\n",
        "        accuracies.append(fold_acc)\n",
        "\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "#defiing optimization_fuction as partial and calling optimize within it\n",
        "\n",
        "optimization_fuction = partial(optimize,x = X, y = y) \n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "#Printing the best hyperparemeter set\n",
        "\n",
        "study.optimize(optimization_fuction, n_trials=15)"
      ],
      "metadata": {
        "id": "phw9SbcQJmD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an objective function"
      ],
      "metadata": {
        "id": "9zw7Dt_UcOW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## In optuna, A Trial represents a single call of the objective function\n",
        "## Study shows an optimization session which contains a set of trials\n",
        "## Study: optimization based on an objective function\n",
        "## Trial: a single execution of the objective function\n",
        "\n",
        "## In this demo, \"alpha\" is the hyperparameter which is need to be optimized\n",
        "def objective(trial):\n",
        "   \n",
        "    # hyperparameter setting, trial.suggest_uniform will suggest uniform hyperparameter\n",
        "    #alpha between the range of 0.0 to 2.0, lowest value of interval is closed and \n",
        "    #when low=high, it will return low value\n",
        "    alpha = trial.suggest_uniform('alpha', 0.0, 2.0)\n",
        "    \n",
        "    # data loading and train-test split\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
        "    \n",
        "    # model training and evaluation\n",
        "    model = sklearn.linear_model.Lasso(alpha=alpha)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n",
        "\n",
        "    # output: evaluation score\n",
        "    return error"
      ],
      "metadata": {
        "id": "Pr8FbrtvcPdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an study for that ML model and optimize it"
      ],
      "metadata": {
        "id": "J5_c2l7TcRKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "# In Optuna, we use the study object to manage optimization.\n",
        "# Method :func:`~optuna.create_study` returns a study object.\n",
        "# A study object has useful properties for analyzing the optimization outcome.\n",
        "study = optuna.create_study(direction='minimize') #Set minimize for minimization and maximize for maximization.\n",
        "#To start the optimization, we create a study object and pass the objective function to method\n",
        "study.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "id": "MDjBVqYkcPfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualized the above hyperparameter optimization study"
      ],
      "metadata": {
        "id": "3vQMiNdmcTqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all the plot functions\n",
        "from optuna.visualization import plot_edf\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_slice"
      ],
      "metadata": {
        "id": "CFlHgvK9cPh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the optimization history. See :func:`~optuna.visualization.plot_optimization_history` for the details.\n",
        "plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "E3dHCwofcVE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize high-dimensional parameter relationships. See :func:`~optuna.visualization.plot_parallel_coordinate` for the details.\n",
        "plot_parallel_coordinate(study)"
      ],
      "metadata": {
        "id": "oQ6qT2ZLcVHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize individual hyperparameters as slice plot. See :func:`~optuna.visualization.plot_slice` for the details.\n",
        "plot_slice(study)"
      ],
      "metadata": {
        "id": "HNAk09O6cVJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize parameter importances. See :func:`~optuna.visualization.plot_param_importances` for the details.\n",
        "#In this case, we have only one parameter.\n",
        "plot_param_importances(study)"
      ],
      "metadata": {
        "id": "nNK4p89hcY1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize empirical distribution function. See :func:`~optuna.visualization.plot_edf` for the details.\n",
        "plot_edf(study)"
      ],
      "metadata": {
        "id": "4UnJr023cY3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import sklearn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 1. 최소화/최대화할 목적함수 정의\n",
        "def objective(trial):\n",
        "    iris = sklearn.datasets.load_iris()\n",
        "    x, y = iris.data, iris.target\n",
        "\n",
        "# 2. trial object로 하이퍼파라미터 값 추천\n",
        "# 다양한 분류모델을 설정해서 비교할 수 있다.\n",
        "    classifier_name = trial.suggest_categorical('classifier', ['SVC', 'RandomForest'])\n",
        "    #분류 모델이 SVC일 때\n",
        "    if classifier_name == 'SVC':\n",
        "        svc_c = trial.suggest_loguniform('svc_c', 1e-10, 1e10)\n",
        "        classifier_obj = sklearn.svm.SVC(C=svc_c, gamma='auto')\n",
        "    \n",
        "    #분류모델이 랜덤포레스트일 때\n",
        "    else:\n",
        "        rf_max_depth = int(trial.suggest_loguniform('rf_max_depth', 2, 32))\n",
        "        classifier_obj = sklearn.ensemble.RandomForestClassifier(max_depth=rf_max_depth, n_estimators=10)\n",
        "    \n",
        "    accuracy = cross_val_score(classifier_obj, x, y, cv = 4).mean()\n",
        "    return accuracy\n",
        "\n",
        "# 3. study 오브젝트 생성하고 목적함수 최적화하는 단계\n",
        "# 여기서는 목적함수를 정확도로 설정했기 때문에 최대화를 목표로 하고 있지만, 손실함수의 경우 direction='minimize'로 설정\n",
        "study = optuna.create_study(direction='maximize')\n",
        "# 반복 시행 횟수(trial)는 200번으로\n",
        "study.optimize(objective, n_trials=200)"
      ],
      "metadata": {
        "id": "8PahkZBmcY5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시행된 trial 중 최적의 하이퍼파라미터 반환하는 메소드\n",
        "print(study.best_trial.params)\n",
        "\n",
        "# 시행된 trial 중 가장 높은 값 반환하는 메소드\n",
        "optuna_acc = study.best_trial.value\n",
        "print(optuna_acc)"
      ],
      "metadata": {
        "id": "8ELZ5u6Bcd-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "H2MWEFmgcgfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_param_importances(study)\n",
        "\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "E84NoqGTcd_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcXuNtGJ8XVh"
      },
      "source": [
        "# 6.Pycaret\n",
        "\n",
        "- AutoML을 하게 해주는 파이썬 라이브러리\n",
        "- scikit-learning 패키지를 기반으로 하고 있으며 Classification, Regression, Clustering, Anomaly Detection 등 다양한 모델을 지원함.\n",
        "\n",
        "- 공식문서에 설명이 매우 잘 되어 있고, 몇 줄의 코드로 쉽게 구현이 가능하기 때문에 유용하게 사용할 수 있음.\n",
        "\n",
        "- Pycaret을 활용하면 여러 모델의 성능 비교 뿐만 아니라 hyperparameter tunning,  여러 모델을 blending한 모델을 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pycaret 설치\n",
        "!pip install pycaret"
      ],
      "metadata": {
        "id": "Yh8ZZa_khlPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 비교시 catboost가 없다면 다음과 같이 설치합니다.\n",
        "!pip install pycaret[full]"
      ],
      "metadata": {
        "id": "zpqIkD3ChlRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data load / pycaret에서 제공하는 'credit'데이터를 사용함.\n",
        "from pycaret.datasets import get_data\n",
        "dataset = get_data('credit')"
      ],
      "metadata": {
        "id": "J4JAVeY8h9zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test 분리\n",
        "train = dataset.sample(frac=0.95, random_state=786)\n",
        "test = dataset.drop(train.index)\n",
        "train.reset_index(inplace=True, drop=True)\n",
        "test.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "Ffliqt1PhlTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 설정.\n",
        "    - Pycaret을 사용하기 전에 Pycaret에 맞게 데이터를 설정해줘야 함.\n",
        "    - set_up() 함수를 사용하며, 기본적으로 data와 target을 입력해줍니다.\n",
        "    - 입력 후 column에 대한 자료형이 출력되며 enter를 치면 data가 설정됩니다."
      ],
      "metadata": {
        "id": "oJkHjdg0h09e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- set_up(): pycaret을 사용하기 위한 data setting\n",
        "\n",
        "- session_id: random_state와 같은 개념으로 같은 결과가 나올 수 있게 seed를 고정합니다.\n",
        "- data: train 데이터를 입력합니다.\n",
        "- target = target 변수 이름을 입력합니다."
      ],
      "metadata": {
        "id": "4xcqgfWVia87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import *\n",
        "\n",
        "exp_clf = setup(data = train, target = 'default', session_id=123)"
      ],
      "metadata": {
        "id": "FcuFHz7phlVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- 모델 비교**\n",
        "\n",
        "\n",
        "    - 여러 모델을 적합하여 성능을 비교하는 단계"
      ],
      "metadata": {
        "id": "96m0o2VhiVuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = compare_models()"
      ],
      "metadata": {
        "id": "0LZKeUmYhlYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- compare_models(): 다양한 모델 적합 후 성능 비교\n",
        "    - fold: cross_validation의 fold를 지정 (default = 10)\n",
        "    - sort: 정렬기준 지표 설정\n",
        "    - n_select: 상위 n개의 모델 결과만 출력"
      ],
      "metadata": {
        "id": "RPWsFQxWin27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 적합\n",
        "    - 하나의 모델의 적합 결과는 보는 방법."
      ],
      "metadata": {
        "id": "x6B9GiT4itVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = create_model('rf')"
      ],
      "metadata": {
        "id": "k4Mxe5rRimuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- create_model(): 하나의 모델 적합\n",
        "\n",
        "    - fold: cross_validation의 fold 지정 (default = 10)"
      ],
      "metadata": {
        "id": "_QpYBwdujDvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- Tunning**\n",
        "\n",
        "\n",
        "    - tune_model() 함수를 사용해서 모델의 하이퍼파라미터 튜닝을 진행"
      ],
      "metadata": {
        "id": "j5fNHFFxjJ3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_rf = tune_model(rf)"
      ],
      "metadata": {
        "id": "yrY2kz5iimxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tuned_rf를 호출하면 튜닝 결과를 확인할 수 있습니다.\n",
        "\n",
        "- tune_model(model): 모델의 하이퍼파라미터 튜닝\n",
        "\n",
        "- optimize: 평가 metric 지정"
      ],
      "metadata": {
        "id": "9dRdCMCfjYXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Blending**\n",
        "\n",
        "- blend_models() 함수를 사용하면 여러 모델들을 혼합하여 새로운 모델을 생성합니다.\n",
        "모델을 하나씩 생성해서 blend해도 되고 compare_model을 사용하여 생성한 모델을 사용해서 blend할 수 있습니다."
      ],
      "metadata": {
        "id": "_HCTAPHIjzV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 방법 1\n",
        "dt = create_model('dt')\n",
        "rf = create_model('rf')\n",
        "\n",
        "blender_2 = blend_models(estimator_list = [dt, rf])\n",
        "\n",
        "# 방법 2\n",
        "best_model_5 = compare_models(n_select=5)\n",
        "blender_5 = blend_models(best_model_5)"
      ],
      "metadata": {
        "id": "brbvUbqUimzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- blend_models(models): 여러 모델들을 혼합한 새로운 모델을 생성"
      ],
      "metadata": {
        "id": "H1T6A9EBj8M9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- 예측**\n",
        "\n",
        "- finalize_model() 함수로 모델을 설정하면, cross_validation을 사용하여 적합한 모델을 전체 데이터로 마지막으로 학습을 합니다. 마지막 모델을 설정한 후에 predict_model()을 통해 예측을 합니다."
      ],
      "metadata": {
        "id": "moLhPog0lzUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = finalize_model(blender_5)\n",
        "prediction = predict_model(final_model, data = test)"
      ],
      "metadata": {
        "id": "kN8MvE4Lim1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- finalize_model(): 최종 모델로 설정 후 마지막 학습 진행\n",
        "- predict_model(): 예측 결과를 'Label' 변수에 저장"
      ],
      "metadata": {
        "id": "fAI7i5nFl_gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba --upgrade"
      ],
      "metadata": {
        "id": "i9e-hfdMW4vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import *\n",
        "data = setup(diabetes, target = 'Class variable')"
      ],
      "metadata": {
        "id": "XrYbAeG3WfEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) 모델 비교"
      ],
      "metadata": {
        "id": "Vbbw1-D_YHdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models()"
      ],
      "metadata": {
        "id": "bMUSFIatWvU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) 모델 생성"
      ],
      "metadata": {
        "id": "Bt1h-dJcYLxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = create_model('lr')"
      ],
      "metadata": {
        "id": "KVA_ln-aYJp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) 모델 튜닝"
      ],
      "metadata": {
        "id": "MOG68YiyYOrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_lr = tune_model(lr)"
      ],
      "metadata": {
        "id": "Yqu7UtmMYNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Bagging"
      ],
      "metadata": {
        "id": "pADYsftgYRUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bagged_lr = ensemble_model(lr, method = 'Bagging')"
      ],
      "metadata": {
        "id": "cxon1iJdYQnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Stacking"
      ],
      "metadata": {
        "id": "Pt9IyAj8YVLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = create_model('lda')\n",
        "rf = create_model('rf')\n",
        "stacker = stack_models(estimator_list = [lda, rf], meta_model = lr)"
      ],
      "metadata": {
        "id": "5Jv2Sl6YYS7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) Plot"
      ],
      "metadata": {
        "id": "CH8XVpoVYX-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(lr)"
      ],
      "metadata": {
        "id": "HT4hxnExYXEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) 모델 저장"
      ],
      "metadata": {
        "id": "xYjlaH9SYcMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(lr, 'lr_saved')"
      ],
      "metadata": {
        "id": "CatDYXb7Ybb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11) Model load"
      ],
      "metadata": {
        "id": "wji83abQYfIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_saved = load_model('lr_saved')"
      ],
      "metadata": {
        "id": "sHT3oSo_YeOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. auto-sklearn(https://automl.github.io/auto-sklearn/master/index.html)\n",
        "\n",
        "- scikit-learning은 다양한 ML estimator를 제공하고 있음.\n",
        "    - ML 모델을 만들기 위해 scikit-learn을 사용할 때 흔히 고민에 빠지는 포인트가 있습니다.\n",
        "        - 어떤 estimator를 골라야 하나?>\n",
        "        - estimator의 파라미터는 뭘로 세팅을 해야 하나? 값은 어떻게 튜닝을 할까?\n",
        "        - 이런 결정은 다른 사람들은 어떻게 할까?\n",
        "- 소개 글\n",
        "    - auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator.\n",
        "\n",
        "- auto-sklearn의 가장 큰 장점 중 하나는 바로 scikit-learn과의 api 유사성으로 인해 scikit-learn 사용자에게 친숙한 인터페이스를 제공합니다. 이를 통해 classifier, regressor를 구현할 때 별도의 튜닝 포인트 없이 편하게 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "UkraQBrGqMWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 작동원리\n",
        "\n",
        "<img src='https://github.com/automl/auto-sklearn/raw/master/doc/images/askl_pipeline.png'>\n",
        "\n",
        "\n",
        "- auto-sklearn은 AutoML을 CASH 문제를 푸는 것으로 다루고 있습니다.\n",
        "\n",
        "- CASH는 Combined Algorithm Selection and Hyperparameter optimization 의 약자로 한글로 풀면 알고리즘 선택과 하이퍼파라미터 튜닝을 의미합니다.\n",
        "\n",
        "- 위 그림에서 auto-sklearn에서 추가한 단계는 meta-learning 과 ensemble 입니다\n",
        "\n",
        "    - 1) meta-learning 단계는 Bayesian optimizer를 warm start 해주는 역할을 합니다. \n",
        "\n",
        "    - 이 단계를 통해 Bayesian optimizer를 좀더 효율적으로 돌릴 수 있게 됩니다. \n",
        "\n",
        "    - 2) Bayesian optimizer를 통해 하이퍼파라미터 튜닝을 진행합니다 \n",
        "\n",
        "    - 3) 지금까지 테스트한 모델과 파라미터 조합을 Ensemble하여 최적의 조합을 찾습니다."
      ],
      "metadata": {
        "id": "IEfVkF3dqtN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install build-essential swig\n",
        "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install\n",
        "!pip install auto-sklearn\n",
        "\n",
        "for _ in range(3):\n",
        "    try:\n",
        "        import autosklearn.classification\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "else:\n",
        "    raise ImportError(\"failed to import from autosklearn\")"
      ],
      "metadata": {
        "id": "tCC4SUstrMZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.datasets\n",
        "import sklearn.model_selection\n",
        "\n",
        "# From OpenML: https://www.openml.org/d/31\n",
        "X, y = sklearn.datasets.fetch_openml('credit-g', as_frame=True, return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "   X, y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "4LA9i5Doqsk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- auto-sklearn을 사용하기 전에 scikit-learn에 포함된 SVC를 이용하면 다음과 같이 분류할 수 있습니다."
      ],
      "metadata": {
        "id": "ujFzuIiVrAOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "# Create the estimator using the default parameters from sklearn\n",
        "estimator_svc = SVC(\n",
        "    C=1.0, kernel='rbf', gamma='scale', shrinking=True, tol=1e-3,\n",
        "    cache_size=200, verbose=False, max_iter=-1, random_state=42, probability=True\n",
        ")\n",
        "\n",
        "# build and fit the pipeline\n",
        "encoder = ColumnTransformer(transformers = [\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), X.dtypes == \"category\"),\n",
        "    ('cont', StandardScaler(), X.dtypes != \"category\"),\n",
        "])\n",
        "\n",
        "pipeline_svc = Pipeline([\n",
        "    ('encoder', encoder),\n",
        "    ('svc', estimator_svc),\n",
        "])\n",
        "pipeline_svc.fit(X_train, y_train)\n",
        "\n",
        "# Score the model\n",
        "prediction = pipeline_svc.predict_proba(X_test)\n",
        "performance_svc = roc_auc_score(y_test, prediction[:, 1])\n",
        "print(f\"SVC performance is {performance_svc}\")"
      ],
      "metadata": {
        "id": "pxu_hl09q9B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SVC를 사용할 경우 하이퍼파라미터 튜닝을 통해 적절한 파라미터를 찾아가는 과정이 필요합니다.\n",
        "\n",
        "그러면 auto-sklearn을 이용하면 어떨까요?"
      ],
      "metadata": {
        "id": "AfIPT21orCEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import autosklearn.classification\n",
        "import autosklearn.metrics\n",
        "\n",
        "# Create and train an ensemble with AutoML \n",
        "estimator_askl = autosklearn.classification.AutoSklearnClassifier(\n",
        "    time_left_for_this_task=300,\n",
        "    seed=42, \n",
        "    resampling_strategy='cv',\n",
        "    metric=autosklearn.metrics.roc_auc,\n",
        ")\n",
        "# Auto-sklearn ingests the pandas dataframe and detects column types\n",
        "estimator_askl.fit(X_train, y_train, dataset_name='credit-g')\n",
        "\n",
        "# Score the model\n",
        "prediction = estimator_askl.predict_proba(X_test)\n",
        "\n",
        "performance_askl = roc_auc_score(y_test, prediction[:, 1])\n",
        "print(f\"Auto-Sklearn Classifier performance is {performance_askl}\")"
      ],
      "metadata": {
        "id": "VTX3IN8-q9EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 별도의 튜닝없이도 괜찮은 성능의 모델을 만들어볼 수 있었습니다. \n",
        "\n",
        "- auto-sklearn을 돌려서 나온 결과를 좀더 자세히 살펴보겠습니다."
      ],
      "metadata": {
        "id": "Rrkki5vMrFun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(estimator_askl.sprint_statistics())"
      ],
      "metadata": {
        "id": "gLgSrQ-hq9Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator_askl.leaderboard()"
      ],
      "metadata": {
        "id": "ryte32Rlq9I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- auto-sklearn이 sklearn을 완벽히 대체할 silver bullet 이라 생각하지는 않습니다. \n",
        "\n",
        "- 하지만 auto-sklearn은 scikit-learn 사용자들이 적당한 성능을 빠른 시간에 얻기 위해 고려해볼만한 좋은 후보라고 생각합니다. "
      ],
      "metadata": {
        "id": "D5NBo4DcrbwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. TPOT(https://epistasislab.github.io/tpot/)\n",
        "\n",
        "- Python에서 AutoML을 수행하기위한 오픈 소스 라이브러리\n",
        "\n",
        "- 데이터 변환 및 기계 학습 알고리즘에 인기있는 Scikit-Learn 기계 학습 라이브러리를 사용\n",
        "\n",
        "- 유전 프로그래밍 확률 적 글로벌 검색 절차를 사용\n",
        "\n",
        "- 주어진 데이터 세트에 대한 최고 성능의 모델 파이프 라인을 효율적으로 검색\n",
        "\n",
        "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fn5XGo%2Fbtq3yKfzKjO%2FY7C6WkOIfdnYqTAv0ckgxk%2Fimg.png'>"
      ],
      "metadata": {
        "id": "iWnQdVixtXJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TPOT tutorial on the Titanic dataset\n",
        "    - The Titanic machine learning competition on Kaggle is one of the most popular beginner's competitions on the platform. We will use that competition here to demonstrate the implementation of TPOT."
      ],
      "metadata": {
        "id": "6N9s-PB2u-lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "U7uDd1hR7uVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telescope_data=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data',header=None)"
      ],
      "metadata": {
        "id": "iJA8x-9N7YKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telescope_data.head()"
      ],
      "metadata": {
        "id": "kMN6Qxe_7wPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telescope_data.columns = ['fLength', 'fWidth','fSize','fConc','fConcl','fAsym','fM3Long','fM3Trans','fAlpha','fDist','class']"
      ],
      "metadata": {
        "id": "UsyS5MVB7wxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telescope_data.head()"
      ],
      "metadata": {
        "id": "ertytRIp7wz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telescope_data.info()"
      ],
      "metadata": {
        "id": "HRpODo407w1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telescope_data.describe()"
      ],
      "metadata": {
        "id": "iDSPlL977w4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telescope_data['class'].value_counts()"
      ],
      "metadata": {
        "id": "kO0mWaLP70Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telescope_shuffle=telescope_data.iloc[np.random.permutation(len(telescope_data))]\n",
        "tele=telescope_shuffle.reset_index(drop=True)\n",
        "tele.head()"
      ],
      "metadata": {
        "id": "4B6ae_ZI70b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tele['class']=tele['class'].map({'g':0,'h':1})\n",
        "\n",
        "tele.head()"
      ],
      "metadata": {
        "id": "pS_9S3yA70eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tele_class = tele['class'].values"
      ],
      "metadata": {
        "id": "LbmXmHJe7w6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.isnull(tele).any()"
      ],
      "metadata": {
        "id": "x7rey5gk8DeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tele = tele.fillna(-999)"
      ],
      "metadata": {
        "id": "4I7KDt_88DgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "training_indices, validation_indices = training_indices, testing_indices = train_test_split(tele.index,\n",
        "                                                                                            stratify = tele_class,\n",
        "                                                                                            train_size=0.75, test_size=0.25)"
      ],
      "metadata": {
        "id": "9N2b3AUi8Dio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tpot import TPOTClassifier\n",
        "from tpot import TPOTRegressor\n",
        "\n",
        "tpot = TPOTClassifier(generations=5,verbosity=2) \n",
        "\n",
        "tpot.fit(tele.drop('class',axis=1).loc[training_indices].values,\n",
        "         tele.loc[training_indices,'class'].values)"
      ],
      "metadata": {
        "id": "_AkwM6478Dkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpot.score(tele.drop('class',axis=1).loc[validation_indices].values,\n",
        "           tele.loc[validation_indices, 'class'].values)"
      ],
      "metadata": {
        "id": "kV3SKp7l8bWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpot.export('tpot_MAGIC_Gamma_Telescope_pipeline.py')"
      ],
      "metadata": {
        "id": "-OzjvlIC8cvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. H2O\n",
        "\n",
        "- h2o는 java 기반의 머신러닝/AI 플랫폼인데요.\n",
        "\n",
        "- 드라이버가 필요없이 간단한 설정만으로 인공지능을 학습하고 예측할 수 있는 소프트웨어\n",
        "\n",
        "- 인공지능에 대한 지식이 부족하여도 좋은 모델을 누구나 이용할 수 있는 소프트웨어가 개발되었음.\n"
      ],
      "metadata": {
        "id": "Wf1hYALW8xxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "import h2o"
      ],
      "metadata": {
        "id": "JxtiOWZx848d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 다음으로, H2O 클러스터를 시작합니다."
      ],
      "metadata": {
        "id": "RJ1l0xjS88Nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이제 타이타닉 데이터셋을 로드하고, H2O 데이터 프레임으로 변환합니다. 그리고 outcome variable을 지정합니다."
      ],
      "metadata": {
        "id": "Zibmi8AY8-h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.init()"
      ],
      "metadata": {
        "id": "rtxlMHIO84-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df = h2o.import_file(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
        "titanic_df[\"Survived\"] = titanic_df[\"Survived\"].asfactor()"
      ],
      "metadata": {
        "id": "zyPp-VeI9Bgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = titanic_df.split_frame(ratios=[0.8], seed=1)"
      ],
      "metadata": {
        "id": "dffjKcjm9Bit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이제 H2O AutoML을 실행하여 최상의 모델을 생성함."
      ],
      "metadata": {
        "id": "iWIWTRuG9Fve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from h2o.automl import H2OAutoML\n",
        "\n",
        "aml = H2OAutoML(max_runtime_secs=30, seed=1)\n",
        "aml.train(y=\"Survived\", training_frame=train)"
      ],
      "metadata": {
        "id": "RJi1ZM4D9Bk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델링이 완료되면, AutoML 리더보드를 확인하여 모델의 성능을 비교할 수 있습니다."
      ],
      "metadata": {
        "id": "xsaSag8I9kdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aml.leaderboard.head()"
      ],
      "metadata": {
        "id": "6sx9I8Bb9ldc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 가장 성능이 좋은 모델을 선택하고 test 데이터셋에서 모델의 성능을 평가합니다."
      ],
      "metadata": {
        "id": "fN2HtrMm9mtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = aml.leader\n",
        "predictions = best_model.predict(test)"
      ],
      "metadata": {
        "id": "RHR_5Bif9oqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 밖에 AutoML을 할 수 있는 라이브러리들은 다양하게 존재합니다:\n",
        "\n",
        "- TPOT\n",
        "- FLAML\n",
        "- EvalML\n",
        "- AutoKeras\n",
        "- Auto-ViML\n",
        "- AutoGluon\n",
        "- MLBox"
      ],
      "metadata": {
        "id": "Km96J6YZ9uQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Hyperparam Tuning & AutoML](https://www.kaggle.com/code/sudalairajkumar/hyperparam-tuning-automl)"
      ],
      "metadata": {
        "id": "cjJOfaXb-YY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고) \n",
        "\n",
        "### Numba\n",
        " - Python 및 Numpy 코드의 하위 집합을 빠른 기계 코드로 변환하는 오픈소스 Jit 컴파일러.\n",
        "\n",
        " - Just In Time 컴파일러를 사용해 파이썬 코드 내에서 일반 코드 및 Numpy를 아주 빠른 속도로 처리 가능한 기능을 제공."
      ],
      "metadata": {
        "id": "LXMue7hEXHpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 공식문서에 설명\n",
        "    - Numba makes Python code fast.\n",
        "    - Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code."
      ],
      "metadata": {
        "id": "9kIyoPXvn0if"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Numbda 작동원리\n",
        "    - 데커레이팅된 함수에 대한 파이썬 bytecode를 읽고 이를 함수의 입력 인수 유형에 대한 정보와 결합한다,.\n",
        "    - 코드를 분석하고 최적화한 후, LLVM compiler library를 사용하여 함수의 machine code 버전을 만들고, 이를 사용자의 CPU 능력에 맞춤.\n",
        "    - 이 complied된 버전이 앞으로 그 함수를 호출할 때마다 사용된다.\n",
        "\n",
        "- Numbda 모듈이 모든 파이썬 코드를 최적화 해주는 것은 아니다. 일부 파이썬 코드와 Numpy 대해서만 작동하며 다른 모듈을 이용한 코드를 최적화 시켜주지는 못한다. ex)Numbda는 Pandas를 이해하지 못함. 특정 목적에 따라 충분히 활용할 수 있는 가치가 있는 모듈."
      ],
      "metadata": {
        "id": "d1t_QtqdoIQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter\n",
        "from numba import jit\n",
        "\n",
        "# 일반적인 loop\n",
        "def pure_sum(n):\n",
        "    result = 0\n",
        "    for i in range(0, n+1):\n",
        "        result += i\n",
        "    return result\n",
        "\n",
        "# Numba 모듈 사용\n",
        "@jit(nopython=True, cache=True)\n",
        "def numba_sum(n):\n",
        "    result = 0\n",
        "    for i in range(0, n+1):\n",
        "        result += i\n",
        "    return result\n",
        "\n",
        "# 시간 재기: 일반\n",
        "start = perf_counter()\n",
        "pure_sum(100000000)\n",
        "print(perf_counter() - start)\n",
        "\n",
        "# 시간 재기에 앞서 먼저 Compile을 해준다.\n",
        "numba_sum(1)\n",
        "\n",
        "# 시간 재기: Numba\n",
        "start = perf_counter()\n",
        "numba_sum(100000000)\n",
        "print(perf_counter() - start)"
      ],
      "metadata": {
        "id": "bfiOI_ASn2v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- @jit 데커레이터의 모드\n",
        "    - @jit 데커레이터는 nopython과 object라는 2가지 compilation 모드로 작동한다.\n",
        "    - 위 예제에서 nopython=True를 통해 Numba에게 nopython 모드로 작동하라고 지시한 셈인데, 이 모드는 decorate된 function을 근본적으로 compile하여 Python Interpreter의 개입 없이 전체가 작동하도록 한다.\n",
        "    - 만약 nopython 모드가 잘 작동하지 않을 경우, Numba은 object 모드를 통해 compile 할 수 있다. @jit(nopython=True)가 아닌 @jit이라고만 데커레이팅하면 이 모드가 작동하게 된다.\n",
        "    - 본 모드에서는 Numba은 loop를 식별하여 machine code에서 compile하며 나머지는 Intereter code에서 compile하게 된다. 더 나은 성능을 기대한다면 이 모드가 아닌 nopython 모드를 사용해야 한다. \n",
        "    "
      ],
      "metadata": {
        "id": "hTIBibfDourG"
      }
    }
  ]
}