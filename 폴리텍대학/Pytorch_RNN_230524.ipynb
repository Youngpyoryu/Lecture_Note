{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### RNN의 many to many 구조에 대한 간단 예"
      ],
      "metadata": {
        "id": "-An1wGPjZg7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "model = nn.RNN(input_size, hidden_size,num_layers,batch_frist=True)\n",
        "output, h_n = model(input)\n",
        "```\n",
        "\n",
        "- input_size : input의 feature수\n",
        "- hidden_size :  은닉상태의 feature 수\n",
        "- num_layers : 은닉층의 수 / num_layers가 2 이상이면 다층 RNN(Multi-layer RNN)이 됨.\n",
        "- batch_frist : input 텐서와 output 텐서 형태에서 batch_size의 위치에 대한 옵션\n",
        "    - True이면 batch가 맨 앞에 위치함.\n",
        "\n",
        "- input 텐서의 형태는 (batch_size, sequence_length, input_size) 순서\n",
        "\n",
        "- output 텐서의 형태는 (batch_size, sequence_length, num_directions *hidden_size) 순서\n",
        "    - num_directions은 방향의 수를 나타냄. Bidirectional RNN을 제외하고는 1이다.\n",
        "    - batch_first 옵션은 은닉상태의 형태에는 적용되지는 않음.\n",
        "\n"
      ],
      "metadata": {
        "id": "7hgPeM4PcRll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.RNN의 출력에는 output, h_n이 있음.\n",
        "    - output은 모든 타임 스텝에 대한 결과이고, h_n은 t=n인 마지막 타임 스텝에 대한 은닉 상태 값이다.\n",
        "    - h_n 형태는 (num_layers * num_directions, batch_size, hidden_size)이다.\n",
        "    - 이것은 batch_first=True 지정유무와 무관하다."
      ],
      "metadata": {
        "id": "3JgwkXyRddX-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hys6KnUnZTBa",
        "outputId": "84db3540-a70b-49a6-c130-cca256fd67d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input :  torch.Size([4, 5, 1]) \n",
            " tensor([[[ 1.],\n",
            "         [ 2.],\n",
            "         [ 3.],\n",
            "         [ 4.],\n",
            "         [ 5.]],\n",
            "\n",
            "        [[ 6.],\n",
            "         [ 7.],\n",
            "         [ 8.],\n",
            "         [ 9.],\n",
            "         [10.]],\n",
            "\n",
            "        [[11.],\n",
            "         [12.],\n",
            "         [13.],\n",
            "         [14.],\n",
            "         [15.]],\n",
            "\n",
            "        [[16.],\n",
            "         [17.],\n",
            "         [18.],\n",
            "         [19.],\n",
            "         [20.]]])\n",
            "\n",
            "output :  torch.Size([4, 5, 2]) \n",
            " tensor([[[-0.0819,  0.8100],\n",
            "         [-0.4311,  0.9332],\n",
            "         [-0.3162,  0.9748],\n",
            "         [-0.3979,  0.9875],\n",
            "         [-0.3675,  0.9944]],\n",
            "\n",
            "        [[-0.1081,  0.9953],\n",
            "         [-0.5145,  0.9986],\n",
            "         [-0.3269,  0.9995],\n",
            "         [-0.4254,  0.9997],\n",
            "         [-0.3820,  0.9999]],\n",
            "\n",
            "        [[-0.1342,  0.9999],\n",
            "         [-0.5245,  1.0000],\n",
            "         [-0.3458,  1.0000],\n",
            "         [-0.4382,  1.0000],\n",
            "         [-0.3982,  1.0000]],\n",
            "\n",
            "        [[-0.1601,  1.0000],\n",
            "         [-0.5328,  1.0000],\n",
            "         [-0.3648,  1.0000],\n",
            "         [-0.4506,  1.0000],\n",
            "         [-0.4143,  1.0000]]], grad_fn=<TransposeBackward1>)\n",
            "\n",
            "hidden :  torch.Size([1, 4, 2]) \n",
            " tensor([[[-0.3675,  0.9944],\n",
            "         [-0.3820,  0.9999],\n",
            "         [-0.3982,  1.0000],\n",
            "         [-0.4143,  1.0000]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "data = [[[1],[2],[3],[4],[5]],\n",
        "        [[6],[7],[8],[9],[10]],\n",
        "        [[11],[12],[13],[14],[15]],\n",
        "        [[16],[17],[18],[19],[20]]]\n",
        "\n",
        "inputs = torch.FloatTensor(np.array(data))\n",
        "\n",
        "INPUT_SIZE=1\n",
        "SEQUENCE_LENGTH=5\n",
        "HIDDEN_SIZE = 2\n",
        "NUM_LAYERS=1\n",
        "BACTH_SIZE=4\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "model = nn.RNN(input_size= INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, batch_first = True)\n",
        "#input_size : (batch, seq_len, input_size)\n",
        "#output size : (batch,seq_len, num_directions*hidden_size)\n",
        "#h_n shape : (num_layers * num_directions, batch, hidden_size)\n",
        "output, h_n = model(inputs)\n",
        "\n",
        "print('Input : ', inputs.shape, '\\n', inputs)\n",
        "print('\\noutput : ', output.shape, '\\n', output)\n",
        "print('\\nhidden : ', h_n.shape, '\\n', h_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.RNN 함수에서 batch_first=True이므로, 형태는 (batch_size, sequence_length, input_size) = (4,5,1)이고, 출력 데이터 형태도 (batch,sequence_length, num_direction *hidden_size) = (4,5,2) / 은닉상태의 형태는 batch_first=True는 지정과 무관하게 (num*layers * num_directions, batch, hidden_size) = (1,4,2)"
      ],
      "metadata": {
        "id": "AirmwtXbfxdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위는 20개의 데이터를 nn.RNN 클래스에서 원하는 형태에 맞추어 미리 변환한 후 모델 구축에 사용함.\n",
        "\n",
        "- 이번에는 20개의 데이터를 view()함수에 의해 원하는 형태로 변환한 후 RNN 모델을 구축해보자."
      ],
      "metadata": {
        "id": "C3VnlG_Kg_NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "data = torch.Tensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "#print('Data : ', data.shape, '\\n', data)\n",
        "\n",
        "INPUT_SIZE=1\n",
        "SEQUENCE_LENGTH=5\n",
        "HIDDEN_SIZE = 2\n",
        "NUM_LAYERS=1\n",
        "BACTH_SIZE=4\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "model = nn.RNN(input_size= INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, batch_first = True)\n",
        "#input_size : (batch, seq_len, input_size)\n",
        "input = data.view(BACTH_SIZE,SEQUENCE_LENGTH,INPUT_SIZE)\n",
        "#output size : (batch,seq_len, num_directions*hidden_size)\n",
        "#h_n shape : (num_layers * num_directions, batch, hidden_size)\n",
        "output, h_n = model(input)\n",
        "\n",
        "print('Input : ', input.shape, '\\n', input)\n",
        "print('\\noutput : ', output.shape, '\\n', output)\n",
        "print('\\nhidden : ', h_n.shape, '\\n', h_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qU_ACiTZ_-O",
        "outputId": "a4b8816a-bfd6-43a8-b787-b02ec3d67cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input :  torch.Size([4, 5, 1]) \n",
            " tensor([[[ 1.],\n",
            "         [ 2.],\n",
            "         [ 3.],\n",
            "         [ 4.],\n",
            "         [ 5.]],\n",
            "\n",
            "        [[ 6.],\n",
            "         [ 7.],\n",
            "         [ 8.],\n",
            "         [ 9.],\n",
            "         [10.]],\n",
            "\n",
            "        [[11.],\n",
            "         [12.],\n",
            "         [13.],\n",
            "         [14.],\n",
            "         [15.]],\n",
            "\n",
            "        [[16.],\n",
            "         [17.],\n",
            "         [18.],\n",
            "         [19.],\n",
            "         [20.]]])\n",
            "\n",
            "output :  torch.Size([4, 5, 2]) \n",
            " tensor([[[-0.0819,  0.8100],\n",
            "         [-0.4311,  0.9332],\n",
            "         [-0.3162,  0.9748],\n",
            "         [-0.3979,  0.9875],\n",
            "         [-0.3675,  0.9944]],\n",
            "\n",
            "        [[-0.1081,  0.9953],\n",
            "         [-0.5145,  0.9986],\n",
            "         [-0.3269,  0.9995],\n",
            "         [-0.4254,  0.9997],\n",
            "         [-0.3820,  0.9999]],\n",
            "\n",
            "        [[-0.1342,  0.9999],\n",
            "         [-0.5245,  1.0000],\n",
            "         [-0.3458,  1.0000],\n",
            "         [-0.4382,  1.0000],\n",
            "         [-0.3982,  1.0000]],\n",
            "\n",
            "        [[-0.1601,  1.0000],\n",
            "         [-0.5328,  1.0000],\n",
            "         [-0.3648,  1.0000],\n",
            "         [-0.4506,  1.0000],\n",
            "         [-0.4143,  1.0000]]], grad_fn=<TransposeBackward1>)\n",
            "\n",
            "hidden :  torch.Size([1, 4, 2]) \n",
            " tensor([[[-0.3675,  0.9944],\n",
            "         [-0.3820,  0.9999],\n",
            "         [-0.3982,  1.0000],\n",
            "         [-0.4143,  1.0000]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 언어 모델\n",
        "    - 순차적으로 입력된 자료를 바탕으로 다음에 나올 단어(word)나 문자(character)를 예측하는 모델로 자연어 처리나 음성인식 분야에 활용되고 있다.\n",
        "    - 단어(word)를 기반으로 학습하는 단어-레벨 언어 모델(word-level language model) 과 문자(character)를 기반으로 학습하는 문자-레벨 언어 모델(word-level language model)이 있다."
      ],
      "metadata": {
        "id": "wA3yYyw1hcZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- epoch이 증가할수록 손실함수 값이 작아지면서 RNN 모델은 목표값을 잘 예측함을 알 수 있다."
      ],
      "metadata": {
        "id": "wSmB44czdMA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- hell에 해당되는 숫자 데이터 x_data, 'hell'에 해당되는 원-핫 인코딩 표현 x_one_hot, 그리고 'hell'에 대한 목표값 y_data에 대한 코드"
      ],
      "metadata": {
        "id": "-md3BUfYd3mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data=[[0,1,2,2]] #hell\n",
        "#batch_size=1\n",
        "x_one_hot = [[[1,0,0,0], #h\n",
        "             [0,1,0,0],#e\n",
        "             [0,0,1,0], #l\n",
        "             [0,0,1,0]]] #l\n",
        "y_data = [[1,2,2,3]] #ello"
      ],
      "metadata": {
        "id": "Su6JXN-XePa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.RNN 함수에서 인자 결정\n",
        "    - input_size를 정한다. 여기서는 input_size=4\n",
        "    - hidden_size를 정하기 위해서는 nn.RNN함수에서 outputs의 형태를 고려해야한다. \n",
        "    - 출력이 하나는 outputs로 하고 다른 하나는 다음 타임 스텝에서 hidden_state로 들어가기 때문이다."
      ],
      "metadata": {
        "id": "QkzLiqLvej_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_set = ['h','e','l','o']\n",
        "input_size = len(char_set) #=4\n",
        "hidden_size = len(char_set) #=4\n",
        "num_layers=1"
      ],
      "metadata": {
        "id": "Q2FzOdS6e6Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 배열을 텐서로 변환\n"
      ],
      "metadata": {
        "id": "JIKIRsDce-6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transform as torch tensor\n",
        "inputs = torch.FloatTensor(x_one_hot)\n",
        "labels = torch.LongTensor(y_data)\n",
        "print('입력 데이터의 크기 : {}'.format(inputs.shape))\n",
        "print('레이블의 크기 : {}'.format(labels.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECcSHdOMe9dy",
        "outputId": "456082b9-87ce-4e02-dbda-84c7d58fbd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 데이터의 크기 : torch.Size([1, 4, 4])\n",
            "레이블의 크기 : torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입력 데이터의 형태는 [1,4,4]는 (batch_size, sequence_length, input_size)이다."
      ],
      "metadata": {
        "id": "NEJWl4R9fULD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RNN 모델 생성\n",
        "    - batch_first이면, 입력 데이터의 크기는 (bacth_size, sequence_length, input_size) 순서가 된다."
      ],
      "metadata": {
        "id": "7OgdCV6BfJU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declare RNN\n",
        "#batch_first gruarantees the order=(batch_size,sequence_length,input_size)\n",
        "rnn = torch.nn.RNN(input_size, hidden_size,num_layers, batch_first=True) #batch_first guarantees the order of ouput = (B, S, F)\n",
        "print(rnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWX5HpC8fIYo",
        "outputId": "3a279a50-f4e8-4bc4-9221-0e24282a3d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(4, 4, batch_first=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실함수와 최적화 방법 선택"
      ],
      "metadata": {
        "id": "oLd3X_VOgAkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loss & optimizer setting\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "Wlko4pf0fIa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RNN 모델 학습"
      ],
      "metadata": {
        "id": "asVb7xHPgEGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  outputs, _ = rnn(inputs)\n",
        "  loss = loss_function(outputs.view(-1, input_size), labels.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  #print(outputs)\n",
        "  result = outputs.data.numpy().argmax(axis=2)\n",
        "  #print(result)\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  #print(result_str)\n",
        "  print('epoch=',i+1,',', \"loss: \", round(loss.item(),4),',', \"pred: \", result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX_FJr7qfIdB",
        "outputId": "e6732912-904a-4341-8512-d848473600b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch= 1 , loss:  1.3764 , pred:  eeeo\n",
            "epoch= 2 , loss:  1.1519 , pred:  elee\n",
            "epoch= 3 , loss:  1.0187 , pred:  elll\n",
            "epoch= 4 , loss:  0.9007 , pred:  ello\n",
            "epoch= 5 , loss:  0.8291 , pred:  ello\n",
            "epoch= 6 , loss:  0.7649 , pred:  ello\n",
            "epoch= 7 , loss:  0.7002 , pred:  ello\n",
            "epoch= 8 , loss:  0.6456 , pred:  ello\n",
            "epoch= 9 , loss:  0.6024 , pred:  ello\n",
            "epoch= 10 , loss:  0.5628 , pred:  ello\n",
            "epoch= 11 , loss:  0.534 , pred:  ello\n",
            "epoch= 12 , loss:  0.5119 , pred:  ello\n",
            "epoch= 13 , loss:  0.4961 , pred:  ello\n",
            "epoch= 14 , loss:  0.4855 , pred:  ello\n",
            "epoch= 15 , loss:  0.4748 , pred:  ello\n",
            "epoch= 16 , loss:  0.4678 , pred:  ello\n",
            "epoch= 17 , loss:  0.4591 , pred:  ello\n",
            "epoch= 18 , loss:  0.4537 , pred:  ello\n",
            "epoch= 19 , loss:  0.4468 , pred:  ello\n",
            "epoch= 20 , loss:  0.4425 , pred:  ello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "loss = loss_function(outputs.view(-1, input_size).labels.view(-1)\n",
        "```\n",
        "\n",
        "- nn.CrossEntropyLoss()함수를 사용하여 손실함수를 계산하는 경우 nn.CrossEntropyLoss()함수는 2개의 텐서 인자를 받는다.\n",
        "\n",
        "- 하나는 예측된 output값이고 다른 하나는 목표값이다. (인자들의 데이터 형태에 주의해야 한다, 그 이유는 데이터 형태가 서로 맞지 않은 경우 오류가 발생하기 때문이다.)\n",
        "\n",
        "- 현재 outputs.view(-1,input_size)의 형태는 [4,4]이고 y.view(-1)의 형태는 [4]이다. 이처럼 nn.CrossEntropyLoss()함수의 인자로서 outputs.view(-1, input_size)의 형태가 [4,?]인 경우 y.view(-1)의 형태는 [4]가 되어야 한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Upxm4B7hgmks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declare RNN\n",
        "#batch_first gruarantees the order=(batch_size,sequence_length,input_size)\n",
        "rnn = torch.nn.RNN(input_size, hidden_size,num_layers, batch_first=True) #batch_first guarantees the order of ouput = (B, S, F)\n",
        "outputs, _ = rnn(inputs)\n",
        "print(outputs.view(-1, input_size).shape)\n",
        "print(labels.view(-1).shape)\n",
        "\n",
        "#loss = loss_function(outputs.view(-1, input_size),label_view(-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Mu0ucyfIfO",
        "outputId": "36421c6c-0769-42b2-a1df-53f5d776ed7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "result = outputs.data.numpy().argmax(axis=2)\n",
        "\n",
        "```\n",
        "- 최댓값이 있는 인덱스를 구하는 함수.\n",
        "    - 2차원 배열인 경우 axis=0이면 열, axis=1이면 행을 기준으로 계산.\n",
        "    - 3차원 배열인 경우 axis=1이면 열, axis=2이면 행을 기준으로 계산한다.\n",
        "    \n"
      ],
      "metadata": {
        "id": "JEWLaw81iEk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)\n",
        "result = outputs.data.numpy().argmax(axis=2)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4xhbNwDh8_n",
        "outputId": "d7a32594-a795-4281-9735-9675acd90e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.2983, -0.1935,  0.2680, -0.1059],\n",
            "         [ 0.6007,  0.3669, -0.1000, -0.3462],\n",
            "         [-0.3116,  0.0516,  0.0056, -0.4168],\n",
            "         [ 0.1862, -0.0535,  0.2869, -0.2876]]], grad_fn=<TransposeBackward1>)\n",
            "[[0 0 1 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- numpy.argmax()함수와 유사한 numpy.max()함수가 있다. 사용 예를 한번 봐보자."
      ],
      "metadata": {
        "id": "Vn7l3WYljT4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([[1,2,3,4],[4,5,6,7],[7,8,9,10]])\n",
        "print('array=\\n', arr)\n",
        "print('dimension',arr.ndim)\n",
        "print('argmax:', arr.argmax(axis=1))\n",
        "print('max:',arr.max(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxWL0zWkh9B5",
        "outputId": "95183741-f564-4495-af54-6af545d9dc71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array=\n",
            " [[ 1  2  3  4]\n",
            " [ 4  5  6  7]\n",
            " [ 7  8  9 10]]\n",
            "dimension 2\n",
            "argmax: [3 3 3]\n",
            "max: [ 4  7 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 3차원 배열에서 numpy.argmax()함수와 numpy.max()함수의 사용 예"
      ],
      "metadata": {
        "id": "_L5t74mFj9wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "arr = np.array([[[1,2,3,4],[4,5,6,7],[7,8,9,10]]])\n",
        "print('array=\\n', arr)\n",
        "print('dimension',arr.ndim)\n",
        "print('argmax:', arr.argmax(axis=2))\n",
        "print('max:',arr.max(axis=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4nIE6UJh9F9",
        "outputId": "695cdbc2-7429-431e-d7d8-2bf18532d90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array=\n",
            " [[[ 1  2  3  4]\n",
            "  [ 4  5  6  7]\n",
            "  [ 7  8  9 10]]]\n",
            "dimension 3\n",
            "argmax: [[3 3 3]]\n",
            "max: [[ 4  7 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)\n",
        "print(np.squeeze(result))\n",
        "print([char_set[c] for c in np.squeeze(result)])\n",
        "result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "print(result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl-OlWXGh9Ib",
        "outputId": "9a586764-c6e5-4935-a20c-1a3d475d5e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 2]]\n",
            "[0 0 1 2]\n",
            "['h', 'h', 'e', 'l']\n",
            "hhel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "|#word level language model\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "\n",
        "char_set = ['h','e','l','o']\n",
        "input_size = len(char_set) #=4\n",
        "hidden_size = len(char_set) #=4\n",
        "num_layers=1\n",
        "\n",
        "x_data=[[0,1,2,2]] #hell\n",
        "#batch_size=1\n",
        "x_one_hot = [[[1,0,0,0], #h\n",
        "             [0,1,0,0],#e\n",
        "             [0,0,1,0], #l\n",
        "             [0,0,1,0]]] #l\n",
        "y_data = [[1,2,2,3]] #ello\n",
        "\n",
        "#transform as torch tensor\n",
        "inputs = torch.FloatTensor(x_one_hot)\n",
        "labels = torch.LongTensor(y_data)\n",
        "print('입력 데이터의 크기 : {}'.format(inputs.shape))\n",
        "print('레이블의 크기 : {}'.format(labels.shape))\n",
        "\n",
        "#declare RNN\n",
        "#batch_first gruarantees the order=(batch_size,sequence_length,input_size)\n",
        "rnn = torch.nn.RNN(input_size, hidden_size, batch_first=True) #batch_first guarantees the order of ouput = (B, S, F)\n",
        "\n",
        "#loss & optimizer setting\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=0.1)\n",
        "\n",
        "#start training\n",
        "\n",
        "for i in range(20):\n",
        "  outputs, _ = rnn(inputs)\n",
        "  loss = criterion(outputs.view(-1, input_size), labels.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  #print(outputs)\n",
        "  result = outputs.data.numpy().argmax(axis=2)\n",
        "  #print(result)\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  #print(result_str)\n",
        "  print('epoch=',i+1,',', \"loss: \", round(loss.item(),4),',', \"pred: \", result_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NfAjJifhPzH",
        "outputId": "0601538e-b95e-43fe-bab0-e0ecfdfc5aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 데이터의 크기 : torch.Size([1, 4, 4])\n",
            "레이블의 크기 : torch.Size([1, 4])\n",
            "epoch= 1 , loss:  1.1658 , pred:  elll\n",
            "epoch= 2 , loss:  0.9308 , pred:  llll\n",
            "epoch= 3 , loss:  0.816 , pred:  lllo\n",
            "epoch= 4 , loss:  0.7669 , pred:  lloo\n",
            "epoch= 5 , loss:  0.7018 , pred:  lllo\n",
            "epoch= 6 , loss:  0.6431 , pred:  ello\n",
            "epoch= 7 , loss:  0.5951 , pred:  ello\n",
            "epoch= 8 , loss:  0.5559 , pred:  ello\n",
            "epoch= 9 , loss:  0.5248 , pred:  ello\n",
            "epoch= 10 , loss:  0.5012 , pred:  ello\n",
            "epoch= 11 , loss:  0.4836 , pred:  ello\n",
            "epoch= 12 , loss:  0.469 , pred:  ello\n",
            "epoch= 13 , loss:  0.4572 , pred:  ello\n",
            "epoch= 14 , loss:  0.4503 , pred:  ello\n",
            "epoch= 15 , loss:  0.4463 , pred:  ello\n",
            "epoch= 16 , loss:  0.4414 , pred:  ello\n",
            "epoch= 17 , loss:  0.437 , pred:  ello\n",
            "epoch= 18 , loss:  0.4338 , pred:  ello\n",
            "epoch= 19 , loss:  0.4284 , pred:  ello\n",
            "epoch= 20 , loss:  0.4232 , pred:  ello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word level language model\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "\n",
        "#hyperparameters\n",
        "learning_rate=0.1\n",
        "num_epochs=20\n",
        "\n",
        "char_set = ['h','e','l','o']\n",
        "\n",
        "#Teach hello:hell->ello\n",
        "x_data=[[0,1,2,2]] #hell\n",
        "#batch_size=1\n",
        "x_one_hot = [[[1,0,0,0], #h\n",
        "             [0,1,0,0],#e\n",
        "             [0,0,1,0], #l\n",
        "             [0,0,1,0]]] #l\n",
        "y_data = [[1,2,2,3]] #ello\n",
        "\n",
        "#As we have one batch of samples, we will change them to variabels only once\n",
        "inputs = torch.Tensor(x_one_hot)\n",
        "labels = torch.LongTensor(y_data)\n",
        "num_classes = 4\n",
        "input_size=4 #one-hot size\n",
        "hidden_size=4 #output from the RNN. 4 to directly predict one-hot\n",
        "num_layers = 1\n",
        "\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(RNN,self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size  = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size,num_classes)\n",
        "    def forward(self,x):\n",
        "        out, _ = self.rnn(x)\n",
        "        #Reshape output from (bacth, seq_len, hidden_size) to (batch*seq_len, hidden_size)\n",
        "        out = out.view(-1, self.hidden_size)\n",
        "        #Return outputs applied to fully connected layer\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "#Instantiate RNN Model\n",
        "rnn = RNN(num_classes, input_size, hidden_size, num_layers)\n",
        "#Set loss & optimizer  function\n",
        "loss_function = torch.nn.CrossEntropyLoss() #Softmax is internally computed.\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "\n",
        "#Tran the model\n",
        "for epoch in range(num_epochs):\n",
        "  outputs = rnn(inputs)\n",
        "  loss = loss_function(outputs, labels.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  result = outputs.data.numpy().argmax(axis=1)\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  print('epoch=',epoch+1,',', \"loss: \", round(loss.item(),4),',', \"pred =  \", ''.join(result_str)) #ello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnsO5yN1pmVi",
        "outputId": "7ec8deb5-191a-4339-f3a6-bae45eabf6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch= 1 , loss:  1.688 , pred =   hhhh\n",
            "epoch= 2 , loss:  1.3476 , pred =   hlll\n",
            "epoch= 3 , loss:  1.1333 , pred =   llll\n",
            "epoch= 4 , loss:  1.0257 , pred =   llll\n",
            "epoch= 5 , loss:  0.9769 , pred =   llll\n",
            "epoch= 6 , loss:  0.931 , pred =   llll\n",
            "epoch= 7 , loss:  0.8573 , pred =   llll\n",
            "epoch= 8 , loss:  0.7595 , pred =   elll\n",
            "epoch= 9 , loss:  0.6604 , pred =   elll\n",
            "epoch= 10 , loss:  0.5792 , pred =   elll\n",
            "epoch= 11 , loss:  0.5104 , pred =   elll\n",
            "epoch= 12 , loss:  0.4391 , pred =   ello\n",
            "epoch= 13 , loss:  0.3983 , pred =   ello\n",
            "epoch= 14 , loss:  0.3603 , pred =   ello\n",
            "epoch= 15 , loss:  0.3088 , pred =   ello\n",
            "epoch= 16 , loss:  0.2781 , pred =   ello\n",
            "epoch= 17 , loss:  0.2522 , pred =   ello\n",
            "epoch= 18 , loss:  0.2101 , pred =   ello\n",
            "epoch= 19 , loss:  0.1761 , pred =   ello\n",
            "epoch= 20 , loss:  0.146 , pred =   ello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word level language model\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device', device)\n",
        "\n",
        "torch.manual_seed(0) #reproduclibility\n",
        "\n",
        "#hyperparameters\n",
        "learning_rate=0.1\n",
        "num_epochs=20\n",
        "\n",
        "input_str = 'hell'\n",
        "label_str = 'ello'\n",
        "\n",
        "char_set = list(set(input_str+label_str))\n",
        "#print(char_set)\n",
        "#char_set = ['h','e','l','o']\n",
        "\n",
        "input_size = len(char_set) # RNN input size(one hot size)\n",
        "hidden_size = len(char_set) # RNN Output size\n",
        "num_classes = len(char_set) # final output size (RNN or softamx, etc.)\n",
        "num_layers = 1\n",
        "#batch_size = 1 #one sentence\n",
        "\n",
        "char_to_index = dict((c,i) for i,c in enumerate(char_set)) #문자에 고유한 정수 인덱스 부여\n",
        "#print(char_to_index)\n",
        "\n",
        "#1차원 리스트\n",
        "\n",
        "x_data = [char_to_index[c] for c in input_str]\n",
        "y_data = [char_to_index[c] for c in label_str]\n",
        "#print(x_data)\n",
        "#print(y_data)\n",
        "\n",
        "#2차원 리스트\n",
        "#텐서 연산인 unsqueeze(0)을 통해 해결할 수도 있었음.\n",
        "x_data = [x_data]\n",
        "y_data = [y_data]\n",
        "#print(x_data)\n",
        "#print(y_data)\n",
        "\n",
        "for x in x_data:\n",
        "    x_one_hot = [np.eye(input_size)[x]]\n",
        "#print(x_one_hot)\n",
        "#As we have one batch of samples, we will change them the variables only once\n",
        "inputs = torch.Tensor(x_one_hot)\n",
        "labels = torch.LongTensor(y_data)\n",
        "inputs = inputs.to(device)\n",
        "label = labels.to(device)\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(RNN,self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size  = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size = input_size, hidden_size = hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size,num_classes)\n",
        "    def forward(self,x):\n",
        "        out, _ = self.rnn(x)\n",
        "        #Reshape output from (bacth, seq_len, hidden_size) to (batch*seq_len, hidden_size)\n",
        "        out = out.view(-1, self.hidden_size)\n",
        "        #Return outputs applied to fully connected layer\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "#Instantiate RNN Model\n",
        "rnn = RNN(num_classes, input_size, hidden_size, num_layers)\n",
        "#Set loss & optimizer  function\n",
        "loss_function = torch.nn.CrossEntropyLoss() #Softmax is internally computed.\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "\n",
        "#Tran the model\n",
        "for epoch in range(num_epochs):\n",
        "  outputs = rnn(inputs)\n",
        "  loss = loss_function(outputs, labels.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  result = outputs.data.numpy().argmax(axis=1)\n",
        "  result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
        "  print('epoch=',epoch+1,',', \"loss: \", round(loss.item(),4),',', \"pred =  \", ''.join(result_str)) #ello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I0dCB8W844F",
        "outputId": "42eab792-7b71-48f8-e9cc-7d51d7253796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cpu\n",
            "epoch= 1 , loss:  1.5623 , pred =   eeee\n",
            "epoch= 2 , loss:  1.1786 , pred =   elll\n",
            "epoch= 3 , loss:  1.0232 , pred =   llll\n",
            "epoch= 4 , loss:  0.9527 , pred =   llll\n",
            "epoch= 5 , loss:  0.891 , pred =   llll\n",
            "epoch= 6 , loss:  0.804 , pred =   llll\n",
            "epoch= 7 , loss:  0.6936 , pred =   elll\n",
            "epoch= 8 , loss:  0.588 , pred =   elll\n",
            "epoch= 9 , loss:  0.502 , pred =   elll\n",
            "epoch= 10 , loss:  0.4263 , pred =   ello\n",
            "epoch= 11 , loss:  0.3486 , pred =   ello\n",
            "epoch= 12 , loss:  0.2792 , pred =   ello\n",
            "epoch= 13 , loss:  0.2243 , pred =   ello\n",
            "epoch= 14 , loss:  0.1786 , pred =   ello\n",
            "epoch= 15 , loss:  0.1419 , pred =   ello\n",
            "epoch= 16 , loss:  0.1138 , pred =   ello\n",
            "epoch= 17 , loss:  0.0918 , pred =   ello\n",
            "epoch= 18 , loss:  0.0742 , pred =   ello\n",
            "epoch= 19 , loss:  0.0601 , pred =   ello\n",
            "epoch= 20 , loss:  0.0488 , pred =   ello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Airline Passengers\n",
        "    - 1949년 1월부터 1960년 1`2월까지 매달 국제선 승객의 수에 대한 데이터."
      ],
      "metadata": {
        "id": "wpHxE9oSAXwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDDFrBWY_EVC",
        "outputId": "dc71d7f7-4fa9-4988-cc7a-d9ba23c01d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-21 01:50:13--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2180 (2.1K) [text/plain]\n",
            "Saving to: ‘airline-passengers.csv’\n",
            "\n",
            "\rairline-passengers.   0%[                    ]       0  --.-KB/s               \rairline-passengers. 100%[===================>]   2.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-21 01:50:13 (30.0 MB/s) - ‘airline-passengers.csv’ saved [2180/2180]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load package\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "yMKb5VUB_bNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data"
      ],
      "metadata": {
        "id": "GbnbZKMQAmOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = pd.read_csv('airline-passengers.csv')\n",
        "\n",
        "training_set = training_set.iloc[:,1:2].values\n",
        "\n",
        "plt.xlabel('month')\n",
        "plt.ylabel('number of passengers (1000s)')\n",
        "plt.plot(training_set)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "YndoWZ75_ejE",
        "outputId": "0b7cf774-72f4-4ecc-e49d-bea704e5c1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시계열 데이터이므로 몇 개의 타임스텝을 현재 시점에 반영할 것 인지 정합니다.\n",
        "\n",
        "- 즉, 현재 시점의 값은 지정한 시퀀스 길이에 맞게 직전 몇 개의 값과 연관되게끔 데이터를 재구성하는 것."
      ],
      "metadata": {
        "id": "VHa8BRzWApIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "training_data = sc.fit_transform(training_set)\n",
        "\n",
        "seq_length = 4\n",
        "x, y = sliding_windows(training_data, seq_length)\n",
        "\n",
        "train_size = int(len(y) * 0.30)\n",
        "test_size = len(y) - train_size\n",
        "\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY = Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))\n",
        "\n",
        "print(training_data.shape)\n",
        "print(dataX.shape)\n",
        "print(dataY.shape)\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxm0UhUW_gpT",
        "outputId": "908a8537-0673-4b7f-9b7c-7563808054c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144, 1)\n",
            "torch.Size([139, 4, 1])\n",
            "torch.Size([139, 1])\n",
            "torch.Size([41, 4, 1])\n",
            "torch.Size([41, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "이제는 시계열 데이터 모델링을 위한 LSTM 모델을 구현해줄 차례입니다. LSTM (Long Short-Term Memory) 는 입력 시퀀스의 타임 스텝 $t$에 따라 hidden state $h_t$, cell state $c_t$에 따른 출력을 Equation 1과 같이 계산합니다. Equation 1의 $i_t, f_t, g_t, o_t$는 각각 input, forget, cell, output 게이트이며 $\\sigma$는 sigmoid 함수를 말합니다.\n",
        "\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Savvas-Varsamopoulos/publication/329362532/figure/fig5/AS:699592479870977@1543807253596/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell_W640.jpg'>"
      ],
      "metadata": {
        "id": "LF469EGLEluP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch 에서는 torch.nn 모듈에서 LSTM 클래스를 쉽게 호출할 수 있습니다. LSTM 클래스 생성시 필요한 파라미터는 다음과 같습니다. \"num_layer\" 아규먼트를 통해 Multi-layer LSTM을 쉽게 구성할 수 있으며 \"num_layer\"가 2 이상일 경우, 타임스텝 $t$, layer $l$에 대한 입력으로는 ($x_t^l, l \\geq 2$) $h_t^{l-1}$에 dropout이 적용된 텐서가 적용됩니다."
      ],
      "metadata": {
        "id": "NXwe8LfHE7QP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- input_size : 입력 $x$의 feature차원\n",
        "- hidden_size : hidden_feature 차원\n",
        "- num_layers : LSTM 층의 개수로 2개 이상일 경우 bais항을 추가할지 말지를 결정.\n",
        "- bias : default : True / bais 항을 추가할지 말지를 결정.\n",
        "- batch_frist : default : False, True일 경우 입력, 출력 모두 [배치사이즈, 입력 길이, feature 차원] 으로 구성되고 fasle일 경우 입력, 출력 모두 [입력 길이, 배치 사이즈, feature 차원]이 됨. 이러한 텐서 차원 순서는 hidden/cell state에는 적용되지 않습니다.\n",
        "\n",
        "- dropout : 마지막 layer의 출력을 제외하고 dropout을 적용함."
      ],
      "metadata": {
        "id": "WDvsgu-HE9_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델을 사용할 때 주의할 점은 각 타임스텝 별로 hidden / cell state 가 업데이트되는 구조로 동작하기 때문에 초기 $h_0, c_0$를 목적에 맞게 선언해줄 수 있다는 점입니다 각각 [$D$*num_layers, 배치 사이즈, feature 차원] 크기로 되어있고 $D$는 bi-directional 일 경우 2, one-directional 일 경우 1이고 따로 제공되지 않을 경우 디폴트는 0으로 할당됩니다. 또한, 입력, 출력의 텐서 구조는 \"batch_first\" 아규먼트가 True / False 여부에 따라 배치 차원이 어디에 위치할지 결정됩니다. 일반적으로 배치 차원은 맨 앞에 있는 것이 편리하므로 \"batch_first=True\"로 설정하는 것이 낫습니다."
      ],
      "metadata": {
        "id": "w1ak0-VAFify"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델에 대해서 forward 함수를 진행할 경우 출력은 \"output, $(h_n, c_n)$\" 이 됩니다. 출력텐서는 (\"output\") \"batch_first\" 아규먼트에 따라 True일 경우 [배치 사이즈, 입력 길이, $D$*feature 차원] 으로 구성되며 각 타임스텝 $t$에 따른 마지막 LSTM layer의 $h_t$를 담습니다. $h_n, c_n$의 크기는 [$D$*num_layers, 배치 사이즈, feature 차원] 으로 구성되며 마지막 타임스텝의 hidden / cell state가 담깁니다"
      ],
      "metadata": {
        "id": "gQ28VbwNFkVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        c_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        \n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        \n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "PAWhp2zS_jGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- $h_0, c_0$는 hidden / cell state의 초기값이기 때문에 requires_grad=False로 설정된 zero 텐서를 넣어줍니다.\n",
        "- 현재 시퀀스 길이는 4이고 마지막 시퀀스에 대해 fully-connected layer를 달아주고 싶기 때문에 $h_n$에 대하여 fully-connected layer를 진행시킵니다. \n",
        "LSTM 모델의 결과로 나오는 \"output\"의 마지막 타임스텝 값은 $h_n$과 같습니다."
      ],
      "metadata": {
        "id": "UOWzQjtcFrDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "rlucDaDxFt6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
        "\n",
        "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = lstm(trainX)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # obtain the loss function\n",
        "    loss = criterion(outputs, trainY)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_ojB7mZ_k_5",
        "outputId": "b5980890-1372-45c3-fe8d-406d4f27c2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.23084\n",
            "Epoch: 100, loss: 0.00385\n",
            "Epoch: 200, loss: 0.00320\n",
            "Epoch: 300, loss: 0.00253\n",
            "Epoch: 400, loss: 0.00180\n",
            "Epoch: 500, loss: 0.00125\n",
            "Epoch: 600, loss: 0.00108\n",
            "Epoch: 700, loss: 0.00104\n",
            "Epoch: 800, loss: 0.00102\n",
            "Epoch: 900, loss: 0.00100\n",
            "Epoch: 1000, loss: 0.00098\n",
            "Epoch: 1100, loss: 0.00097\n",
            "Epoch: 1200, loss: 0.00095\n",
            "Epoch: 1300, loss: 0.00094\n",
            "Epoch: 1400, loss: 0.00092\n",
            "Epoch: 1500, loss: 0.00091\n",
            "Epoch: 1600, loss: 0.00090\n",
            "Epoch: 1700, loss: 0.00088\n",
            "Epoch: 1800, loss: 0.00088\n",
            "Epoch: 1900, loss: 0.00087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test\n",
        "\n",
        "- 테스트 진행 시에는 전에 선언했던 \"MinMaxScaler\" 객체의 \"inverse_transform\" 함수를 이용하여 원래 데이터 값으로 복원시킵니다."
      ],
      "metadata": {
        "id": "AwdXg9AcFwKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm.eval()\n",
        "\n",
        "# predict on training and test data\n",
        "all_predict = lstm(dataX)\n",
        "\n",
        "data_predict = all_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "\n",
        "data_predict = sc.inverse_transform(data_predict)\n",
        "dataY_plot = sc.inverse_transform(dataY_plot)\n",
        "\n",
        "plt.axvline(x=train_size, c='r', linestyle='--', label='right limit of GT used')\n",
        "\n",
        "plt.plot(dataY_plot, label='GT')\n",
        "plt.plot(data_predict, label='predictions')\n",
        "plt.suptitle('Time-Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "rtPLQwLlAIdB",
        "outputId": "5a2dfe5f-8ba5-4eb1-cd77-082264718d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 참고) https://hongl.tistory.com/194\n",
        "\n"
      ],
      "metadata": {
        "id": "mW-0hr_HF5Ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torchtext는 자연어 처리(NLP)분야에서 사용되는 dataloader, torchtext는 파일 가져오기, 토큰화, 단어 집합, 생성, 인코딩, 단어 벡터 생성 등의 작업을 지원하기 때문에 자연어 처리에서 많이 사용되고 있음."
      ],
      "metadata": {
        "id": "sg7Z6ivWOAST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BddcGwARc8Kj",
        "outputId": "ae872c44-90dd-4f12-d314-070ce37f8830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.4\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.4) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.4) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.4) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.4) (1.3.0)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.2\n",
            "    Uninstalling torchtext-0.15.2:\n",
            "      Successfully uninstalled torchtext-0.15.2\n",
            "Successfully installed torchtext-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import datasets, data # 자연어 데이터셋을 다루기 위해 토치비전이 아닌 토치 텍스트를 사용합니다.\n",
        "\n",
        "# 하이퍼파라미터 정의\n",
        "BATCH_SIZE = 64\n",
        "lr = 0.001\n",
        "EPOCHS = 10\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"다음 기기로 학습합니다:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfK_vS5COQbH",
        "outputId": "4f97151b-6de2-4b91-a34e-0057194847a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로딩하기\n",
        "# 텍스트 형태의 영화 리뷰들과 그에 해당하는 리뷰들을 텐서로 바꿔주기\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "# sequential = True : 데이터셋이 순차적인 데이터셋임을 명시\n",
        "# batch_first = True : 신경망에 입력되는 텐서의 첫 번째 차원값을 batch size로 지정\n",
        "# lower = True : 텍스트 데이터 속 모든 영문 알파벳이 소문자가 되도록 처리\n",
        "LABEL = data.Field(sequential=False, batch_first=True) #Label은 순차적 데이터가 아님\n",
        "trainset, testset = datasets.IMDB.splits(TEXT, LABEL) # train test 분리\n",
        "TEXT.build_vocab(trainset, min_freq=5) # 워드 임베딩에 필요한 단어 사전(word vocabulary) 만들기\n",
        "# min_freq = 5 : 학습 데이터에서 최소 5번 이상 등장한 단어만을 사전에 담음\n",
        "LABEL.build_vocab(trainset)\n",
        "\n",
        "# 학습용 데이터를 학습셋 80% 검증셋 20% 로 나누기\n",
        "trainset, valset = trainset.split(split_ratio=0.8)\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (trainset, valset, testset), batch_size=BATCH_SIZE,\n",
        "        shuffle=True, repeat=False)\n",
        "\n",
        "\n",
        "vocab_size = len(TEXT.vocab) #사전 속 단어들의 개수와 레이블 수 지정\n",
        "n_classes = 2\n",
        "\n",
        "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
        "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHWzoJsmc66j",
        "outputId": "88d38871-1099-4014-bdf2-0c986d77f4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 34.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RNN의 입력이 길어지면 기울기(경사도) 폭발(gradient explosion) 혹은 기울기(경사도) 소실(vanishing gradient)이 발생 가능합니다\n",
        "- 이러한 단점이 보완된 것이 GRU(Gated Recurrent Unit)로, GRU는 시계열 데이터 속 벡터 사이의 정보 전달량을 조절함으로써 기울기를 적정하게 유지하고 문장 앞부분의 정보가 끝까지 도달할 수 있도록 돕습니다.\n",
        "GRU에는 시계열 데이터 내 정보 전달량을 조절하는 업데이트 게이트(update gate)와 리셋 게이트(reset gate)라는 개념이 존재합니다.\n",
        "- 리셋 게이트는 새로운 입력이 이전 은닉 벡터와 어떻게 조합하는지를 결정합니다."
      ],
      "metadata": {
        "id": "mA9St5BKfJlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN 모델 구현\n",
        "class BasicGRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(BasicGRU, self).__init__()\n",
        "        print(\"Building Basic GRU model...\")\n",
        "        self.n_layers = n_layers # 은닉 벡터들의 '층'이라고 할 수 있는 n_layers를 정의합니다.(보통 2이하로 정의)\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim) \n",
        "        # n_vocab : 전체 데이터셋의 모든 단어를 사전형태로 나타냈을 때 그 사전에 등재된 단어 수\n",
        "        # embed_dim : 임베딩된 단어 텐서가 지니는 차원 값\n",
        "        self.hidden_dim = hidden_dim # 은닉 벡터(hidden vector)의 차원값과 드롭아웃을 정의합니다.\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True) #위의 이유로 GRU를 사용합니다.\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes) # 압축된 텐서를 신경망에 통과시켜 예측을 출력합니다.\n",
        "\n",
        "    def forward(self, x): # 입력되는 x는 한 배치 속에 있는 모든 영화평입니다.\n",
        "        x = self.embed(x) # 워드 임베딩하면 시계열 데이터(벡터의 배열)로 변환됩니다.\n",
        "        h_0 = self._init_state(batch_size=x.size(0)) #첫 번쨰 은닉 벡터 H0를 정의해 x와 함께 입력해줍니다.\n",
        "        x, _ = self.gru(x, h_0)  # [i, b, h]\n",
        "        h_t = x[:,-1,:] # 영호 리뷰 배열들을 압축한 은닉벡터입니다.\n",
        "        self.dropout(h_t)\n",
        "        logit = self.out(h_t)  # [b, h] -> [b, o]\n",
        "        return logit\n",
        "    \n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        # parameters() 함수는 신경망 모듈의 가중치 형태를 반복자(iterator) 형태를 반환합니다.\n",
        "        # 즉 weight는 nn.GRU 모듈의 첫 번째 가중치 텐서를 말합니다.\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "metadata": {
        "id": "4tIizRUrdVEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습함수와 평가함수 구현\n",
        "\n",
        "#학습함수\n",
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter): # 반복마다 배치 데이터를 반환합니다.\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1)  # 1과 2의 레이블 값을 모든 값에서 1씩 빼서 0과 1로 변환\n",
        "        optimizer.zero_grad() # 매번 기울기를 새로 계산\n",
        "        logit = model(x) \n",
        "        loss = F.cross_entropy(logit, y) \n",
        "        loss.backward()\n",
        "        optimizer.step() #오차를 구하고 최적화 반복\n",
        "        \n",
        "#평가함수\n",
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum') #오차의 합 구하기\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy #오찻값과 정확도의 평균 반환"
      ],
      "metadata": {
        "id": "uPVzsqVglQZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 객체 정의\n",
        "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(DEVICE)\n",
        "# 모델 내 은닉벡터의 차원값 = 256, 임베딩된 토큰의 차원값 = 128로 임의 설정\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr) # 최적화 알고리즘으로 Adam 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VroAwrm4lRsv",
        "outputId": "25199287-55a6-487e-8ef6-457dce4fbbd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Basic GRU model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#검증오차(val_loss) 최소화된 모델 저장\n",
        "best_val_loss = None\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, train_iter)\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
        "    \n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"snapshot\"):\n",
        "            os.makedirs(\"snapshot\")\n",
        "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
        "        best_val_loss = val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ndINDmWlSrz",
        "outputId": "bcbb4b35-608e-4b7d-e500-3a09e6a4ed99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[이폭: 1] 검증 오차: 0.71 | 검증 정확도:49.62\n",
            "[이폭: 2] 검증 오차: 0.69 | 검증 정확도:52.72\n",
            "[이폭: 3] 검증 오차: 0.69 | 검증 정확도:53.44\n",
            "[이폭: 4] 검증 오차: 0.74 | 검증 정확도:50.08\n",
            "[이폭: 5] 검증 오차: 0.65 | 검증 정확도:60.78\n",
            "[이폭: 6] 검증 오차: 0.37 | 검증 정확도:84.06\n",
            "[이폭: 7] 검증 오차: 0.32 | 검증 정확도:86.66\n",
            "[이폭: 8] 검증 오차: 0.31 | 검증 정확도:87.72\n",
            "[이폭: 9] 검증 오차: 0.34 | 검증 정확도:86.98\n",
            "[이폭: 10] 검증 오차: 0.36 | 검증 정확도:86.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증셋에서 가장 성능이 좋았던 모델을 불러와 테스트\n",
        "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iter)\n",
        "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwkRKKIjlT6C",
        "outputId": "b8646d40-f1a6-4cfd-9c7e-bff7bee8d47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 오차:  0.33 | 테스트 정확도: 85.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seq2Seq 기계 번역\n",
        "  - 2010년 이후 인공지능에서 가장 큰 관심을 받은 건 알파고지만, 그와 더불어 크게 화제가 된 머신러닝 모델이 언어를 다른 언어로 해석해주는 뉴럴 기계 번역(Neural Machine Translation)모델입니다.\n",
        "  - RNN 기반의 번역 모델인 Sequence to Sequence (줄여서 Seq2Seq) 모델은 기계 번역의 새로운 패러다임을 열었다고 할 정도로 뛰어난 성능을 보여줬습니다.\n",
        "  - Seq2Seq 모델은 시퀀스(Sequence)를 입력받아 또 다른 시퀀스를 출력합니다. 한마디로 문장을 다른 문장으로 번역해주는 모델입니다.\n",
        "  - 일반적으로 Seq2Seq와 같은 기계 번역 모델이 이러한 능력을 학습하려면 흔히 병렬 말뭉치(parallel corpora)라고 하는 원문과 번역문이 쌍을 이루는 형태의 많은 텍스트 데이터가 필요합니다. 따라서 이런 모델을 제대로 학습시키려면 당연히 강력한 GPU, 복잡한 텍스트 전처리 과정, 긴 학습시간 등 많은 리소스가 됩니다.\n",
        "\n",
        "\n",
        "따라서, 이번 예제에서는 Seq2Seq 모델을 아주 간소화하여 한 언어의 문장을 다른 언어의 문장으로 번역하는 덩치 큰 모델이 아닌, 영어 알파벳 문자열 \"hello\"를 스페인어 알파벳 문자열 \"hola\"로 번역하는 미니 Seq2Seq 모델을 구현해보겠습니다.\n",
        "\n",
        "#### 개요\n",
        "- Seq2Seq는 각자 다른 역할을 하는 두 개의 RNN을 이어붙인 모델입니다.\n",
        "- 번역은 1. 원문을 이해하고, 2. 번역문을 작성하는 두 가지 동작으로 구성되는데, Seq2Seq 모델에서 이 두 역할을 각각 - 인코더(encoder)와 디코더(decoder)라는 두 RNN에 부여함으로써 번역합니다.\n",
        "- 인코더는 원문 속의 모든 단어를 입력받아 문장의 뜻을 내포하는 고정 크기의 텐서를 만들어냅니다. 이렇게 압축된 텐서는 원문의 뜻과 내용을 압축하고 있다고 하여 문맥 벡터(context vector)라고 합니다. 인코더 RNN은 원문 속의 토큰을 차례대로 입력받습니다. 원문 마지막 토큰에 해당하는 은닉 벡터는 원문의 뜻을 모두 내포하는 문맥 벡터입니다.\n",
        "- 디코더 또한 RNN 모델로, 인코더에서 원문 문맥 벡터를 이어받아 번역문 속의 토큰을 차례대로 예상합니다. 번역할 때 '원문이 말하는 바가 무엇인가'를 항상 생각하고 있어야 합니다. 이는 디코더가 번역문의 단어나 토큰을 출력할 때 인코더로부터 정보를 전달받아야 한 다는 뜻이기도 합니다."
      ],
      "metadata": {
        "id": "9R_8fHXnli9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델구현하기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "GLjL3l1zlhqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 한 언어로 된 문장을 다른 언어로 번역하는 작업을 할 때는 보통 단어를 문장의 최소단위로 여겨 단어 단위의 임베딩(word embedding)을 하지만 이번 예제에선 간단한 영단어 \"hello\"를 스페인어 \"hola\"로 번역하는 작업을 할 것이므로 이번 예제에서는 단어 단위의 워드 임베딩이 아닌 글자 단위의 캐릭터 임베딩(Character embedding)을 사용하겠습니다."
      ],
      "metadata": {
        "id": "bC-4uejNp4Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 256  # 총 아스키 코드 개수 (아스키 코드: 영문을 숫자로 변환하는 방식)\n",
        "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
        "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
        "print(\"hello -> \", x_)\n",
        "print(\"hola  -> \", y_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Y-pNaUp29K",
        "outputId": "706e3865-dc6c-46be-d8a7-10376b1500fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello ->  [104, 101, 108, 108, 111]\n",
            "hola  ->  [104, 111, 108, 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아스키 코드 리스트를 파이토치 텐서로 변환\n",
        "x = torch.LongTensor(x_)\n",
        "y = torch.LongTensor(y_)"
      ],
      "metadata": {
        "id": "Sqg9MYxIp6IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seq2Seq 모델 클래스 정의\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.n_layers = 1\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size) # hidden_size가 임베딩된 토큰의 차원값\n",
        "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
        "        self.decoder = nn.GRU(hidden_size, hidden_size) # encoder와 decoder 객체는 GRU\n",
        "        self.project = nn.Linear(hidden_size, vocab_size) # 번역문의 다음 토큰을 예상해내는 신경망\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # 인코더에 들어갈 입력\n",
        "        initial_state = self._init_state()\n",
        "        embedding = self.embedding(inputs).unsqueeze(1)\n",
        "        # embedding = [seq_len, batch_size, embedding_size]\n",
        "        \n",
        "        # 인코더 (Encoder)\n",
        "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
        "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
        "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
        "\n",
        "        # 디코더에 들어갈 입력\n",
        "        decoder_state = encoder_state # 원문을 인코더에 입력시킨 문맥벡터 : encoder_state , 디코더의 첫 번째 은닉벡터 : decoder_state\n",
        "        decoder_input = torch.LongTensor([0]) # 0 : 아스키값의 공백 문자(null)를 뜻함\n",
        "        \n",
        "        # 디코더 (Decoder)\n",
        "        outputs = []\n",
        "        \n",
        "        for i in range(targets.size()[0]): #\"hola\"의 \"h\" 다음에 올 문자가 \"o\"임을 예측하기 위한 for 반복문\n",
        "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
        "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
        "            projection = self.project(decoder_output)\n",
        "            outputs.append(projection) # 디코더의 출력값으로 다음 글자 예측하기\n",
        "            \n",
        "            # 티처 포싱(Teacher Forcing) 사용\n",
        "            # 티처 포싱: 디코더 학습시 실제 번역문의 토큰을 디코더의 전 출력값 대신 입력으로 사용해 학습을 가속하는 방법\n",
        "            decoder_input = torch.LongTensor([targets[i]])\n",
        "\n",
        "        outputs = torch.stack(outputs).squeeze() # 번역문의 모든 토큰에 대한 결괏값들의 배열\n",
        "        return outputs\n",
        "    \n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
      ],
      "metadata": {
        "id": "am_yNVBJp7SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq(vocab_size, 16)\n",
        "criterion = nn.CrossEntropyLoss() # 교차 엔트로피 오차를 구하는 CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3) # 최적화 알고리즘"
      ],
      "metadata": {
        "id": "HkrolagJp8_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1000번의 이폭에 걸쳐 모델 학습\n",
        "log = []\n",
        "for i in range(1000):\n",
        "    prediction = seq2seq(x, y)\n",
        "    loss = criterion(prediction, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_val = loss.data\n",
        "    log.append(loss_val)\n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
        "        _, top1 = prediction.data.topk(1, 1)\n",
        "        print([chr(c) for c in top1.squeeze().numpy().tolist()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDlPtSy4p9zo",
        "outputId": "b9daa235-d69b-4143-ac88-ce6fc9030e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 반복:0 오차: 5.55353307723999\n",
            "['¾', '\\n', '\\n', '\\x88']\n",
            "\n",
            " 반복:100 오차: 1.9585472345352173\n",
            "['o', 'o', 'o', 'a']\n",
            "\n",
            " 반복:200 오차: 0.5188415050506592\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:300 오차: 0.25546300411224365\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:400 오차: 0.15862157940864563\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:500 오차: 0.111066073179245\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:600 오차: 0.08373981714248657\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:700 오차: 0.06610075384378433\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:800 오차: 0.05383450910449028\n",
            "['h', 'o', 'l', 'a']\n",
            "\n",
            " 반복:900 오차: 0.04485679045319557\n",
            "['h', 'o', 'l', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 맷플롯립을 통한 오차가 줄어드는 모습 확인\n",
        "plt.plot(log)\n",
        "plt.ylabel('cross entropy loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vTGf4qq2p-40",
        "outputId": "66f8f2c4-9077-4e25-c68a-f43d81449429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMDB를 활용한 RNN 구현"
      ],
      "metadata": {
        "id": "4FBroRgvIgoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "wETUPqYhqKxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Field는 데이터 전처리를 위해 사용되며 여기에서 사용되는 파라미터는 다음과 같습니다.\n",
        "\n",
        "```\n",
        "torchtext.data.Field(lower=True, fix_length=200, batch_first=False)\n",
        "```\n",
        "\n",
        "- lower : 대문자를 모두 소문자로 변경. 기본값은 False\n",
        "- fix_length : 고정된 길이의 데이터를 얻을 수 있음. 여기에서는 데이터의 길이를 200으로 고정했으며, 200보다 짧으면 패딩 작업(padding)을 통해 200으로 맞추어줌.\n",
        "\n",
        "- batch_frist : 신경망에 입력되는 텐서의 첫번째 차원 값이 배치 크기(batch_size)가 되도록 합니다. 기본값은 false.\n",
        "\n",
        "- 모델의 네트워크로 입력되는 데이터는 [시퀀스 길이, 배치 크기, 은닉층의 뉴런 개수]([seq_len, batch_size, hidden_size]) 형태.\n",
        "  - batch_size = True로 설정하면 [배치크기, 시퀀스 길이, 은닉층뉴런 개수] ([batch_size, seq_len, hidden_size]) 형태로 변경.\n",
        "  - batch_size = True와 무관하게, [은닉층 개수, 배치 크기, 은닉층의 뉴런 개수] (num_layers, batch, hidden_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "vw7Rg-SHIjs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "TEXT = torchtext.data.Field(lower=True, fix_length=200, batch_first=False)\n",
        "LABEL =torchtext.data.Field(sequential=False)"
      ],
      "metadata": {
        "id": "98Vw7Th_H9E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "torchtext.data.Field(sequential=False)\n",
        "```\n",
        "\n",
        "seqential : 데이터에 순서(sequenatial)이 있는지를 나타냄. \n",
        "\n"
      ],
      "metadata": {
        "id": "0FVJ70Z6LyxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "metadata": {
        "id": "weU0PzVKJ2zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- split : 텍스트(text)와 레이블(label)로 분할."
      ],
      "metadata": {
        "id": "xD_Uk_wjL9Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKA_KB9CJ8cW",
        "outputId": "6a4df9e1-411f-4d35-8545-6cfc26a668a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['i', \"haven't\", 'seen', 'this', 'in', 'over', '20yrs', 'but', 'i', 'still', 'remember', 'things', 'about', 'it.<br', '/><br', '/>this', 'film', 'could', 'not', 'have', 'been', 'made', 'in', 'color.', 'the', 'stark', 'grays', 'are', 'what', 'make', 'it,', 'and', 'was', 'life', 'really', 'that', 'simple', 'in', 'the', \"1950's??\", 'what', 'stands', 'out', 'the', 'most', 'in', 'my', 'memory', 'is', 'perry', 'smith', 'going', 'to', 'the', 'gallows.', 'his', 'breathing', 'under', 'the', 'hood', 'just', 'before', 'they', 'sprung', 'the', 'trap.', 'i', \"don't\", 'think', 'i', 'could', 'watch', 'that', 'again.....once', 'is', 'plenty.', \"it's\", 'like', 'that', 'unnamed', 'guy', 'at', 'the', 'beginning', 'of', '\"papillon\"', 'who', 'is', 'dragged', 'out', 'in', 'terror', 'to', 'the', 'guillotine.', 'the', 'guy', 'that', 'said', 'watch', 'this', 'on', 'a', 'double', 'bill', 'with', '\"dead', 'man', 'walking\"', 'should', 'have', 'added', 'the', 'last', '10', 'minutes', 'of', '\"i', 'want', 'to', 'live\"', 'as', 'well.<br', '/><br', '/>some', 'of', 'my', 'ancestors', 'being', '\"aristos\"', 'went', 'to', 'the', 'guillotine', 'in', '1794-95', 'so', 'my', 'feelings', 'on', 'the', 'death', 'penalty', 'are', 'rather', 'intense.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- text와 label을 갖는 사전 형식(dict type)으로 구성되어 있음."
      ],
      "metadata": {
        "id": "0WdHUzgzMH1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "for example in train_data.examples:\n",
        "    text = [x.lower() for x in vars(example)['text']] \n",
        "    text = [x.replace(\"<br\",\"\") for x in text] \n",
        "    text = [''.join(c for c in s if c not in string.punctuation) for s in text] \n",
        "    text = [s for s in text if s] \n",
        "    vars(example)['text'] = text\n",
        "    \n",
        "for example in test_data.examples:\n",
        "    text = [x.lower() for x in vars(example)['text']]\n",
        "    text = [x.replace(\"<br\",\"\") for x in text]\n",
        "    text = [''.join(c for c in s if c not in string.punctuation) for s in text]\n",
        "    text = [s for s in text if s]\n",
        "    vars(example)['text'] = text"
      ],
      "metadata": {
        "id": "36k5zfDZH-PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전처리 코드를 진행. 공백처리, 불필요한 문자 제거 등이 포함됨."
      ],
      "metadata": {
        "id": "wDN9rwH5SZN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(0), split_ratio=0.8)"
      ],
      "metadata": {
        "id": "SvOfXcXlKQwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh2AMGIiKRmb",
        "outputId": "3a393ec9-4de5-4718-d038-863a7c763309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단어 집합을 만들어 보겠습니다.\n",
        "  - IMDB 데이터셋에 포함된 단어들을 이용하여 하나의 딕셔너리와 같은 집합을 만드는 것으로 이해하자.\n",
        "  - 단어 집합을 만들 때, 단어들의 중복은 제거된 상태에서 진행합니다."
      ],
      "metadata": {
        "id": "pEA01fsISlWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doxRmhuBKSnI",
        "outputId": "dc32b556-7bb5-47a7-b9f2-7d8059d33b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 10002\n",
            "Unique tokens in LABEL vocabulary: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "```\n",
        "\n",
        "- train_data : 훈련 데이터셋\n",
        "- max_size : 단어 집합의 크기로 단어 집합에 포함되는 어휘 수\n",
        "- min_freq : 훈련 데이터셋에서 특정 단어의 최소 등장 횟수\n",
        "- vectors : 임베딩 벡터를 지정할 수 있음. 임베딩 벡터는 워드 임베딩의 결과로 나온 벡터. / pytorch에서도 nn.embedding()을 통해 단어를 랜덤한 숫자 값으로 변환한 후 가중치를 학습하는 방법을 제공함.\n",
        "\n"
      ],
      "metadata": {
        "id": "lcC8KiXpUx_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MCkkZc0KUI1",
        "outputId": "9ec26f2f-7d09-4fcc-c85c-7fa5e4862ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f18653d2350>>, {'<unk>': 0, 'pos': 1, 'neg': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "embeding_dim = 100\n",
        "hidden_size = 300\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "E3-2vXfGKVTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BucketIterator : dataloader와 쓰임새가 같습니다.\n",
        "  - 즉, 배치 크기 단위로 값을 차례대로 꺼내어 메모리로 가져오고 싶을 때 사용.\n",
        "  - Field에서 fix_length를 사용하지 않았다면, BuckIterator에서 데이터의 길이를 조정할 수 있음.\n",
        "  - BucketIterator는 비슷한 길이의 데이터를 한 배치에 할당하여 패딩(Padding)을 최소화시켜줌."
      ],
      "metadata": {
        "id": "q7rQZw20SGXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.embedding()을 이용하여 임베딩 처리를 진행해 보자."
      ],
      "metadata": {
        "id": "0-kDxMukXALx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCell_Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_size):\n",
        "        super(RNNCell_Encoder, self).__init__()\n",
        "        self.rnn = nn.RNNCell(input_dim, hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        bz = inputs.shape[1]\n",
        "        ht = torch.zeros((bz, hidden_size)).to(device)\n",
        "\n",
        "        for word in inputs:\n",
        "            ht = self.rnn(word, ht) #재귀적으로 발생하는 상태 값을 처리하기 위한 구문.\n",
        "        return ht\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.em = nn.Embedding(len(TEXT.vocab.stoi), embeding_dim)\n",
        "        self.rnn = RNNCell_Encoder(embeding_dim, hidden_size)\n",
        "        self.fc1 = nn.Linear(hidden_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.em(x)\n",
        "        x = self.rnn(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kYe84moVKWfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "Z7kPNEUBKZrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(epoch, model, trainloader, validloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for b in trainloader:\n",
        "        x, y = b.text, b.label\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            correct += (y_pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            running_loss += loss.item()\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    valid_correct = 0\n",
        "    valid_total = 0\n",
        "    valid_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for b in validloader:\n",
        "            x, y = b.text, b.label\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            valid_correct += (y_pred == y).sum().item()\n",
        "            valid_total += y.size(0)\n",
        "            valid_running_loss += loss.item()\n",
        "\n",
        "    epoch_valid_loss = valid_running_loss / len(validloader.dataset)\n",
        "    epoch_valid_acc = valid_correct / valid_total\n",
        "\n",
        "    print('epoch: ', epoch,\n",
        "          'loss： ', round(epoch_loss, 3),\n",
        "          'accuracy:', round(epoch_acc, 3),\n",
        "          'valid_loss： ', round(epoch_valid_loss, 3),\n",
        "          'valid_accuracy:', round(epoch_valid_acc, 3)\n",
        "          )\n",
        "    return epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc"
      ],
      "metadata": {
        "id": "uzlJoePbKaxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss, epoch_acc, epoch_valid_loss, epoch_valid_acc = training(epoch, model,train_iterator,valid_iterator)\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    valid_loss.append(epoch_valid_loss)\n",
        "    valid_acc.append(epoch_valid_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhyqFYhkKcId",
        "outputId": "6a1d7346-c543-430f-aeb3-e9fd8aed21d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss：  0.011 accuracy: 0.494 valid_loss：  0.011 valid_accuracy: 0.507\n",
            "epoch:  1 loss：  0.011 accuracy: 0.504 valid_loss：  0.011 valid_accuracy: 0.5\n",
            "epoch:  2 loss：  0.011 accuracy: 0.511 valid_loss：  0.011 valid_accuracy: 0.494\n",
            "epoch:  3 loss：  0.011 accuracy: 0.517 valid_loss：  0.011 valid_accuracy: 0.493\n",
            "epoch:  4 loss：  0.011 accuracy: 0.527 valid_loss：  0.011 valid_accuracy: 0.511\n",
            "273.1426305770874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(epoch, model, testloader):    \n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    test_running_loss = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for b in testloader:\n",
        "            x, y = b.text, b.label\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            test_correct += (y_pred == y).sum().item()\n",
        "            test_total += y.size(0)\n",
        "            test_running_loss += loss.item()\n",
        "\n",
        "    epoch_test_loss = test_running_loss / len(testloader.dataset)\n",
        "    epoch_test_acc = test_correct / test_total\n",
        "\n",
        "    print('epoch: ', epoch,\n",
        "          'test_loss： ', round(epoch_test_loss, 3),\n",
        "          'test_accuracy:', round(epoch_test_acc, 3)\n",
        "          )\n",
        "    return epoch_test_loss, epoch_test_acc"
      ],
      "metadata": {
        "id": "FUAYoRKpKdO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_test_loss, epoch_test_acc = evaluate(epoch,\n",
        "                                               model,\n",
        "                                               test_iterator)\n",
        "    test_loss.append(epoch_test_loss)\n",
        "    test_acc.append(epoch_test_acc)\n",
        "\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3qz4-NVKhD8",
        "outputId": "2665916e-e5e8-45c5-f4d3-aae8cb17e4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 test_loss：  0.011 test_accuracy: 0.503\n",
            "epoch:  1 test_loss：  0.011 test_accuracy: 0.503\n",
            "epoch:  2 test_loss：  0.011 test_accuracy: 0.503\n",
            "epoch:  3 test_loss：  0.011 test_accuracy: 0.503\n",
            "epoch:  4 test_loss：  0.011 test_accuracy: 0.503\n",
            "313.01343297958374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN 계층적 구현\n",
        "  - 미세한 차이만 있다."
      ],
      "metadata": {
        "id": "GWXBOYIniGac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOEHPO_qiGIj",
        "outputId": "2991e2ae-224d-4fd4-b04e-37e177b72908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.4\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m554.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.4) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.4) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.4) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.4) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.4) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.4) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.4) (1.3.0)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.2\n",
            "    Uninstalling torchtext-0.15.2:\n",
            "      Successfully uninstalled torchtext-0.15.2\n",
            "Successfully installed torchtext-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ],
      "metadata": {
        "id": "nga0nPUoh-uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "TEXT = torchtext.data.Field(sequential = True, batch_first = True, lower = True)\n",
        "LABEL = torchtext.data.Field(sequential = False, batch_first = True) "
      ],
      "metadata": {
        "id": "WaFIDhSrh-ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(split_ratio = 0.8)\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "y5Lc4kR9h-ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "zxZkMhByKiN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  vocab_size : 영화 리뷰에 대한 텍스트 길이, \n",
        "- n_classes : 레이블(긍정,부정)값을 지정.\n"
      ],
      "metadata": {
        "id": "uK2NpFTyFC69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 2  "
      ],
      "metadata": {
        "id": "xDguuSMDiXJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True)\n",
        "```\n",
        "\n",
        "- embed_dim : 훈련 데이터셋의 특성(feature) 개수(칼럼 갯수)\n",
        "- self.hidden_dim : 은닉 계층의 뉴런(유닛) 개수\n",
        "- num_layers : RNN 계층의 갯수\n",
        "- batch_first : 기본값은 Flase, 입력 데이터의 형태는 (시퀀스의 길이, 배치 크기, 특성 개수)입니다. True로 설정하게 되면, 배치 크기가 맨 앞으로 오게 되며, (배치 크기, 시퀀스의 길이, 특성 개수) 형태가 됨.\n",
        "\n"
      ],
      "metadata": {
        "id": "rbmCOnGMFMoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicRNN(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p = 0.2):\n",
        "        super(BasicRNN, self).__init__()\n",
        "        self.n_layers = n_layers \n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim) \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers = self.n_layers, batch_first = True) \n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes) \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x) \n",
        "        h_0 = self._init_state(batch_size = x.size(0)) \n",
        "        x, _ = self.rnn(x, h_0) \n",
        "        h_t = x[:, -1, :] \n",
        "        self.dropout(h_t)\n",
        "        logit = torch.sigmoid(self.out(h_t))\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size = 1):\n",
        "        weight = next(self.parameters()).data \n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "metadata": {
        "id": "sx2L1GKMiYHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicRNN(n_layers = 1, hidden_dim = 256, n_vocab = vocab_size, embed_dim = 128, n_classes = n_classes, dropout_p = 0.5)\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "CF2QJzZliZip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1) #뺄셈에 대한 함수, 함수명에 '_'이 붙은 것은 inplace 연산을 하겠다는 의미.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if b % 50 == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(e,\n",
        "                                                                           b * len(x),\n",
        "                                                                           len(train_iter.dataset),\n",
        "                                                                           100. * b / len(train_iter),\n",
        "                                                                           loss.item()))"
      ],
      "metadata": {
        "id": "PH-xClRjial8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):\n",
        "    model.eval()\n",
        "    corrects, total, total_loss = 0, 0, 0\n",
        "\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(device), batch.label.to(device)\n",
        "        y.data.sub_(1) \n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction = \"sum\")\n",
        "        total += y.size(0)\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "        \n",
        "    avg_loss = total_loss / len(val_iter.dataset)\n",
        "    avg_accuracy = corrects / total\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "R0DOkS20ib6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "```\n",
        "\n",
        "- max(1)[1] : max(dim=0)[0]은 최댓값을 나타내고, max(dim=0)[1] 최댓값을 갖는 데이터의 인덱스를 나타냄.\n",
        "\n",
        "- view(y.size()) : logit.max(1)[1] 결과는 y.size() 크기로 변경.\n",
        "\n",
        "-  data == y.data : 모델의 예측 결과(logit.max(1)[1].view(y.size()).data)가 레이블(실제값, y.data)과 같은지 확인함.\n",
        "\n",
        "- sum() : 모델의 예측 결과와 레이블(실제값)이 같으면 그 합을 corrects 변수에 누적하여 저장.\n",
        "\n"
      ],
      "metadata": {
        "id": "p-czhLgsIAHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "LR = 0.001\n",
        "EPOCHS = 5\n",
        "for e in range(1, EPOCHS + 1):\n",
        "    train(model, optimizer, train_iterator)\n",
        "    val_loss, val_accuracy = evaluate(model, valid_iterator)\n",
        "    print(\"[EPOCH: %d], Validation Loss: %5.2f | Validation Accuracy: %5.2f\" % (e, val_loss, val_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENNLsqNAizp4",
        "outputId": "61e959dd-ad6c-43a9-cf08-aad98e224bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/20000 (0%)]\tLoss: 0.695275\n",
            "Train Epoch: 1 [5000/20000 (25%)]\tLoss: 0.699182\n",
            "Train Epoch: 1 [10000/20000 (50%)]\tLoss: 0.701557\n",
            "Train Epoch: 1 [15000/20000 (75%)]\tLoss: 0.696948\n",
            "[EPOCH: 1], Validation Loss:  0.69 | Validation Accuracy:  0.48\n",
            "Train Epoch: 2 [0/20000 (0%)]\tLoss: 0.696892\n",
            "Train Epoch: 2 [5000/20000 (25%)]\tLoss: 0.690230\n",
            "Train Epoch: 2 [10000/20000 (50%)]\tLoss: 0.694637\n",
            "Train Epoch: 2 [15000/20000 (75%)]\tLoss: 0.693824\n",
            "[EPOCH: 2], Validation Loss:  0.69 | Validation Accuracy:  0.49\n",
            "Train Epoch: 3 [0/20000 (0%)]\tLoss: 0.690381\n",
            "Train Epoch: 3 [5000/20000 (25%)]\tLoss: 0.692152\n",
            "Train Epoch: 3 [10000/20000 (50%)]\tLoss: 0.693827\n",
            "Train Epoch: 3 [15000/20000 (75%)]\tLoss: 0.692619\n",
            "[EPOCH: 3], Validation Loss:  0.69 | Validation Accuracy:  0.48\n",
            "Train Epoch: 4 [0/20000 (0%)]\tLoss: 0.692208\n",
            "Train Epoch: 4 [5000/20000 (25%)]\tLoss: 0.692768\n",
            "Train Epoch: 4 [10000/20000 (50%)]\tLoss: 0.702437\n",
            "Train Epoch: 4 [15000/20000 (75%)]\tLoss: 0.692688\n",
            "[EPOCH: 4], Validation Loss:  0.69 | Validation Accuracy:  0.51\n",
            "Train Epoch: 5 [0/20000 (0%)]\tLoss: 0.693034\n",
            "Train Epoch: 5 [5000/20000 (25%)]\tLoss: 0.692962\n",
            "Train Epoch: 5 [10000/20000 (50%)]\tLoss: 0.694657\n",
            "Train Epoch: 5 [15000/20000 (75%)]\tLoss: 0.695360\n",
            "[EPOCH: 5], Validation Loss:  0.69 | Validation Accuracy:  0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_iterator)\n",
        "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sTC-oPIi09f",
        "outputId": "da6e39af-d067-4da6-8bc3-65eb6486b651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  0.69 | Test Accuracy:  0.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "S9fE7q6XtBuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "이제는 시계열 데이터 모델링을 위한 LSTM 모델을 구현해줄 차례입니다. LSTM (Long Short-Term Memory) 는 입력 시퀀스의 타임 스텝 $t$에 따라 hidden state $h_t$, cell state $c_t$에 따른 출력을 Equation 1과 같이 계산합니다. Equation 1의 $i_t, f_t, g_t, o_t$는 각각 input, forget, cell, output 게이트이며 $\\sigma$는 sigmoid 함수를 말합니다.\n",
        "\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Savvas-Varsamopoulos/publication/329362532/figure/fig5/AS:699592479870977@1543807253596/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell_W640.jpg'>"
      ],
      "metadata": {
        "id": "OgJkYMA2s_Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch 에서는 torch.nn 모듈에서 LSTM 클래스를 쉽게 호출할 수 있습니다. LSTM 클래스 생성시 필요한 파라미터는 다음과 같습니다. \"num_layer\" 아규먼트를 통해 Multi-layer LSTM을 쉽게 구성할 수 있으며 \"num_layer\"가 2 이상일 경우, 타임스텝 $t$, layer $l$에 대한 입력으로는 ($x_t^l, l \\geq 2$) $h_t^{l-1}$에 dropout이 적용된 텐서가 적용됩니다."
      ],
      "metadata": {
        "id": "af3WBW9ss_Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- input_size : 입력 $x$의 feature차원\n",
        "- hidden_size : hidden_feature 차원\n",
        "- num_layers : LSTM 층의 개수로 2개 이상일 경우 bais항을 추가할지 말지를 결정.\n",
        "- bias : default : True / bais 항을 추가할지 말지를 결정.\n",
        "- batch_frist : default : False, True일 경우 입력, 출력 모두 [배치사이즈, 입력 길이, feature 차원] 으로 구성되고 fasle일 경우 입력, 출력 모두 [입력 길이, 배치 사이즈, feature 차원]이 됨. 이러한 텐서 차원 순서는 hidden/cell state에는 적용되지 않습니다.\n",
        "\n",
        "- dropout : 마지막 layer의 출력을 제외하고 dropout을 적용함."
      ],
      "metadata": {
        "id": "lJPD1XUUs_Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델을 사용할 때 주의할 점은 각 타임스텝 별로 hidden / cell state 가 업데이트되는 구조로 동작하기 때문에 초기 $h_0, c_0$를 목적에 맞게 선언해줄 수 있다는 점입니다 각각 [$D$*num_layers, 배치 사이즈, feature 차원] 크기로 되어있고 $D$는 bi-directional 일 경우 2, one-directional 일 경우 1이고 따로 제공되지 않을 경우 디폴트는 0으로 할당됩니다. 또한, 입력, 출력의 텐서 구조는 \"batch_first\" 아규먼트가 True / False 여부에 따라 배치 차원이 어디에 위치할지 결정됩니다. 일반적으로 배치 차원은 맨 앞에 있는 것이 편리하므로 \"batch_first=True\"로 설정하는 것이 낫습니다."
      ],
      "metadata": {
        "id": "cnJ76ua0s_Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM 모델에 대해서 forward 함수를 진행할 경우 출력은 \"output, $(h_n, c_n)$\" 이 됩니다. 출력텐서는 (\"output\") \"batch_first\" 아규먼트에 따라 True일 경우 [배치 사이즈, 입력 길이, $D$*feature 차원] 으로 구성되며 각 타임스텝 $t$에 따른 마지막 LSTM layer의 $h_t$를 담습니다. $h_n, c_n$의 크기는 [$D$*num_layers, 배치 사이즈, feature 차원] 으로 구성되며 마지막 타임스텝의 hidden / cell state가 담깁니다"
      ],
      "metadata": {
        "id": "oOFXcaz4s_Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "    \n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n",
        "\n",
        "torch.manual_seed(125)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(125)"
      ],
      "metadata": {
        "id": "jdfSgebLi2sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.5,), (1.0,))\n",
        "])"
      ],
      "metadata": {
        "id": "D_b9HrkVtH7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "\n",
        "download_root = 'MNIST_DATASET/'\n",
        "\n",
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
        "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwXDHfmxtJMo",
        "outputId": "562b3e84-c3a3-4e5b-9fef-dcb031b86788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 471818598.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_DATASET/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 37538175.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 142284726.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 24114593.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_DATASET/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "valid_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)"
      ],
      "metadata": {
        "id": "O0TcL6idtKwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_iters = 6000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)"
      ],
      "metadata": {
        "id": "O9YiAekFtNgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
        "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "    \n",
        "    def forward(self, x, hidden):        \n",
        "        hx, cx = hidden        \n",
        "        x = x.view(-1, x.size(1))\n",
        "        \n",
        "        gates = self.x2h(x) + self.h2h(hx)    \n",
        "        gates = gates.squeeze()        \n",
        "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
        "        \n",
        "        ingate = F.sigmoid(ingate)\n",
        "        forgetgate = F.sigmoid(forgetgate)\n",
        "        cellgate = F.tanh(cellgate)\n",
        "        outgate = F.sigmoid(outgate)\n",
        "        \n",
        "        cy = torch.mul(cx, forgetgate) +  torch.mul(ingate, cellgate)        \n",
        "        hy = torch.mul(outgate, F.tanh(cy))        \n",
        "        return (hy, cy)"
      ],
      "metadata": {
        "id": "cxgdq3UutO96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
        "self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
        "```\n",
        "\n",
        "- 왜 4 *hidden_size가 사용되고 있을까요?\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Savvas-Varsamopoulos/publication/329362532/figure/fig5/AS:699592479870977@1543807253596/Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell_W640.jpg'>\n",
        "\n",
        "- 게이트는 망각, 입력, 셀, 출력으로 구성되어 있다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "99u8MltLXM2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh)\n",
        "```\n",
        "\n",
        "앞의 F.linear\n",
        "- input : 입력층으로 입력되는 훈련 데이터셋의 특성(feature) 수(Column 수)\n",
        "- w_ih : 입력층과 은닉층 사이의 가중치\n",
        "- b_ih : 입력층과 은닉층 사이의 바이어스\n",
        "\n",
        "뒤의 F.linear\n",
        "- hx : 은닉층의 뉴런/유닛 개수(은닉층의 특성(feature) 개수)\n",
        "- w_hh : 은닉층과 은닉층 사이의 가중치\n",
        "- b_hh : 은닉층과 은닉층 사이의 바이어스\n",
        "\n"
      ],
      "metadata": {
        "id": "U6Bx0ZP6e_87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "         \n",
        "        self.layer_dim = layer_dim               \n",
        "        self.lstm = LSTMCell(input_dim, hidden_dim, layer_dim)          \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "         \n",
        "    def forward(self, x):        \n",
        "        if torch.cuda.is_available():\n",
        "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
        "        else:\n",
        "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
        "        else:\n",
        "            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), hidden_dim))\n",
        "                           \n",
        "        outs = []        \n",
        "        cn = c0[0,:,:]\n",
        "        hn = h0[0,:,:]\n",
        "\n",
        "        for seq in range(x.size(1)):\n",
        "            hn, cn = self.lstm(x[:,seq,:], (hn,cn)) \n",
        "            outs.append(hn)\n",
        "                \n",
        "        out = outs[-1].squeeze()        \n",
        "        out = self.fc(out) \n",
        "        return out"
      ],
      "metadata": {
        "id": "otDX0Sg3tQku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28\n",
        "hidden_dim = 128\n",
        "layer_dim = 1  \n",
        "output_dim = 10\n",
        " \n",
        "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1 \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "F3Hm4lUdtSH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_dim = 28 \n",
        "loss_list = []\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):          \n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
        "            labels = Variable(labels)\n",
        "          \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            loss.cuda()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()        \n",
        "        loss_list.append(loss.item())\n",
        "        iter += 1\n",
        "         \n",
        "        if iter % 500 == 0:         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in valid_loader:\n",
        "                if torch.cuda.is_available():\n",
        "                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "                else:\n",
        "                    images = Variable(images.view(-1 , seq_dim, input_dim))\n",
        "                \n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                 \n",
        "                total += labels.size(0)\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "             \n",
        "            accuracy = 100 * correct / total\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB7Y0aNgtTxd",
        "outputId": "2b2c66e8-ea60-4e70-8c2f-758a7ff49b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 2.237457275390625. Accuracy: 21.420000076293945\n",
            "Iteration: 1000. Loss: 0.9968994855880737. Accuracy: 74.94999694824219\n",
            "Iteration: 1500. Loss: 0.42673957347869873. Accuracy: 88.13999938964844\n",
            "Iteration: 2000. Loss: 0.30981600284576416. Accuracy: 93.56999969482422\n",
            "Iteration: 2500. Loss: 0.0558248832821846. Accuracy: 95.69000244140625\n",
            "Iteration: 3000. Loss: 0.09873700886964798. Accuracy: 95.58000183105469\n",
            "Iteration: 3500. Loss: 0.08254366368055344. Accuracy: 96.8499984741211\n",
            "Iteration: 4000. Loss: 0.03308983892202377. Accuracy: 97.08000183105469\n",
            "Iteration: 4500. Loss: 0.049307383596897125. Accuracy: 97.08000183105469\n",
            "Iteration: 5000. Loss: 0.08068697154521942. Accuracy: 96.69999694824219\n",
            "Iteration: 5500. Loss: 0.12790139019489288. Accuracy: 97.30999755859375\n",
            "Iteration: 6000. Loss: 0.007093742024153471. Accuracy: 97.66000366210938\n",
            "Iteration: 6500. Loss: 0.011727366596460342. Accuracy: 97.63999938964844\n",
            "Iteration: 7000. Loss: 0.008610538206994534. Accuracy: 98.06999969482422\n",
            "Iteration: 7500. Loss: 0.027341270819306374. Accuracy: 97.8499984741211\n",
            "Iteration: 8000. Loss: 0.10305538773536682. Accuracy: 97.5199966430664\n",
            "Iteration: 8500. Loss: 0.007204337045550346. Accuracy: 98.13999938964844\n",
            "Iteration: 9000. Loss: 0.012087937444448471. Accuracy: 97.4800033569336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):    \n",
        "    corrects, total, total_loss = 0, 0, 0\n",
        "    model.eval()\n",
        "    for images, labels in val_iter:\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "        else:\n",
        "            images = Variable(images.view(-1 , seq_dim, input_dim)).to(device)\n",
        "        labels = labels.cuda()        \n",
        "        logit = model(images).cuda()\n",
        "        loss = F.cross_entropy(logit, labels, reduction = \"sum\")\n",
        "        _, predicted = torch.max(logit.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_loss += loss.item()\n",
        "        corrects += (predicted == labels).sum()\n",
        "\n",
        "    avg_loss = total_loss / len(val_iter.dataset)\n",
        "    avg_accuracy = corrects / total\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "9nHnoUXCtVto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_loader)\n",
        "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mslJge22tXVr",
        "outputId": "66dc9f01-d4a7-4547-e3ef-d7f17d78a93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  0.07 | Test Accuracy:  0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU\n",
        "- GRU는 기존 LSTM의 구조를 조금 더 간단하게 개선한 모델입니다. 그리고 모델의 대략적인 구조와 수식은 아래와 같습니다.\n",
        "\n",
        "-   LSTM의 경우 forget gate, input gate, output gate 3개의 gate가 있었지만, GRU에서는 reset gate, update gate 2개의 gate만을 사용합니다. 또한 cell state, hidden state가 합쳐져 하나의 hidden state로 표현하고 있습니다. \n",
        "  - Reset Gate : 이전 시점의 hidden state와 현 시점의 x를 활성화함수 시그모이드를 적용하여 구하는 방식입니다. 결과값은 0~1 사이의 값을 가질 것이며 이전 hidden state의 값을 얼마나 활용할 것인지에 대한 정보로 해석할 수 있을 것입니다.\n",
        "  \n",
        "  - Update Gate : STM의 input, forget gate와 비슷한 역할을 하며 과거와 현재의 정보를 각각 얼마나 반영할지에 대한 비율을 구하는 것이 핵심\n",
        "\n",
        "-  GRU는 기존 LSTM에 비해 더 간단한 구조를 가지고 있습니다. 그리고 마지막 출력값에 활성화함수를 적용하지 않습니다. 성능 면에서는 LSTM과 비교해서 우월하다고 할 수 없지만 학습할 파라미터가 더 적은 것이 장점이라고 할 수 있습니다.|\n",
        "\n"
      ],
      "metadata": {
        "id": "65tB5Qd4hKtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png'>"
      ],
      "metadata": {
        "id": "j2KXqqrbkviK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dataset\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "    \n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n",
        "\n",
        "torch.manual_seed(125)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(125)"
      ],
      "metadata": {
        "id": "W_hfO9mmtYg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.5,), (1.0,))\n",
        "])"
      ],
      "metadata": {
        "id": "arBOcbYihMf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "download_root = 'MNIST_DATASET/'\n",
        "\n",
        "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
        "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
        "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_bY-X-_hN2J",
        "outputId": "8ce3ea20-5f69-4f7f-e494-ee61f2d47b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 217118013.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_DATASET/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_DATASET/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 108739402.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_DATASET/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 171861817.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_DATASET/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_DATASET/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 25366882.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_DATASET/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_DATASET/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "valid_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True)"
      ],
      "metadata": {
        "id": "4Hs6ERyUhO4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_iters = 6000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)"
      ],
      "metadata": {
        "id": "wXfGvneRhP4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        self.x2h = nn.Linear(input_size, 3 * hidden_size, bias=bias)\n",
        "        self.h2h = nn.Linear(hidden_size, 3 * hidden_size, bias=bias)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "    \n",
        "    def forward(self, x, hidden):        \n",
        "        x = x.view(-1, x.size(1))\n",
        "        \n",
        "        gate_x = self.x2h(x) \n",
        "        gate_h = self.h2h(hidden)\n",
        "        \n",
        "        gate_x = gate_x.squeeze()\n",
        "        gate_h = gate_h.squeeze()\n",
        "        \n",
        "        i_r, i_i, i_n = gate_x.chunk(3, 1)\n",
        "        h_r, h_i, h_n = gate_h.chunk(3, 1)\n",
        "                \n",
        "        resetgate = F.sigmoid(i_r + h_r)\n",
        "        inputgate = F.sigmoid(i_i + h_i)\n",
        "        newgate = F.tanh(i_n + (resetgate * h_n))\n",
        "        \n",
        "        hy = newgate + inputgate * (hidden - newgate)              \n",
        "        return hy"
      ],
      "metadata": {
        "id": "_QaO-ZSFhQxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim               \n",
        "        self.gru_cell = GRUCell(input_dim, hidden_dim, layer_dim)                \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if torch.cuda.is_available():\n",
        "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
        "        else:\n",
        "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
        "                \n",
        "        outs = []        \n",
        "        hn = h0[0,:,:]\n",
        "        \n",
        "        for seq in range(x.size(1)):\n",
        "            hn = self.gru_cell(x[:,seq,:], hn) \n",
        "            outs.append(hn)\n",
        "            \n",
        "        out = outs[-1].squeeze()        \n",
        "        out = self.fc(out) \n",
        "        return out"
      ],
      "metadata": {
        "id": "wwtDLzE-hSlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 28\n",
        "hidden_dim = 128\n",
        "layer_dim = 1  \n",
        "output_dim = 10\n",
        " \n",
        "model = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        " \n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1 \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "EXroob8EhTvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_dim = 28 \n",
        "loss_list = []\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):         \n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
        "            labels = Variable(labels)\n",
        "          \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            loss.cuda()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss_list.append(loss.item())\n",
        "        iter += 1\n",
        "         \n",
        "        if iter % 500 == 0:         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in valid_loader:\n",
        "                if torch.cuda.is_available():\n",
        "                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "                else:\n",
        "                    images = Variable(images.view(-1 , seq_dim, input_dim))\n",
        "                \n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "             \n",
        "            accuracy = 100 * correct / total\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_HqceMahU_6",
        "outputId": "d9b6dbb8-431a-466c-9797-393abcad6644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 1.6616928577423096. Accuracy: 43.59000015258789\n",
            "Iteration: 1000. Loss: 0.8945668339729309. Accuracy: 76.19999694824219\n",
            "Iteration: 1500. Loss: 0.29147759079933167. Accuracy: 89.7300033569336\n",
            "Iteration: 2000. Loss: 0.23627927899360657. Accuracy: 93.51000213623047\n",
            "Iteration: 2500. Loss: 0.03288726136088371. Accuracy: 95.05000305175781\n",
            "Iteration: 3000. Loss: 0.030374974012374878. Accuracy: 95.81999969482422\n",
            "Iteration: 3500. Loss: 0.16210567951202393. Accuracy: 96.33999633789062\n",
            "Iteration: 4000. Loss: 0.19308766722679138. Accuracy: 96.19000244140625\n",
            "Iteration: 4500. Loss: 0.051720067858695984. Accuracy: 97.0\n",
            "Iteration: 5000. Loss: 0.13900163769721985. Accuracy: 97.26000213623047\n",
            "Iteration: 5500. Loss: 0.08090294152498245. Accuracy: 97.62000274658203\n",
            "Iteration: 6000. Loss: 0.10488356649875641. Accuracy: 97.69000244140625\n",
            "Iteration: 6500. Loss: 0.07984025031328201. Accuracy: 97.80000305175781\n",
            "Iteration: 7000. Loss: 0.10250380635261536. Accuracy: 97.55999755859375\n",
            "Iteration: 7500. Loss: 0.0647798627614975. Accuracy: 97.86000061035156\n",
            "Iteration: 8000. Loss: 0.10547610372304916. Accuracy: 97.80000305175781\n",
            "Iteration: 8500. Loss: 0.04281146451830864. Accuracy: 98.0199966430664\n",
            "Iteration: 9000. Loss: 0.041988763958215714. Accuracy: 98.22000122070312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):    \n",
        "    corrects, total, total_loss = 0, 0, 0\n",
        "    model.eval()\n",
        "    for images, labels in val_iter:\n",
        "        if torch.cuda.is_available():\n",
        "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
        "        else:\n",
        "            images = Variable(images.view(-1 , seq_dim, input_dim)).to(device)\n",
        "        labels = labels.cuda()\n",
        "        logit = model(images).cuda()\n",
        "        loss = F.cross_entropy(logit, labels, reduction = \"sum\")\n",
        "        _, predicted = torch.max(logit.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total_loss += loss.item()\n",
        "        corrects += (predicted == labels).sum()\n",
        "\n",
        "    avg_loss = total_loss / len(val_iter.dataset)\n",
        "    avg_accuracy = corrects / total\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "S22NKeLEhWgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model,test_loader)\n",
        "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js2_cE7ThYBD",
        "outputId": "0736c6c2-a776-414f-c6b6-1811a6ae0060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:  0.07 | Test Accuracy:  0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer 참고 : https://cpm0722.github.io/pytorch-implementation/transformer"
      ],
      "metadata": {
        "id": "hfN-Q9iekHGq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUNOUme3kJH9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}